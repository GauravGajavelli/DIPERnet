{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised graph classification with GCN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "source": [
    "<table><tr><td>Run the latest release of this notebook:</td><td><a href=\"https://mybinder.org/v2/gh/stellargraph/stellargraph/master?urlpath=lab/tree/demos/graph-classification/gcn-supervised-graph-classification.ipynb\" alt=\"Open In Binder\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\"/></a></td><td><a href=\"https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/graph-classification/gcn-supervised-graph-classification.ipynb\" alt=\"Open In Colab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train a graph classification model in a supervised setting using graph convolutional layers followed by a mean pooling layer as well as any number of fully connected layers.\n",
    "\n",
    "The graph convolutional classification model architecture is based on the one proposed in [1] (see Figure 5 in [1]) using the graph convolutional layers from [2]. This demo differs from [1] in the dataset, MUTAG, used here; MUTAG is a collection of static graphs representing chemical compounds with each graph associated with a binary label. Furthermore, none of the graph convolutional layers in our model utilise an attention head as proposed in [1].\n",
    "\n",
    "Evaluation data for graph kernel-based approaches shown in the very last cell in this notebook are taken from [3].\n",
    "\n",
    "**References**\n",
    "\n",
    "[1] Fake News Detection on Social Media using Geometric Deep Learning, F. Monti, F. Frasca, D. Eynard, D. Mannion, and M. M. Bronstein, ICLR 2019. ([link](https://arxiv.org/abs/1902.06673))\n",
    "\n",
    "[2] Semi-supervised Classification with Graph Convolutional Networks, T. N. Kipf and M. Welling, ICLR 2017. ([link](https://arxiv.org/abs/1609.02907))\n",
    "\n",
    "[3] An End-to-End Deep Learning Architecture for Graph Classification, M. Zhang, Z. Cui, M. Neumann, Y. Chen, AAAI-18. ([link](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/17146))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "outputs": [],
   "source": [
    "# install StellarGraph if running on Google Colab\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  %pip install -q stellargraph[demos]==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "VersionCheck"
    ]
   },
   "outputs": [],
   "source": [
    "# verify that we're using the correct version of StellarGraph for this notebook\n",
    "import stellargraph as sg\n",
    "\n",
    "try:\n",
    "    sg.utils.validate_notebook_version(\"1.2.1\")\n",
    "except AttributeError:\n",
    "    raise ValueError(\n",
    "        f\"This notebook requires StellarGraph version 1.2.1, but a different version {sg.__version__} is installed.  Please see <https://github.com/stellargraph/stellargraph/issues/1172>.\"\n",
    "    ) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import PaddedGraphGenerator\n",
    "# from stellargraph.mapper import FullBatchNodeGenerator\n",
    "# mapper.FullBatchNodeGenerator(graph, method=\"gcn\")\n",
    "from stellargraph.layer import GCNSupervisedGraphClassification\n",
    "from stellargraph import StellarGraph\n",
    "\n",
    "from stellargraph import datasets\n",
    "\n",
    "from sklearn import model_selection\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pprint\n",
    "from stellargraph.datasets.dataset_loader import DatasetLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "DataLoadingLinks"
    ]
   },
   "source": [
    "(See [the \"Loading from Pandas\" demo](../basics/loading-pandas.ipynb) for details on how data can be loaded.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_graph_kernel_dataset(dataset):\n",
    "    expected_files = dataset.expected_files\n",
    "    A_filename = expected_files[0]\n",
    "    graph_indicator_filename = expected_files[1]\n",
    "    node_labels_filename = expected_files[2]\n",
    "    edge_labels_filename = expected_files[3]\n",
    "    graph_labels_filename = expected_files[4]\n",
    "    \n",
    "    def _load_from_txt_file(filename, names=None, dtype=None, index_increment=None):\n",
    "        df = pd.read_csv(filename,header=None,index_col=False,dtype=dtype,names=names)\n",
    "        # We optional increment the index by 1 because indexing, e.g. node IDs, for this dataset starts\n",
    "        # at 1 whereas the Pandas DataFrame implicit index starts at 0 potentially causing confusion selecting\n",
    "        # rows later on.\n",
    "        if index_increment:\n",
    "            df.index = df.index + index_increment\n",
    "        return df\n",
    "\n",
    "    # edge information:\n",
    "    df_graph = _load_from_txt_file(filename=A_filename, names=[\"source\", \"target\"])\n",
    "\n",
    "    if dataset._edge_labels_as_weights:\n",
    "        # there's some edge labels, that can be used as edge weights\n",
    "        df_edge_labels = _load_from_txt_file(\n",
    "            filename=edge_labels_filename, names=[\"weight\"], dtype=int\n",
    "        )\n",
    "        df_graph = pd.concat([df_graph, df_edge_labels], axis=1)\n",
    "\n",
    "    # node information:\n",
    "    df_graph_ids = _load_from_txt_file(\n",
    "        filename=graph_indicator_filename, names=[\"graph_id\"], index_increment=1\n",
    "    )\n",
    "\n",
    "    df_node_labels = _load_from_txt_file(\n",
    "        filename=node_labels_filename, dtype=\"category\", index_increment=1\n",
    "    )\n",
    "    # One-hot encode the node labels because these are used as node features in graph classification\n",
    "    # tasks.\n",
    "    df_node_features = pd.get_dummies(df_node_labels)\n",
    "\n",
    "    # graph information:\n",
    "    df_graph_labels = _load_from_txt_file(\n",
    "        filename=graph_labels_filename, dtype=\"category\", names=[\"label\"], index_increment=1\n",
    "    )\n",
    "\n",
    "    # split the data into each of the graphs, based on the nodes in each one\n",
    "    def graph_for_nodes(nodes):\n",
    "        # each graph is disconnected, so the source is enough to identify the graph for an edge\n",
    "        edges = df_graph[df_graph[\"source\"].isin(nodes.index)]\n",
    "        return StellarGraph(nodes, edges)\n",
    "\n",
    "    groups = df_node_features.groupby(df_graph_ids[\"graph_id\"])\n",
    "    graphs = [graph_for_nodes(nodes) for _, nodes in groups]\n",
    "\n",
    "    return graphs, df_graph_labels[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuavData():\n",
    "    name=\"PPMI\"\n",
    "    expected_files=[\"Pioneer GCN Data/GCN_A.txt\",\n",
    "        \"Pioneer GCN Data/GCN_graph_indicator.txt\",\n",
    "        \"Pioneer GCN Data/GCN_node_labels.txt\",\n",
    "        \"Pioneer GCN Data/GCN_edge_labels.txt\",\n",
    "        \"Pioneer GCN Data/GCN_graph_labels.txt\"]\n",
    "#     expected_files=[\"pp/GCN_A.txt\",\n",
    "#             \"pp/GCN_graph_indicator.txt\",\n",
    "#             \"pp/GCN_node_labels.txt\",\n",
    "#             \"pp/GCN_edge_labels.txt\",\n",
    "#             \"pp/GCN_graph_labels.txt\"]\n",
    "#     expected_files=[\"MUTAG_A.txt\",\n",
    "#         \"MUTAG_graph_indicator.txt\",\n",
    "#         \"MUTAG_node_labels.txt\",\n",
    "#         \"MUTAG_edge_labels.txt\",\n",
    "#         \"MUTAG_graph_labels.txt\"]\n",
    "    description=\"Each graph represents a brain derived from an fMRI. There are 164 nodes with 141 distinct node labels.\",\n",
    "    _edge_labels_as_weights = False\n",
    "    _node_attributes = False\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load this dataset into a list of StellarGraph objects with corresponding labels, downloading it if required.\n",
    "\n",
    "        Note: Edges in MUTAG are labelled as one of 4 values: aromatic, single, double, and triple indicated by integers\n",
    "        0, 1, 2, 3 respectively. The edge labels are included in the  :class:`.StellarGraph` objects as edge weights in\n",
    "        integer representation.\n",
    "\n",
    "        Returns:\n",
    "            A tuple that is a list of :class:`.StellarGraph` objects and a Pandas Series of labels one for each graph.\n",
    "        \"\"\"\n",
    "        return _load_graph_kernel_dataset(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "DataLoading"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Each graph represents a brain derived from an fMRI. There are 164 nodes with 141 distinct node labels.',)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = GuavData()\n",
    "display(dataset.description)\n",
    "graphs, graph_labels = dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `graphs` value is a list of many `StellarGraph` instances, each of which has a few node features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 164, Edges: 4518\n",
      "\n",
      " Node types:\n",
      "  default: [164]\n",
      "    Features: float32 vector, length 142\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [4518]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(graphs[0].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 164, Edges: 1844\n",
      "\n",
      " Node types:\n",
      "  default: [164]\n",
      "    Features: float32 vector, length 142\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [1844]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(graphs[1].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics of the sizes of the graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>164.0</td>\n",
       "      <td>3114.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1312.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>164.0</td>\n",
       "      <td>1724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>164.0</td>\n",
       "      <td>1850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>164.0</td>\n",
       "      <td>2850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>164.0</td>\n",
       "      <td>4449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>164.0</td>\n",
       "      <td>4645.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nodes   edges\n",
       "count   20.0    20.0\n",
       "mean   164.0  3114.8\n",
       "std      0.0  1312.2\n",
       "min    164.0  1724.0\n",
       "25%    164.0  1850.0\n",
       "50%    164.0  2850.0\n",
       "75%    164.0  4449.0\n",
       "max    164.0  4645.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame(\n",
    "    [(g.number_of_nodes(), g.number_of_edges()) for g in graphs],\n",
    "    columns=[\"nodes\", \"edges\"],\n",
    ")\n",
    "summary.describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dir(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dir(dataset.load()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are `1` or `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "-1     10\n",
       "1      10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_labels.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_labels = pd.get_dummies(graph_labels, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare graph generator\n",
    "\n",
    "To feed data to the `tf.Keras` model that we will create later, we need a data generator. For supervised graph classification, we create an instance of `StellarGraph`'s `PaddedGraphGenerator` class. Note that `graphs` is a list of `StellarGraph` graph objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = PaddedGraphGenerator(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Keras graph classification model\n",
    "\n",
    "We are now ready to create a `tf.Keras` graph classification model using `StellarGraph`'s `GraphClassification` class together with standard `tf.Keras` layers, e.g., `Dense`. \n",
    "\n",
    "The input is the graph represented by its adjacency and node features matrices. The first two layers are Graph Convolutional as in [2] with each layer having 64 units and `relu` activations. The next layer is a mean pooling layer where the learned node representation are summarized to create a graph representation. The graph representation is input to two fully connected layers with 32 and 16 units respectively and `relu` activations. The last layer is the output layer with a single unit and `sigmoid` activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graph_classification_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_classification_model(generator):\n",
    "    gc_model = GCNSupervisedGraphClassification(\n",
    "        layer_sizes=[64, 64],\n",
    "        activations=[\"relu\", \"relu\"],\n",
    "        generator=generator,\n",
    "        dropout=0.5,\n",
    "    )\n",
    "    x_inp, x_out = gc_model.in_out_tensors()\n",
    "    predictions = Dense(units=32, activation=\"relu\")(x_out)\n",
    "    predictions = Dense(units=16, activation=\"relu\")(predictions)\n",
    "    predictions = Dense(units=1, activation=\"sigmoid\")(predictions)\n",
    "\n",
    "    # Let's create the Keras model and prepare it for training\n",
    "    model = Model(inputs=x_inp, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(0.005), loss=binary_crossentropy, metrics=[\"acc\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "We can now train the model using the model's `fit` method. First, we specify some important training parameters such as the number of training epochs, number of fold for cross validation and the number of time to repeat cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 200  # maximum number of training epochs\n",
    "folds = 2  # the number of folds for k-fold cross validation\n",
    "n_repeats = 1  # the number of repeats for repeated k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0, patience=25, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `train_fold` is used to train a graph classification model for a single fold of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(model, train_gen, test_gen, es, epochs):\n",
    "    history = model.fit(\n",
    "        train_gen, epochs=epochs, validation_data=test_gen, verbose=2, callbacks=[es],\n",
    "    )\n",
    "    # calculate performance on the test data and return along with history\n",
    "    test_metrics = model.evaluate(test_gen, verbose=0)\n",
    "    test_acc = test_metrics[model.metrics_names.index(\"acc\")]\n",
    "\n",
    "    return history, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators(train_index, test_index, graph_labels, batch_size):\n",
    "    train_gen = generator.flow(\n",
    "        train_index, targets=graph_labels.iloc[train_index].values, batch_size=batch_size\n",
    "    )\n",
    "    test_gen = generator.flow(\n",
    "        test_index, targets=graph_labels.iloc[test_index].values, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_gen, test_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below puts all the above functionality together in a training loop for repeated k-fold cross-validation where the number of folds is 10, `folds=10`; that is we do 10-fold cross validation `n_repeats` times where `n_repeats=5`.\n",
    "\n",
    "**Note**: The below code may take a long time to run depending on the value set for `n_repeats`. The larger the latter, the longer it takes since for each repeat we train and evaluate 10 graph classification models, one for each fold of the data. For progress updates, we recommend that you set `verbose=2` in the call to the `fit` method is cell 10, line 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accs = []\n",
    "\n",
    "stratified_folds = model_selection.RepeatedStratifiedKFold(\n",
    "    n_splits=folds, n_repeats=n_repeats\n",
    ").split(graph_labels, graph_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(enumerate(stratified_folds).__sizeof__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(graph_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating on fold 1 out of 2...\n",
      "train_index[ 2  3  6  8  9 11 13 14 18 19]\n",
      "test_index[ 0  1  4  5  7 10 12 15 16 17]\n",
      "Epoch 1/200\n",
      "3/3 - 1s - loss: 0.6990 - acc: 0.3000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/200\n",
      "3/3 - 0s - loss: 0.6949 - acc: 0.6000 - val_loss: 0.6930 - val_acc: 0.5000\n",
      "Epoch 3/200\n",
      "3/3 - 0s - loss: 0.6951 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 0.6936 - acc: 0.4000 - val_loss: 0.6929 - val_acc: 0.4000\n",
      "Epoch 6/200\n",
      "3/3 - 0s - loss: 0.6940 - acc: 0.6000 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 7/200\n",
      "3/3 - 0s - loss: 0.6946 - acc: 0.6000 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 0.6945 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.5000\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 0.6947 - acc: 0.5000 - val_loss: 0.6918 - val_acc: 1.0000\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 0.6909 - acc: 0.7000 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 0.6910 - acc: 0.7000 - val_loss: 0.6909 - val_acc: 0.5000\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 0.6906 - acc: 0.7000 - val_loss: 0.6892 - val_acc: 0.9000\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 0.6873 - acc: 0.6000 - val_loss: 0.6880 - val_acc: 0.5000\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 0.6885 - acc: 0.5000 - val_loss: 0.6861 - val_acc: 0.5000\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 0.6835 - acc: 0.5000 - val_loss: 0.6846 - val_acc: 1.0000\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 0.6799 - acc: 0.9000 - val_loss: 0.6842 - val_acc: 0.5000\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 0.6781 - acc: 0.8000 - val_loss: 0.6782 - val_acc: 0.5000\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 0.6727 - acc: 0.7000 - val_loss: 0.6715 - val_acc: 0.5000\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 0.6648 - acc: 0.8000 - val_loss: 0.6574 - val_acc: 1.0000\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 0.6511 - acc: 0.9000 - val_loss: 0.6520 - val_acc: 0.5000\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 0.6209 - acc: 1.0000 - val_loss: 0.6629 - val_acc: 0.5000\n",
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 0.6369 - acc: 0.6000 - val_loss: 0.6475 - val_acc: 0.5000\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 0.5899 - acc: 0.6000 - val_loss: 0.5771 - val_acc: 1.0000\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 0.5945 - acc: 0.8000 - val_loss: 0.5836 - val_acc: 0.5000\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 0.5348 - acc: 0.9000 - val_loss: 0.5940 - val_acc: 0.5000\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 0.5003 - acc: 0.8000 - val_loss: 0.4812 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 0.4821 - acc: 0.9000 - val_loss: 0.4002 - val_acc: 1.0000\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 0.4284 - acc: 0.9000 - val_loss: 0.5360 - val_acc: 0.5000\n",
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 0.3405 - acc: 0.9000 - val_loss: 0.2861 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 0.2496 - acc: 1.0000 - val_loss: 0.2285 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 0.1707 - acc: 1.0000 - val_loss: 0.2627 - val_acc: 1.0000\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 0.1678 - acc: 1.0000 - val_loss: 0.1297 - val_acc: 1.0000\n",
      "Epoch 33/200\n",
      "3/3 - 0s - loss: 0.0946 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "3/3 - 0s - loss: 0.0865 - acc: 1.0000 - val_loss: 0.0591 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "3/3 - 0s - loss: 0.0542 - acc: 1.0000 - val_loss: 0.1680 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "3/3 - 0s - loss: 0.0524 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "3/3 - 0s - loss: 0.0317 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "3/3 - 0s - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "3/3 - 0s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "3/3 - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "3/3 - 0s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "3/3 - 0s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "3/3 - 0s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "3/3 - 0s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "3/3 - 0s - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "3/3 - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "3/3 - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "3/3 - 0s - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "3/3 - 0s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "3/3 - 0s - loss: 9.3843e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "3/3 - 0s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "3/3 - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "3/3 - 0s - loss: 8.1339e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "3/3 - 0s - loss: 6.9228e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "3/3 - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "3/3 - 0s - loss: 4.0332e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "3/3 - 0s - loss: 4.0979e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "3/3 - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "3/3 - 0s - loss: 4.7642e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "3/3 - 0s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "3/3 - 0s - loss: 2.8012e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "3/3 - 0s - loss: 4.1672e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "3/3 - 0s - loss: 3.3058e-04 - acc: 1.0000 - val_loss: 9.9396e-04 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "3/3 - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 9.4529e-04 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "3/3 - 0s - loss: 9.3290e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "3/3 - 0s - loss: 5.3177e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "3/3 - 0s - loss: 3.4964e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "3/3 - 0s - loss: 2.5514e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "3/3 - 0s - loss: 3.6690e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "3/3 - 0s - loss: 3.4086e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "3/3 - 0s - loss: 4.0984e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "3/3 - 0s - loss: 2.5886e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "3/3 - 0s - loss: 5.1670e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "3/3 - 0s - loss: 3.8770e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "3/3 - 0s - loss: 2.7312e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "3/3 - 0s - loss: 6.0697e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "3/3 - 0s - loss: 3.8012e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "3/3 - 0s - loss: 3.1218e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "3/3 - 0s - loss: 2.2948e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "3/3 - 0s - loss: 4.9549e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "3/3 - 0s - loss: 2.9854e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "3/3 - 0s - loss: 6.2794e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "3/3 - 0s - loss: 5.1091e-04 - acc: 1.0000 - val_loss: 9.0875e-04 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "3/3 - 0s - loss: 2.0835e-04 - acc: 1.0000 - val_loss: 8.4209e-04 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "3/3 - 0s - loss: 4.7910e-04 - acc: 1.0000 - val_loss: 8.2938e-04 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "3/3 - 0s - loss: 3.7328e-04 - acc: 1.0000 - val_loss: 8.2773e-04 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "3/3 - 0s - loss: 2.3953e-04 - acc: 1.0000 - val_loss: 8.1806e-04 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "3/3 - 0s - loss: 1.8688e-04 - acc: 1.0000 - val_loss: 8.1073e-04 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "3/3 - 0s - loss: 2.4690e-04 - acc: 1.0000 - val_loss: 8.1049e-04 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "3/3 - 0s - loss: 2.2024e-04 - acc: 1.0000 - val_loss: 8.1123e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200\n",
      "3/3 - 0s - loss: 4.2971e-04 - acc: 1.0000 - val_loss: 8.1444e-04 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "3/3 - 0s - loss: 2.3720e-04 - acc: 1.0000 - val_loss: 8.1350e-04 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "3/3 - 0s - loss: 6.8936e-04 - acc: 1.0000 - val_loss: 7.1928e-04 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "3/3 - 0s - loss: 1.4856e-04 - acc: 1.0000 - val_loss: 6.5770e-04 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "3/3 - 0s - loss: 1.7744e-04 - acc: 1.0000 - val_loss: 6.2468e-04 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "3/3 - 0s - loss: 3.5280e-04 - acc: 1.0000 - val_loss: 6.2022e-04 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "3/3 - 0s - loss: 2.1413e-04 - acc: 1.0000 - val_loss: 6.3571e-04 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "3/3 - 0s - loss: 3.4159e-04 - acc: 1.0000 - val_loss: 6.4859e-04 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "3/3 - 0s - loss: 3.5430e-04 - acc: 1.0000 - val_loss: 6.3311e-04 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "3/3 - 0s - loss: 2.3833e-04 - acc: 1.0000 - val_loss: 6.1696e-04 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "3/3 - 0s - loss: 2.5117e-04 - acc: 1.0000 - val_loss: 5.9356e-04 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "3/3 - 0s - loss: 4.6278e-04 - acc: 1.0000 - val_loss: 5.7448e-04 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "3/3 - 0s - loss: 3.3110e-04 - acc: 1.0000 - val_loss: 5.7479e-04 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "3/3 - 0s - loss: 2.8197e-04 - acc: 1.0000 - val_loss: 5.8373e-04 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "3/3 - 0s - loss: 1.3548e-04 - acc: 1.0000 - val_loss: 5.8626e-04 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "3/3 - 0s - loss: 1.5488e-04 - acc: 1.0000 - val_loss: 5.9030e-04 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "3/3 - 0s - loss: 2.1259e-04 - acc: 1.0000 - val_loss: 6.0439e-04 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "3/3 - 0s - loss: 2.6639e-04 - acc: 1.0000 - val_loss: 6.2484e-04 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "3/3 - 0s - loss: 1.4050e-04 - acc: 1.0000 - val_loss: 6.3547e-04 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "3/3 - 0s - loss: 1.4982e-04 - acc: 1.0000 - val_loss: 6.3836e-04 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "3/3 - 0s - loss: 9.6203e-05 - acc: 1.0000 - val_loss: 6.3665e-04 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "3/3 - 0s - loss: 1.3670e-04 - acc: 1.0000 - val_loss: 6.3490e-04 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "3/3 - 0s - loss: 2.0031e-04 - acc: 1.0000 - val_loss: 6.2283e-04 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "3/3 - 0s - loss: 2.0834e-04 - acc: 1.0000 - val_loss: 6.0816e-04 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "3/3 - 0s - loss: 1.4554e-04 - acc: 1.0000 - val_loss: 6.0600e-04 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "3/3 - 0s - loss: 2.2772e-04 - acc: 1.0000 - val_loss: 6.2735e-04 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "3/3 - 0s - loss: 2.7047e-04 - acc: 1.0000 - val_loss: 6.4113e-04 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "3/3 - 0s - loss: 7.4086e-05 - acc: 1.0000 - val_loss: 6.4813e-04 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "3/3 - 0s - loss: 1.8534e-04 - acc: 1.0000 - val_loss: 6.4648e-04 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "3/3 - 0s - loss: 5.8287e-04 - acc: 1.0000 - val_loss: 5.2234e-04 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "3/3 - 0s - loss: 1.2018e-04 - acc: 1.0000 - val_loss: 4.6471e-04 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "3/3 - 0s - loss: 2.0054e-04 - acc: 1.0000 - val_loss: 4.2328e-04 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "3/3 - 0s - loss: 1.7967e-04 - acc: 1.0000 - val_loss: 3.9598e-04 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "3/3 - 0s - loss: 4.6886e-04 - acc: 1.0000 - val_loss: 3.9681e-04 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "3/3 - 0s - loss: 1.5097e-04 - acc: 1.0000 - val_loss: 4.1175e-04 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "3/3 - 0s - loss: 1.4096e-04 - acc: 1.0000 - val_loss: 4.2294e-04 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "3/3 - 0s - loss: 2.0691e-04 - acc: 1.0000 - val_loss: 4.3976e-04 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "3/3 - 0s - loss: 1.2309e-04 - acc: 1.0000 - val_loss: 4.4930e-04 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "3/3 - 0s - loss: 8.5606e-05 - acc: 1.0000 - val_loss: 4.5646e-04 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "3/3 - 0s - loss: 1.1816e-04 - acc: 1.0000 - val_loss: 4.6077e-04 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "3/3 - 0s - loss: 1.2274e-04 - acc: 1.0000 - val_loss: 4.5872e-04 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "3/3 - 0s - loss: 2.3995e-04 - acc: 1.0000 - val_loss: 4.5904e-04 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "3/3 - 0s - loss: 8.4645e-05 - acc: 1.0000 - val_loss: 4.6897e-04 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "3/3 - 0s - loss: 8.5287e-05 - acc: 1.0000 - val_loss: 4.7915e-04 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "3/3 - 0s - loss: 9.9271e-05 - acc: 1.0000 - val_loss: 4.8117e-04 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "3/3 - 0s - loss: 8.0250e-05 - acc: 1.0000 - val_loss: 4.8159e-04 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "3/3 - 0s - loss: 8.6182e-05 - acc: 1.0000 - val_loss: 4.7968e-04 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "3/3 - 0s - loss: 5.8422e-04 - acc: 1.0000 - val_loss: 5.0452e-04 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "3/3 - 0s - loss: 5.9988e-05 - acc: 1.0000 - val_loss: 6.1822e-04 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "3/3 - 0s - loss: 1.8059e-04 - acc: 1.0000 - val_loss: 7.1297e-04 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "3/3 - 0s - loss: 1.3038e-04 - acc: 1.0000 - val_loss: 7.5098e-04 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "3/3 - 0s - loss: 1.0544e-04 - acc: 1.0000 - val_loss: 7.6528e-04 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "3/3 - 0s - loss: 8.6875e-04 - acc: 1.0000 - val_loss: 7.4762e-04 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "3/3 - 0s - loss: 2.1943e-04 - acc: 1.0000 - val_loss: 7.2104e-04 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "3/3 - 0s - loss: 3.1731e-05 - acc: 1.0000 - val_loss: 6.9016e-04 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "3/3 - 0s - loss: 9.6787e-05 - acc: 1.0000 - val_loss: 6.6151e-04 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "3/3 - 0s - loss: 3.8995e-04 - acc: 1.0000 - val_loss: 5.2070e-04 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "3/3 - 0s - loss: 1.1719e-04 - acc: 1.0000 - val_loss: 4.2956e-04 - val_acc: 1.0000\n",
      "Training and evaluating on fold 2 out of 2...\n",
      "train_index[ 0  1  4  5  7 10 12 15 16 17]\n",
      "test_index[ 2  3  6  8  9 11 13 14 18 19]\n",
      "Epoch 1/200\n",
      "3/3 - 1s - loss: 0.6969 - acc: 0.5000 - val_loss: 0.6938 - val_acc: 0.5000\n",
      "Epoch 2/200\n",
      "3/3 - 0s - loss: 0.6911 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 3/200\n",
      "3/3 - 0s - loss: 0.6924 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 0.6879 - acc: 0.8000 - val_loss: 0.6916 - val_acc: 0.5000\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 0.6909 - acc: 0.5000 - val_loss: 0.6905 - val_acc: 0.5000\n",
      "Epoch 6/200\n",
      "3/3 - 0s - loss: 0.6883 - acc: 0.7000 - val_loss: 0.6890 - val_acc: 0.5000\n",
      "Epoch 7/200\n",
      "3/3 - 0s - loss: 0.6862 - acc: 0.8000 - val_loss: 0.6857 - val_acc: 1.0000\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 0.6765 - acc: 0.7000 - val_loss: 0.6816 - val_acc: 0.8000\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 0.6677 - acc: 0.8000 - val_loss: 0.6745 - val_acc: 0.9000\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 0.6616 - acc: 0.7000 - val_loss: 0.6641 - val_acc: 0.5000\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 0.6319 - acc: 0.9000 - val_loss: 0.6463 - val_acc: 0.8000\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 0.6368 - acc: 0.7000 - val_loss: 0.6296 - val_acc: 0.5000\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 0.5914 - acc: 0.7000 - val_loss: 0.6174 - val_acc: 0.5000\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 0.5385 - acc: 1.0000 - val_loss: 0.5544 - val_acc: 1.0000\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 0.4740 - acc: 0.9000 - val_loss: 0.4955 - val_acc: 1.0000\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 0.4730 - acc: 1.0000 - val_loss: 0.4209 - val_acc: 1.0000\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 0.3580 - acc: 0.8000 - val_loss: 0.4507 - val_acc: 0.7000\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 0.4024 - acc: 0.7000 - val_loss: 0.3163 - val_acc: 1.0000\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 0.4460 - acc: 0.8000 - val_loss: 0.2480 - val_acc: 1.0000\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 0.2217 - acc: 1.0000 - val_loss: 0.7103 - val_acc: 0.5000\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 0.2317 - acc: 0.9000 - val_loss: 0.1737 - val_acc: 1.0000\n",
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 0.1664 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 1.0000\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 0.0627 - acc: 1.0000 - val_loss: 0.2301 - val_acc: 0.9000\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 0.0875 - acc: 1.0000 - val_loss: 0.1914 - val_acc: 0.9000\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 0.0473 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 1.0000\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 0.1587 - acc: 0.9000 - val_loss: 0.2685 - val_acc: 0.9000\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 0.0778 - acc: 1.0000 - val_loss: 0.8787 - val_acc: 0.6000\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 0.2174 - acc: 0.9000 - val_loss: 0.0266 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 0.2601 - acc: 0.9000 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 0.0272 - acc: 1.0000 - val_loss: 0.0682 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 0.0170 - acc: 1.0000 - val_loss: 0.2210 - val_acc: 0.9000\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 0.0337 - acc: 1.0000 - val_loss: 0.2291 - val_acc: 0.9000\n",
      "Epoch 33/200\n",
      "3/3 - 0s - loss: 0.0303 - acc: 1.0000 - val_loss: 0.0459 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "3/3 - 0s - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "3/3 - 0s - loss: 0.0991 - acc: 1.0000 - val_loss: 0.0755 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "3/3 - 0s - loss: 0.0082 - acc: 1.0000 - val_loss: 0.5772 - val_acc: 0.8000\n",
      "Epoch 37/200\n",
      "3/3 - 0s - loss: 0.3052 - acc: 0.9000 - val_loss: 0.0841 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "3/3 - 0s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "3/3 - 0s - loss: 0.1535 - acc: 0.9000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "3/3 - 0s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.2384 - val_acc: 0.9000\n",
      "Epoch 41/200\n",
      "3/3 - 0s - loss: 0.0763 - acc: 1.0000 - val_loss: 0.3566 - val_acc: 0.8000\n",
      "Epoch 42/200\n",
      "3/3 - 0s - loss: 0.0385 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "3/3 - 0s - loss: 0.0275 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "3/3 - 0s - loss: 0.0589 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "3/3 - 0s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "3/3 - 0s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "3/3 - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "3/3 - 0s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0638 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "3/3 - 0s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0730 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "3/3 - 0s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0771 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "3/3 - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0785 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "3/3 - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0781 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "3/3 - 0s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0677 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "3/3 - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0587 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "3/3 - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0501 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "3/3 - 0s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0451 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "3/3 - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0425 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "3/3 - 0s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "3/3 - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0349 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "3/3 - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "3/3 - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "3/3 - 0s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "3/3 - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "3/3 - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "3/3 - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "3/3 - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "3/3 - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "3/3 - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "3/3 - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(stratified_folds):\n",
    "    print(f\"Training and evaluating on fold {i+1} out of {folds * n_repeats}...\")\n",
    "    print(\"train_index\" + str(train_index))\n",
    "    print(\"test_index\" + str(test_index))\n",
    "    train_gen, test_gen = get_generators(\n",
    "        train_index, test_index, graph_labels, batch_size=4\n",
    "    )\n",
    "\n",
    "    model = create_graph_classification_model(generator)\n",
    "\n",
    "    history, acc = train_fold(model, train_gen, test_gen, es, epochs)\n",
    "\n",
    "    test_accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over all folds mean: 1e+02% and std: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Accuracy over all folds mean: {np.mean(test_accs)*100:.3}% and std: {np.std(test_accs)*100:.2}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot a histogram of the accuracy of all `n_repeats x folds` models trained (25 in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(test_accs)\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shown above indicates the difficulty of training a good model on the MUTAG dataset due to the following factors,\n",
    "- small amount of available data, i.e., only 188 graphs\n",
    "- small amount of validation data since for a single fold only 19 graphs are used for validation\n",
    "- the data are unbalanced since the majority class is twice as prevalent in the data\n",
    "\n",
    "Given the above, average performance as estimated using repeated 10-fold cross validation displays high variance but overall good performance for a straightforward application of graph convolutional neural networks to supervised graph classification. The high variance is likely the result of the small dataset size.\n",
    "\n",
    "Generally, performance is a bit lower than SOTA in recent literature. However, we have not tuned the model for the best performance possible so some improvement over the current baseline may be attainable.\n",
    "\n",
    "When comparing to graph kernel-based approaches, our straightforward GCN with mean pooling graph classification model is competitive with the WL kernel being the exception.\n",
    "\n",
    "For comparison, some performance numbers repeated from [3] for graph kernel-based approaches are, \n",
    "- Graphlet Kernel (GK): $81.39\\pm1.74$\n",
    "- Random Walk Kernel (RW): $79.17\\pm2.07$\n",
    "- Propagation Kernel (PK): $76.00\\pm2.69$\n",
    "- Weisfeiler-Lehman Subtree Kernel (WL): $84.11\\pm1.91$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "source": [
    "<table><tr><td>Run the latest release of this notebook:</td><td><a href=\"https://mybinder.org/v2/gh/stellargraph/stellargraph/master?urlpath=lab/tree/demos/graph-classification/gcn-supervised-graph-classification.ipynb\" alt=\"Open In Binder\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\"/></a></td><td><a href=\"https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/graph-classification/gcn-supervised-graph-classification.ipynb\" alt=\"Open In Colab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a></td></tr></table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
