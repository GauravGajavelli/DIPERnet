{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6oZgrsXs0yh"
      },
      "source": [
        "# Supervised graph classification with GCN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MLD9_Gks0ym"
      },
      "source": [
        "This notebook demonstrates how to train a graph classification model in a supervised setting using graph convolutional layers followed by a mean pooling layer as well as any number of fully connected layers.\n",
        "\n",
        "The graph convolutional classification model architecture is based on the one proposed in [1] (see Figure 5 in [1]) using the graph convolutional layers from [2]. This demo differs from [1] in the dataset, MUTAG, used here; MUTAG is a collection of static graphs representing chemical compounds with each graph associated with a binary label. Furthermore, none of the graph convolutional layers in our model utilise an attention head as proposed in [1].\n",
        "\n",
        "Evaluation data for graph kernel-based approaches shown in the very last cell in this notebook are taken from [3].\n",
        "\n",
        "**References**\n",
        "\n",
        "[1] Fake News Detection on Social Media using Geometric Deep Learning, F. Monti, F. Frasca, D. Eynard, D. Mannion, and M. M. Bronstein, ICLR 2019. ([link](https://arxiv.org/abs/1902.06673))\n",
        "\n",
        "[2] Semi-supervised Classification with Graph Convolutional Networks, T. N. Kipf and M. Welling, ICLR 2017. ([link](https://arxiv.org/abs/1609.02907))\n",
        "\n",
        "[3] An End-to-End Deep Learning Architecture for Graph Classification, M. Zhang, Z. Cui, M. Neumann, Y. Chen, AAAI-18. ([link](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/17146))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbsphinx": "hidden",
        "tags": [
          "CloudRunner"
        ],
        "id": "IyjsJYYTs0yn"
      },
      "outputs": [],
      "source": [
        "import stellargraph as sg\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_7o0LFOs0yo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import stellargraph as sg\n",
        "from stellargraph.mapper import PaddedGraphGenerator\n",
        "# from stellargraph.mapper import FullBatchNodeGenerator\n",
        "# mapper.FullBatchNodeGenerator(graph, method=\"gcn\")\n",
        "from stellargraph.layer import GCNSupervisedGraphClassification\n",
        "from stellargraph import StellarGraph\n",
        "\n",
        "from stellargraph import datasets\n",
        "\n",
        "from sklearn import model_selection\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pprint\n",
        "from stellargraph.datasets.dataset_loader import DatasetLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcVlrX0Ws0yp"
      },
      "source": [
        "## Import the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "DataLoadingLinks"
        ],
        "id": "zhPB4Pocs0yp"
      },
      "source": [
        "(See [the \"Loading from Pandas\" demo](../basics/loading-pandas.ipynb) for details on how data can be loaded.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFprGPO9s0yq"
      },
      "outputs": [],
      "source": [
        "def _load_graph_kernel_dataset(dataset):\n",
        "    expected_files = dataset.expected_files\n",
        "    A_filename = expected_files[0]\n",
        "    graph_indicator_filename = expected_files[1]\n",
        "    node_labels_filename = expected_files[2]\n",
        "    edge_labels_filename = expected_files[3]\n",
        "    graph_labels_filename = expected_files[4]\n",
        "    \n",
        "    def _load_from_txt_file(filename, names=None, dtype=None, index_increment=None):\n",
        "        df = pd.read_csv(filename,header=None,index_col=False,dtype=dtype,names=names)\n",
        "        # We optional increment the index by 1 because indexing, e.g. node IDs, for this dataset starts\n",
        "        # at 1 whereas the Pandas DataFrame implicit index starts at 0 potentially causing confusion selecting\n",
        "        # rows later on.\n",
        "        if index_increment:\n",
        "            df.index = df.index + index_increment\n",
        "        return df\n",
        "\n",
        "    # edge information:\n",
        "    df_graph = _load_from_txt_file(filename=A_filename, names=[\"source\", \"target\"])\n",
        "\n",
        "    if dataset._edge_labels_as_weights:\n",
        "        # there's some edge labels, that can be used as edge weights\n",
        "        df_edge_labels = _load_from_txt_file(\n",
        "            filename=edge_labels_filename, names=[\"weight\"], dtype=int\n",
        "        )\n",
        "        df_graph = pd.concat([df_graph, df_edge_labels], axis=1)\n",
        "\n",
        "    # node information:\n",
        "    df_graph_ids = _load_from_txt_file(\n",
        "        filename=graph_indicator_filename, names=[\"graph_id\"], index_increment=1\n",
        "    )\n",
        "\n",
        "    df_node_labels = _load_from_txt_file(\n",
        "        filename=node_labels_filename, dtype=\"category\", index_increment=1\n",
        "    )\n",
        "    # One-hot encode the node labels because these are used as node features in graph classification\n",
        "    # tasks.\n",
        "    df_node_features = pd.get_dummies(df_node_labels)\n",
        "\n",
        "    # graph information:\n",
        "    df_graph_labels = _load_from_txt_file(\n",
        "        filename=graph_labels_filename, dtype=\"category\", names=[\"label\"], index_increment=1\n",
        "    )\n",
        "\n",
        "    # split the data into each of the graphs, based on the nodes in each one\n",
        "    def graph_for_nodes(nodes):\n",
        "        # each graph is disconnected, so the source is enough to identify the graph for an edge\n",
        "        edges = df_graph[df_graph[\"source\"].isin(nodes.index)]\n",
        "        return StellarGraph(nodes, edges)\n",
        "\n",
        "    groups = df_node_features.groupby(df_graph_ids[\"graph_id\"])\n",
        "    graphs = [graph_for_nodes(nodes) for _, nodes in groups]\n",
        "\n",
        "    return graphs, df_graph_labels[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6-oGdOks0yr"
      },
      "outputs": [],
      "source": [
        "class GuavData():\n",
        "    name=\"PPMI\"\n",
        "#     expected_files=[\"Pioneer GCN Data/GCN_A.txt\",\n",
        "#         \"Pioneer GCN Data/GCN_graph_indicator.txt\",\n",
        "#         \"Pioneer GCN Data/GCN_node_labels.txt\",\n",
        "#         \"Pioneer GCN Data/GCN_edge_labels.txt\",\n",
        "#         \"Pioneer GCN Data/GCN_graph_labels.txt\"]\n",
        "    expected_files=[\"BIG_GCN_A.txt\",\n",
        "            \"BIG_GCN_graph_indicator.txt\",\n",
        "            \"BIG_GCN_node_labels.txt\",\n",
        "            \"BIG_GCN_edge_labels.txt\",\n",
        "            \"BIG_GCN_graph_labels.txt\"]\n",
        "#     expected_files=[\"MUTAG_A.txt\",\n",
        "#         \"MUTAG_graph_indicator.txt\",\n",
        "#         \"MUTAG_node_labels.txt\",\n",
        "#         \"MUTAG_edge_labels.txt\",\n",
        "#         \"MUTAG_graph_labels.txt\"]\n",
        "    description=\"Each graph represents a brain derived from an fMRI. There are 164 nodes with 141 distinct node labels.\",\n",
        "    _edge_labels_as_weights = False\n",
        "    _node_attributes = False\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\"\n",
        "        Load this dataset into a list of StellarGraph objects with corresponding labels, downloading it if required.\n",
        "\n",
        "        Note: Edges in MUTAG are labelled as one of 4 values: aromatic, single, double, and triple indicated by integers\n",
        "        0, 1, 2, 3 respectively. The edge labels are included in the  :class:`.StellarGraph` objects as edge weights in\n",
        "        integer representation.\n",
        "\n",
        "        Returns:\n",
        "            A tuple that is a list of :class:`.StellarGraph` objects and a Pandas Series of labels one for each graph.\n",
        "        \"\"\"\n",
        "        return _load_graph_kernel_dataset(self)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "DataLoading"
        ],
        "id": "d5BHJNyQs0yt",
        "outputId": "439d55f1-eb24-4847-93fa-d63e92ca57d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Each graph represents a brain derived from an fMRI. There are 164 nodes with 141 distinct node labels.',)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = GuavData()\n",
        "display(dataset.description)\n",
        "graphs, graph_labels = dataset.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QAPBlHOs0yu"
      },
      "source": [
        "The `graphs` value is a list of many `StellarGraph` instances, each of which has a few node features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmrQ7GBVs0yv",
        "outputId": "64a60b61-360f-4c50-c5e2-1d7f18b0cb57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StellarGraph: Undirected multigraph\n",
            " Nodes: 164, Edges: 3124\n",
            "\n",
            " Node types:\n",
            "  default: [164]\n",
            "    Features: float32 vector, length 142\n",
            "    Edge types: default-default->default\n",
            "\n",
            " Edge types:\n",
            "    default-default->default: [3124]\n",
            "        Weights: all 1 (default)\n",
            "        Features: none\n"
          ]
        }
      ],
      "source": [
        "print(graphs[0].info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkUnUmtns0yv",
        "outputId": "2c4aa9cc-630c-4776-b908-204e16d63d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StellarGraph: Undirected multigraph\n",
            " Nodes: 164, Edges: 4248\n",
            "\n",
            " Node types:\n",
            "  default: [164]\n",
            "    Features: float32 vector, length 142\n",
            "    Edge types: default-default->default\n",
            "\n",
            " Edge types:\n",
            "    default-default->default: [4248]\n",
            "        Weights: all 1 (default)\n",
            "        Features: none\n"
          ]
        }
      ],
      "source": [
        "print(graphs[1].info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEXYmH-as0yw"
      },
      "source": [
        "Summary statistics of the sizes of the graphs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUHhCcw7s0yw",
        "outputId": "c32d22a3-fbbb-4d73-d0a8-c51ae0ae3cc7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nodes</th>\n",
              "      <th>edges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>240.0</td>\n",
              "      <td>240.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>164.0</td>\n",
              "      <td>3444.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>590.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>164.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>164.0</td>\n",
              "      <td>3274.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>164.0</td>\n",
              "      <td>3490.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>164.0</td>\n",
              "      <td>3704.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>164.0</td>\n",
              "      <td>4689.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       nodes   edges\n",
              "count  240.0   240.0\n",
              "mean   164.0  3444.4\n",
              "std      0.0   590.6\n",
              "min    164.0     0.0\n",
              "25%    164.0  3274.0\n",
              "50%    164.0  3490.0\n",
              "75%    164.0  3704.0\n",
              "max    164.0  4689.0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary = pd.DataFrame(\n",
        "    [(g.number_of_nodes(), g.number_of_edges()) for g in graphs],\n",
        "    columns=[\"nodes\", \"edges\"],\n",
        ")\n",
        "summary.describe().round(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwpUjENYs0yx"
      },
      "outputs": [],
      "source": [
        "# print(dir(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJqbUaeBs0yx"
      },
      "outputs": [],
      "source": [
        "# print(dir(dataset.load()[0][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkiBGQ90s0yx"
      },
      "source": [
        "The labels are `1` or `0`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rq9f4BxUs0yy",
        "outputId": "4ebfe32b-3eef-4e0f-8682-fa7dfe72782f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-1</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label\n",
              "-1    120\n",
              "1     120"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_labels.value_counts().to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyAW3yrCs0yy"
      },
      "outputs": [],
      "source": [
        "graph_labels = pd.get_dummies(graph_labels, drop_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntgTWVdis0yy"
      },
      "source": [
        "### Prepare graph generator\n",
        "\n",
        "To feed data to the `tf.Keras` model that we will create later, we need a data generator. For supervised graph classification, we create an instance of `StellarGraph`'s `PaddedGraphGenerator` class. Note that `graphs` is a list of `StellarGraph` graph objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR_SDcIYs0yz"
      },
      "outputs": [],
      "source": [
        "generator = PaddedGraphGenerator(graphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qHIhpOVs0yz"
      },
      "source": [
        "### Create the Keras graph classification model\n",
        "\n",
        "We are now ready to create a `tf.Keras` graph classification model using `StellarGraph`'s `GraphClassification` class together with standard `tf.Keras` layers, e.g., `Dense`. \n",
        "\n",
        "The input is the graph represented by its adjacency and node features matrices. The first two layers are Graph Convolutional as in [2] with each layer having 64 units and `relu` activations. The next layer is a mean pooling layer where the learned node representation are summarized to create a graph representation. The graph representation is input to two fully connected layers with 32 and 16 units respectively and `relu` activations. The last layer is the output layer with a single unit and `sigmoid` activation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdcbe0cos0yz"
      },
      "source": [
        "![](graph_classification_architecture.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoxzNDtas0y0"
      },
      "outputs": [],
      "source": [
        "def create_graph_classification_model(generator):\n",
        "    gc_model = GCNSupervisedGraphClassification(\n",
        "        layer_sizes=[64, 64],\n",
        "        activations=[\"relu\", \"relu\"],\n",
        "        generator=generator,\n",
        "        dropout=0.5,\n",
        "    )\n",
        "    x_inp, x_out = gc_model.in_out_tensors()\n",
        "    predictions = Dense(units=32, activation=\"relu\")(x_out)\n",
        "    predictions = Dense(units=16, activation=\"relu\")(predictions)\n",
        "    predictions = Dense(units=1, activation=\"sigmoid\")(predictions)\n",
        "\n",
        "    # Let's create the Keras model and prepare it for training\n",
        "    model = Model(inputs=x_inp, outputs=predictions)\n",
        "    model.compile(optimizer=Adam(0.004), loss=binary_crossentropy, metrics=[tf.keras.metrics.BinaryAccuracy(name=\"acc\"),tf.keras.metrics.Precision(name=\"precision\"),tf.keras.metrics.Recall(name=\"recall\"),tf.keras.metrics.TrueNegatives(name=\"tn\"),tf.keras.metrics.FalsePositives(name=\"fp\")])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4xNpGFks0y0"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "We can now train the model using the model's `fit` method. First, we specify some important training parameters such as the number of training epochs, number of fold for cross validation and the number of time to repeat cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ],
        "id": "lZD2al5zs0y0"
      },
      "outputs": [],
      "source": [
        "epochs = 500  # maximum number of training epochs\n",
        "folds = 4  # the number of folds for k-fold cross validation\n",
        "n_repeats = 2  # the number of repeats for repeated k-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhQQcrMPs0y1"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0, patience=25, restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-MDn-Yas0y1"
      },
      "source": [
        "The method `train_fold` is used to train a graph classification model for a single fold of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26H_SYuOs0y1"
      },
      "outputs": [],
      "source": [
        "def train_fold(model, train_gen, test_gen, es, epochs):\n",
        "    history = model.fit(\n",
        "        train_gen, epochs=epochs, validation_data=test_gen, verbose=2, callbacks=[es],\n",
        "    )\n",
        "    # calculate performance on the test data and return along with history\n",
        "    test_metrics = model.evaluate(test_gen, verbose=1)\n",
        "    print('loss:')\n",
        "    print(test_metrics)\n",
        "    print(model.metrics_names)\n",
        "#     loss = test_metrics[model.metrics_names.index(\"loss\")]\n",
        "    test_acc = test_metrics[model.metrics_names.index(\"acc\")]\n",
        "    precision = test_metrics[model.metrics_names.index(\"precision\")]\n",
        "    recall = test_metrics[model.metrics_names.index(\"recall\")]\n",
        "    true_neg = test_metrics[model.metrics_names.index(\"tn\")]\n",
        "    false_pos = test_metrics[model.metrics_names.index(\"fp\")]\n",
        "    \n",
        "    return history, test_acc, precision, recall, true_neg, false_pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV3w5E8Ks0y2"
      },
      "outputs": [],
      "source": [
        "def get_generators(train_index, test_index, graph_labels, batch_size):\n",
        "    train_gen = generator.flow(\n",
        "        train_index, targets=graph_labels.iloc[train_index].values, batch_size=batch_size\n",
        "    )\n",
        "    test_gen = generator.flow(\n",
        "        test_index, targets=graph_labels.iloc[test_index].values, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    return train_gen, test_gen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F54WILtPs0y2"
      },
      "source": [
        "The code below puts all the above functionality together in a training loop for repeated k-fold cross-validation where the number of folds is 10, `folds=10`; that is we do 10-fold cross validation `n_repeats` times where `n_repeats=5`.\n",
        "\n",
        "**Note**: The below code may take a long time to run depending on the value set for `n_repeats`. The larger the latter, the longer it takes since for each repeat we train and evaluate 10 graph classification models, one for each fold of the data. For progress updates, we recommend that you set `verbose=2` in the call to the `fit` method is cell 10, line 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVivM3ggs0y2"
      },
      "outputs": [],
      "source": [
        "test_accs = []\n",
        "test_precision = []\n",
        "test_recall = []\n",
        "test_true_neg = []\n",
        "test_false_pos = []\n",
        "histories = []\n",
        "\n",
        "stratified_folds = model_selection.RepeatedStratifiedKFold(\n",
        "    n_splits=folds, n_repeats=n_repeats\n",
        ").split(graph_labels, graph_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AclF842Cs0y2",
        "outputId": "8e68d70c-aec3-4975-a431-31797744d9c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48\n"
          ]
        }
      ],
      "source": [
        "print(enumerate(stratified_folds).__sizeof__())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9icZ338vs0y3"
      },
      "outputs": [],
      "source": [
        "# print(graph_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BSXjN-ss0y3",
        "outputId": "1afde534-3ddb-4eab-b71d-12c0deb75f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and evaluating on fold 1 out of 8...\n",
            "train_index[  0   1   2   3   4   5   8   9  10  11  13  14  15  16  23  25  26  28\n",
            "  29  31  32  33  34  35  37  38  39  40  41  43  44  45  46  47  48  49\n",
            "  50  51  52  53  54  55  57  58  61  62  63  64  66  67  69  70  72  73\n",
            "  74  75  76  77  78  79  81  82  83  85  86  87  88  89  91  92  93  94\n",
            "  95  98  99 101 102 104 107 108 109 110 112 113 114 115 116 117 118 119\n",
            " 120 121 123 125 127 128 131 132 134 136 137 138 139 140 141 142 143 145\n",
            " 147 148 149 150 151 152 153 154 155 156 157 158 161 162 163 164 165 167\n",
            " 168 169 170 171 172 173 174 177 178 179 180 181 182 183 184 185 187 188\n",
            " 189 192 193 194 196 197 198 199 201 202 203 204 205 208 209 210 213 215\n",
            " 216 217 218 219 220 221 222 223 225 227 228 229 230 231 233 234 238 239]\n",
            "test_index[  6   7  12  17  18  19  20  21  22  24  27  30  36  42  56  59  60  65\n",
            "  68  71  80  84  90  96  97 100 103 105 106 111 122 124 126 129 130 133\n",
            " 135 144 146 159 160 166 175 176 186 190 191 195 200 206 207 211 212 214\n",
            " 224 226 232 235 236 237]\n",
            "Epoch 1/500\n",
            "18/18 - 2s - loss: 0.7052 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6960 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 2/500\n",
            "18/18 - 0s - loss: 0.7025 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6958 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 3/500\n",
            "18/18 - 0s - loss: 0.6918 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6933 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 4/500\n",
            "18/18 - 0s - loss: 0.6956 - acc: 0.3889 - precision: 0.3148 - recall: 0.1889 - tn: 53.0000 - fp: 37.0000 - val_loss: 0.6933 - val_acc: 0.4833 - val_precision: 0.4915 - val_recall: 0.9667 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 5/500\n",
            "18/18 - 0s - loss: 0.6976 - acc: 0.3167 - precision: 0.3226 - recall: 0.3333 - tn: 27.0000 - fp: 63.0000 - val_loss: 0.6933 - val_acc: 0.4833 - val_precision: 0.4915 - val_recall: 0.9667 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 6/500\n",
            "18/18 - 0s - loss: 0.6985 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 7/500\n",
            "18/18 - 0s - loss: 0.6953 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 8/500\n",
            "18/18 - 0s - loss: 0.6948 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 9/500\n",
            "18/18 - 0s - loss: 0.6948 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 10/500\n",
            "18/18 - 0s - loss: 0.6939 - acc: 0.3667 - precision: 0.4200 - recall: 0.7000 - tn: 3.0000 - fp: 87.0000 - val_loss: 0.6932 - val_acc: 0.5500 - val_precision: 0.5273 - val_recall: 0.9667 - val_tn: 4.0000 - val_fp: 26.0000\n",
            "Epoch 11/500\n",
            "18/18 - 0s - loss: 0.6940 - acc: 0.3833 - precision: 0.4255 - recall: 0.6667 - tn: 9.0000 - fp: 81.0000 - val_loss: 0.6932 - val_acc: 0.4833 - val_precision: 0.4915 - val_recall: 0.9667 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 12/500\n",
            "18/18 - 0s - loss: 0.6950 - acc: 0.4500 - precision: 0.4698 - recall: 0.7778 - tn: 11.0000 - fp: 79.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 13/500\n",
            "18/18 - 0s - loss: 0.6966 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6939 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 14/500\n",
            "18/18 - 0s - loss: 0.6929 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6937 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 15/500\n",
            "18/18 - 0s - loss: 0.6899 - acc: 0.4556 - precision: 0.3462 - recall: 0.1000 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.6958 - val_acc: 0.5500 - val_precision: 0.5273 - val_recall: 0.9667 - val_tn: 4.0000 - val_fp: 26.0000\n",
            "Epoch 16/500\n",
            "18/18 - 0s - loss: 0.6847 - acc: 0.5333 - precision: 0.5211 - recall: 0.8222 - tn: 22.0000 - fp: 68.0000 - val_loss: 0.7233 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 0.6667 - val_tn: 10.0000 - val_fp: 20.0000\n",
            "Epoch 17/500\n",
            "18/18 - 0s - loss: 0.6834 - acc: 0.4833 - precision: 0.4898 - recall: 0.8000 - tn: 15.0000 - fp: 75.0000 - val_loss: 0.7080 - val_acc: 0.5667 - val_precision: 0.5370 - val_recall: 0.9667 - val_tn: 5.0000 - val_fp: 25.0000\n",
            "Epoch 18/500\n",
            "18/18 - 0s - loss: 0.6597 - acc: 0.5611 - precision: 0.5379 - recall: 0.8667 - tn: 23.0000 - fp: 67.0000 - val_loss: 0.7400 - val_acc: 0.5333 - val_precision: 0.5208 - val_recall: 0.8333 - val_tn: 7.0000 - val_fp: 23.0000\n",
            "Epoch 19/500\n",
            "18/18 - 0s - loss: 0.6590 - acc: 0.5778 - precision: 0.5467 - recall: 0.9111 - tn: 22.0000 - fp: 68.0000 - val_loss: 0.7797 - val_acc: 0.5333 - val_precision: 0.5208 - val_recall: 0.8333 - val_tn: 7.0000 - val_fp: 23.0000\n",
            "Epoch 20/500\n",
            "18/18 - 0s - loss: 0.6540 - acc: 0.6000 - precision: 0.5592 - recall: 0.9444 - tn: 23.0000 - fp: 67.0000 - val_loss: 0.7826 - val_acc: 0.6000 - val_precision: 0.5577 - val_recall: 0.9667 - val_tn: 7.0000 - val_fp: 23.0000\n",
            "Epoch 21/500\n",
            "18/18 - 0s - loss: 0.6579 - acc: 0.5556 - precision: 0.5338 - recall: 0.8778 - tn: 21.0000 - fp: 69.0000 - val_loss: 0.7839 - val_acc: 0.6000 - val_precision: 0.5577 - val_recall: 0.9667 - val_tn: 7.0000 - val_fp: 23.0000\n",
            "Epoch 22/500\n",
            "18/18 - 0s - loss: 0.6484 - acc: 0.5944 - precision: 0.5541 - recall: 0.9667 - tn: 20.0000 - fp: 70.0000 - val_loss: 0.8153 - val_acc: 0.5667 - val_precision: 0.5400 - val_recall: 0.9000 - val_tn: 7.0000 - val_fp: 23.0000\n",
            "Epoch 23/500\n",
            "18/18 - 0s - loss: 0.6322 - acc: 0.6056 - precision: 0.5655 - recall: 0.9111 - tn: 27.0000 - fp: 63.0000 - val_loss: 0.8050 - val_acc: 0.6000 - val_precision: 0.5577 - val_recall: 0.9667 - val_tn: 7.0000 - val_fp: 23.0000\n",
            "Epoch 24/500\n",
            "18/18 - 0s - loss: 0.6327 - acc: 0.6056 - precision: 0.5613 - recall: 0.9667 - tn: 22.0000 - fp: 68.0000 - val_loss: 0.8778 - val_acc: 0.5500 - val_precision: 0.5319 - val_recall: 0.8333 - val_tn: 8.0000 - val_fp: 22.0000\n",
            "Epoch 25/500\n",
            "18/18 - 0s - loss: 0.6347 - acc: 0.5944 - precision: 0.5570 - recall: 0.9222 - tn: 24.0000 - fp: 66.0000 - val_loss: 0.8351 - val_acc: 0.5833 - val_precision: 0.5490 - val_recall: 0.9333 - val_tn: 7.0000 - val_fp: 23.0000\n",
            "Epoch 26/500\n",
            "18/18 - 0s - loss: 0.6171 - acc: 0.6167 - precision: 0.5695 - recall: 0.9556 - tn: 25.0000 - fp: 65.0000 - val_loss: 0.8616 - val_acc: 0.5833 - val_precision: 0.5490 - val_recall: 0.9333 - val_tn: 7.0000 - val_fp: 23.0000\n",
            "Epoch 27/500\n",
            "18/18 - 0s - loss: 0.6384 - acc: 0.5611 - precision: 0.5350 - recall: 0.9333 - tn: 17.0000 - fp: 73.0000 - val_loss: 0.8184 - val_acc: 0.6000 - val_precision: 0.5577 - val_recall: 0.9667 - val_tn: 7.0000 - val_fp: 23.0000\n",
            "Epoch 28/500\n",
            "18/18 - 0s - loss: 0.6053 - acc: 0.6389 - precision: 0.5817 - recall: 0.9889 - tn: 26.0000 - fp: 64.0000 - val_loss: 0.8915 - val_acc: 0.5833 - val_precision: 0.5510 - val_recall: 0.9000 - val_tn: 8.0000 - val_fp: 22.0000\n",
            "Epoch 29/500\n",
            "18/18 - 0s - loss: 0.6112 - acc: 0.6000 - precision: 0.5616 - recall: 0.9111 - tn: 26.0000 - fp: 64.0000 - val_loss: 0.7324 - val_acc: 0.6000 - val_precision: 0.5577 - val_recall: 0.9667 - val_tn: 7.0000 - val_fp: 23.0000\n",
            "Epoch 30/500\n",
            "18/18 - 0s - loss: 0.5963 - acc: 0.6278 - precision: 0.5742 - recall: 0.9889 - tn: 24.0000 - fp: 66.0000 - val_loss: 0.6572 - val_acc: 0.5833 - val_precision: 0.5490 - val_recall: 0.9333 - val_tn: 7.0000 - val_fp: 23.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31/500\n",
            "18/18 - 0s - loss: 0.6481 - acc: 0.5833 - precision: 0.5573 - recall: 0.8111 - tn: 32.0000 - fp: 58.0000 - val_loss: 1.1119 - val_acc: 0.5333 - val_precision: 1.0000 - val_recall: 0.0667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 32/500\n",
            "18/18 - 0s - loss: 0.6621 - acc: 0.5556 - precision: 0.5362 - recall: 0.8222 - tn: 26.0000 - fp: 64.0000 - val_loss: 0.6914 - val_acc: 0.6000 - val_precision: 0.5577 - val_recall: 0.9667 - val_tn: 7.0000 - val_fp: 23.0000\n",
            "Epoch 33/500\n",
            "18/18 - 0s - loss: 0.6103 - acc: 0.6111 - precision: 0.5649 - recall: 0.9667 - tn: 23.0000 - fp: 67.0000 - val_loss: 0.7377 - val_acc: 0.5667 - val_precision: 0.5417 - val_recall: 0.8667 - val_tn: 8.0000 - val_fp: 22.0000\n",
            "Epoch 34/500\n",
            "18/18 - 0s - loss: 0.6009 - acc: 0.6000 - precision: 0.5577 - recall: 0.9667 - tn: 21.0000 - fp: 69.0000 - val_loss: 0.6354 - val_acc: 0.6000 - val_precision: 0.5600 - val_recall: 0.9333 - val_tn: 8.0000 - val_fp: 22.0000\n",
            "Epoch 35/500\n",
            "18/18 - 0s - loss: 0.5804 - acc: 0.6167 - precision: 0.5677 - recall: 0.9778 - tn: 23.0000 - fp: 67.0000 - val_loss: 0.5809 - val_acc: 0.6167 - val_precision: 0.5745 - val_recall: 0.9000 - val_tn: 10.0000 - val_fp: 20.0000\n",
            "Epoch 36/500\n",
            "18/18 - 0s - loss: 0.5800 - acc: 0.6167 - precision: 0.5695 - recall: 0.9556 - tn: 25.0000 - fp: 65.0000 - val_loss: 0.5939 - val_acc: 0.6000 - val_precision: 0.5652 - val_recall: 0.8667 - val_tn: 10.0000 - val_fp: 20.0000\n",
            "Epoch 37/500\n",
            "18/18 - 0s - loss: 0.6029 - acc: 0.6000 - precision: 0.5600 - recall: 0.9333 - tn: 24.0000 - fp: 66.0000 - val_loss: 0.5912 - val_acc: 0.6167 - val_precision: 0.5745 - val_recall: 0.9000 - val_tn: 10.0000 - val_fp: 20.0000\n",
            "Epoch 38/500\n",
            "18/18 - 0s - loss: 0.5386 - acc: 0.6444 - precision: 0.5844 - recall: 1.0000 - tn: 26.0000 - fp: 64.0000 - val_loss: 0.5585 - val_acc: 0.6000 - val_precision: 0.5600 - val_recall: 0.9333 - val_tn: 8.0000 - val_fp: 22.0000\n",
            "Epoch 39/500\n",
            "18/18 - 0s - loss: 0.5401 - acc: 0.6167 - precision: 0.5686 - recall: 0.9667 - tn: 24.0000 - fp: 66.0000 - val_loss: 0.5516 - val_acc: 0.6167 - val_precision: 0.5745 - val_recall: 0.9000 - val_tn: 10.0000 - val_fp: 20.0000\n",
            "Epoch 40/500\n",
            "18/18 - 0s - loss: 0.5282 - acc: 0.6111 - precision: 0.5649 - recall: 0.9667 - tn: 23.0000 - fp: 67.0000 - val_loss: 0.5225 - val_acc: 0.6000 - val_precision: 0.5600 - val_recall: 0.9333 - val_tn: 8.0000 - val_fp: 22.0000\n",
            "Epoch 41/500\n",
            "18/18 - 0s - loss: 0.5737 - acc: 0.5278 - precision: 0.5225 - recall: 0.6444 - tn: 37.0000 - fp: 53.0000 - val_loss: 0.5603 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 42/500\n",
            "18/18 - 0s - loss: 0.5192 - acc: 0.6556 - precision: 0.6148 - recall: 0.8333 - tn: 43.0000 - fp: 47.0000 - val_loss: 0.5419 - val_acc: 0.7167 - val_precision: 0.8421 - val_recall: 0.5333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 43/500\n",
            "18/18 - 0s - loss: 0.4854 - acc: 0.7167 - precision: 0.6857 - recall: 0.8000 - tn: 57.0000 - fp: 33.0000 - val_loss: 0.5155 - val_acc: 0.6833 - val_precision: 0.7391 - val_recall: 0.5667 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 44/500\n",
            "18/18 - 0s - loss: 0.4936 - acc: 0.6889 - precision: 0.6545 - recall: 0.8000 - tn: 52.0000 - fp: 38.0000 - val_loss: 0.5318 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 45/500\n",
            "18/18 - 0s - loss: 0.5286 - acc: 0.7500 - precision: 0.7368 - recall: 0.7778 - tn: 65.0000 - fp: 25.0000 - val_loss: 0.5344 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 46/500\n",
            "18/18 - 0s - loss: 0.5076 - acc: 0.7222 - precision: 0.8030 - recall: 0.5889 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5296 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 47/500\n",
            "18/18 - 0s - loss: 0.4709 - acc: 0.7500 - precision: 0.7184 - recall: 0.8222 - tn: 61.0000 - fp: 29.0000 - val_loss: 0.5248 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 48/500\n",
            "18/18 - 0s - loss: 0.4749 - acc: 0.7056 - precision: 0.7284 - recall: 0.6556 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.5148 - val_acc: 0.7333 - val_precision: 0.8889 - val_recall: 0.5333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 49/500\n",
            "18/18 - 0s - loss: 0.5278 - acc: 0.7111 - precision: 0.6557 - recall: 0.8889 - tn: 48.0000 - fp: 42.0000 - val_loss: 0.5499 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 50/500\n",
            "18/18 - 0s - loss: 0.4951 - acc: 0.7556 - precision: 0.7875 - recall: 0.7000 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.6476 - val_acc: 0.5833 - val_precision: 0.5455 - val_recall: 1.0000 - val_tn: 5.0000 - val_fp: 25.0000\n",
            "Epoch 51/500\n",
            "18/18 - 0s - loss: 0.5065 - acc: 0.7222 - precision: 0.7273 - recall: 0.7111 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.5458 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 52/500\n",
            "18/18 - 0s - loss: 0.5171 - acc: 0.7500 - precision: 0.9091 - recall: 0.5556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5298 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 53/500\n",
            "18/18 - 0s - loss: 0.4887 - acc: 0.7444 - precision: 0.7391 - recall: 0.7556 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.5285 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 54/500\n",
            "18/18 - 0s - loss: 0.4835 - acc: 0.7722 - precision: 0.8025 - recall: 0.7222 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5023 - val_acc: 0.7500 - val_precision: 0.8947 - val_recall: 0.5667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 55/500\n",
            "18/18 - 0s - loss: 0.4726 - acc: 0.7500 - precision: 0.7922 - recall: 0.6778 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5112 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 56/500\n",
            "18/18 - 0s - loss: 0.4879 - acc: 0.7611 - precision: 0.7975 - recall: 0.7000 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5270 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 57/500\n",
            "18/18 - 0s - loss: 0.4588 - acc: 0.7444 - precision: 0.7292 - recall: 0.7778 - tn: 64.0000 - fp: 26.0000 - val_loss: 0.5153 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 58/500\n",
            "18/18 - 0s - loss: 0.4610 - acc: 0.7722 - precision: 0.8769 - recall: 0.6333 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5281 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 59/500\n",
            "18/18 - 0s - loss: 0.4667 - acc: 0.7500 - precision: 0.7273 - recall: 0.8000 - tn: 63.0000 - fp: 27.0000 - val_loss: 0.4977 - val_acc: 0.7500 - val_precision: 0.8571 - val_recall: 0.6000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 60/500\n",
            "18/18 - 0s - loss: 0.4461 - acc: 0.7778 - precision: 0.8906 - recall: 0.6333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5278 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 61/500\n",
            "18/18 - 0s - loss: 0.4606 - acc: 0.7833 - precision: 0.7742 - recall: 0.8000 - tn: 69.0000 - fp: 21.0000 - val_loss: 0.4910 - val_acc: 0.7333 - val_precision: 0.8889 - val_recall: 0.5333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 62/500\n",
            "18/18 - 0s - loss: 0.4380 - acc: 0.7722 - precision: 0.9016 - recall: 0.6111 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5239 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 63/500\n",
            "18/18 - 0s - loss: 0.4233 - acc: 0.7778 - precision: 0.8049 - recall: 0.7333 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4993 - val_acc: 0.7167 - val_precision: 0.8824 - val_recall: 0.5000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 64/500\n",
            "18/18 - 0s - loss: 0.4565 - acc: 0.8000 - precision: 0.7755 - recall: 0.8444 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.5194 - val_acc: 0.6833 - val_precision: 0.8667 - val_recall: 0.4333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 65/500\n",
            "18/18 - 0s - loss: 0.4553 - acc: 0.7667 - precision: 0.9615 - recall: 0.5556 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5213 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66/500\n",
            "18/18 - 0s - loss: 0.4286 - acc: 0.7944 - precision: 0.8630 - recall: 0.7000 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5048 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 67/500\n",
            "18/18 - 0s - loss: 0.4181 - acc: 0.8167 - precision: 0.9130 - recall: 0.7000 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4962 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 68/500\n",
            "18/18 - 0s - loss: 0.4466 - acc: 0.8167 - precision: 0.8132 - recall: 0.8222 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.5092 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 69/500\n",
            "18/18 - 0s - loss: 0.4646 - acc: 0.7500 - precision: 0.8082 - recall: 0.6556 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.4993 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 70/500\n",
            "18/18 - 0s - loss: 0.4355 - acc: 0.8000 - precision: 0.9219 - recall: 0.6556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4976 - val_acc: 0.7167 - val_precision: 0.8824 - val_recall: 0.5000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 71/500\n",
            "18/18 - 0s - loss: 0.4391 - acc: 0.8222 - precision: 0.8625 - recall: 0.7667 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5031 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 72/500\n",
            "18/18 - 0s - loss: 0.4012 - acc: 0.8056 - precision: 0.8022 - recall: 0.8111 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4961 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 73/500\n",
            "18/18 - 0s - loss: 0.4588 - acc: 0.8000 - precision: 0.8140 - recall: 0.7778 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5482 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 74/500\n",
            "18/18 - 0s - loss: 0.3895 - acc: 0.8389 - precision: 0.8675 - recall: 0.8000 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5063 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 75/500\n",
            "18/18 - 0s - loss: 0.4070 - acc: 0.8000 - precision: 0.7872 - recall: 0.8222 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.5219 - val_acc: 0.6667 - val_precision: 0.8571 - val_recall: 0.4000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 76/500\n",
            "18/18 - 0s - loss: 0.4545 - acc: 0.7833 - precision: 0.9474 - recall: 0.6000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5020 - val_acc: 0.7000 - val_precision: 0.8750 - val_recall: 0.4667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 77/500\n",
            "18/18 - 0s - loss: 0.3752 - acc: 0.8444 - precision: 0.8690 - recall: 0.8111 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4494 - val_acc: 0.7667 - val_precision: 0.9000 - val_recall: 0.6000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 78/500\n",
            "18/18 - 0s - loss: 0.3787 - acc: 0.8444 - precision: 0.8690 - recall: 0.8111 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5134 - val_acc: 0.6667 - val_precision: 0.8571 - val_recall: 0.4000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 79/500\n",
            "18/18 - 0s - loss: 0.4083 - acc: 0.8500 - precision: 0.8987 - recall: 0.7889 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4930 - val_acc: 0.7167 - val_precision: 0.8824 - val_recall: 0.5000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 80/500\n",
            "18/18 - 0s - loss: 0.3799 - acc: 0.8111 - precision: 0.8182 - recall: 0.8000 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5229 - val_acc: 0.6667 - val_precision: 0.8571 - val_recall: 0.4000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 81/500\n",
            "18/18 - 0s - loss: 0.3617 - acc: 0.8333 - precision: 0.9054 - recall: 0.7444 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4920 - val_acc: 0.7333 - val_precision: 0.8889 - val_recall: 0.5333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 82/500\n",
            "18/18 - 0s - loss: 0.4099 - acc: 0.8056 - precision: 0.8313 - recall: 0.7667 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.5090 - val_acc: 0.6833 - val_precision: 0.8667 - val_recall: 0.4333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 83/500\n",
            "18/18 - 0s - loss: 0.3565 - acc: 0.8167 - precision: 0.8202 - recall: 0.8111 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5004 - val_acc: 0.6833 - val_precision: 0.8667 - val_recall: 0.4333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 84/500\n",
            "18/18 - 0s - loss: 0.4269 - acc: 0.8000 - precision: 0.9219 - recall: 0.6556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5111 - val_acc: 0.6667 - val_precision: 0.8125 - val_recall: 0.4333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 85/500\n",
            "18/18 - 0s - loss: 0.3841 - acc: 0.8278 - precision: 0.8471 - recall: 0.8000 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5281 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 86/500\n",
            "18/18 - 0s - loss: 0.4204 - acc: 0.7944 - precision: 0.8841 - recall: 0.6778 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4586 - val_acc: 0.7500 - val_precision: 0.8571 - val_recall: 0.6000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 87/500\n",
            "18/18 - 0s - loss: 0.4112 - acc: 0.8056 - precision: 0.9508 - recall: 0.6444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4973 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 88/500\n",
            "18/18 - 0s - loss: 0.3980 - acc: 0.8056 - precision: 0.8873 - recall: 0.7000 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4907 - val_acc: 0.7000 - val_precision: 0.8750 - val_recall: 0.4667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 89/500\n",
            "18/18 - 0s - loss: 0.4231 - acc: 0.8167 - precision: 0.8202 - recall: 0.8111 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5025 - val_acc: 0.6833 - val_precision: 0.8667 - val_recall: 0.4333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 90/500\n",
            "18/18 - 0s - loss: 0.4375 - acc: 0.7667 - precision: 1.0000 - recall: 0.5333 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5164 - val_acc: 0.6667 - val_precision: 0.8571 - val_recall: 0.4000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 91/500\n",
            "18/18 - 0s - loss: 0.4369 - acc: 0.7611 - precision: 0.8052 - recall: 0.6889 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.5199 - val_acc: 0.6500 - val_precision: 0.8000 - val_recall: 0.4000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 92/500\n",
            "18/18 - 0s - loss: 0.4569 - acc: 0.7778 - precision: 0.9808 - recall: 0.5667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5163 - val_acc: 0.6833 - val_precision: 0.8235 - val_recall: 0.4667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 93/500\n",
            "18/18 - 0s - loss: 0.4069 - acc: 0.8500 - precision: 0.8706 - recall: 0.8222 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4612 - val_acc: 0.7500 - val_precision: 0.8571 - val_recall: 0.6000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 94/500\n",
            "18/18 - 0s - loss: 0.3922 - acc: 0.7944 - precision: 0.8841 - recall: 0.6778 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4938 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 95/500\n",
            "18/18 - 0s - loss: 0.4094 - acc: 0.7722 - precision: 0.7816 - recall: 0.7556 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.4701 - val_acc: 0.7333 - val_precision: 0.8500 - val_recall: 0.5667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 96/500\n",
            "18/18 - 0s - loss: 0.3481 - acc: 0.8667 - precision: 0.9342 - recall: 0.7889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4560 - val_acc: 0.7500 - val_precision: 0.8571 - val_recall: 0.6000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 97/500\n",
            "18/18 - 0s - loss: 0.3669 - acc: 0.8444 - precision: 0.8974 - recall: 0.7778 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4184 - val_acc: 0.7833 - val_precision: 0.8696 - val_recall: 0.6667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 98/500\n",
            "18/18 - 0s - loss: 0.3608 - acc: 0.8556 - precision: 0.8810 - recall: 0.8222 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4627 - val_acc: 0.7500 - val_precision: 0.8947 - val_recall: 0.5667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 99/500\n",
            "18/18 - 0s - loss: 0.3051 - acc: 0.8778 - precision: 0.8617 - recall: 0.9000 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.4966 - val_acc: 0.6833 - val_precision: 0.8667 - val_recall: 0.4333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 100/500\n",
            "18/18 - 0s - loss: 0.3405 - acc: 0.8667 - precision: 0.9583 - recall: 0.7667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4762 - val_acc: 0.7333 - val_precision: 0.8889 - val_recall: 0.5333 - val_tn: 28.0000 - val_fp: 2.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 101/500\n",
            "18/18 - 0s - loss: 0.3864 - acc: 0.8278 - precision: 0.8172 - recall: 0.8444 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.5125 - val_acc: 0.6667 - val_precision: 0.8571 - val_recall: 0.4000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 102/500\n",
            "18/18 - 0s - loss: 0.4442 - acc: 0.7556 - precision: 0.9259 - recall: 0.5556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5268 - val_acc: 0.6667 - val_precision: 0.8571 - val_recall: 0.4000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 103/500\n",
            "18/18 - 0s - loss: 0.3602 - acc: 0.8611 - precision: 0.9452 - recall: 0.7667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4879 - val_acc: 0.7167 - val_precision: 0.8421 - val_recall: 0.5333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 104/500\n",
            "18/18 - 0s - loss: 0.3329 - acc: 0.8778 - precision: 0.9048 - recall: 0.8444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4769 - val_acc: 0.7333 - val_precision: 0.8889 - val_recall: 0.5333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 105/500\n",
            "18/18 - 0s - loss: 0.3559 - acc: 0.8389 - precision: 0.9067 - recall: 0.7556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5374 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 106/500\n",
            "18/18 - 0s - loss: 0.3635 - acc: 0.8444 - precision: 0.9189 - recall: 0.7556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3889 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 107/500\n",
            "18/18 - 0s - loss: 0.3155 - acc: 0.8833 - precision: 0.9481 - recall: 0.8111 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5037 - val_acc: 0.6833 - val_precision: 0.8667 - val_recall: 0.4333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 108/500\n",
            "18/18 - 0s - loss: 0.3208 - acc: 0.8778 - precision: 0.8778 - recall: 0.8778 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4840 - val_acc: 0.7000 - val_precision: 0.8750 - val_recall: 0.4667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 109/500\n",
            "18/18 - 0s - loss: 0.3395 - acc: 0.8389 - precision: 0.9692 - recall: 0.7000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4731 - val_acc: 0.7000 - val_precision: 0.8750 - val_recall: 0.4667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 110/500\n",
            "18/18 - 0s - loss: 0.3254 - acc: 0.8611 - precision: 0.8571 - recall: 0.8667 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.7995 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 111/500\n",
            "18/18 - 0s - loss: 0.3710 - acc: 0.8611 - precision: 0.9333 - recall: 0.7778 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4532 - val_acc: 0.7333 - val_precision: 0.8500 - val_recall: 0.5667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 112/500\n",
            "18/18 - 0s - loss: 0.2968 - acc: 0.8944 - precision: 0.9494 - recall: 0.8333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4293 - val_acc: 0.8000 - val_precision: 0.8214 - val_recall: 0.7667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 113/500\n",
            "18/18 - 0s - loss: 0.3344 - acc: 0.8722 - precision: 0.9467 - recall: 0.7889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4961 - val_acc: 0.6833 - val_precision: 0.8235 - val_recall: 0.4667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 114/500\n",
            "18/18 - 0s - loss: 0.4034 - acc: 0.8389 - precision: 0.8675 - recall: 0.8000 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4985 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 115/500\n",
            "18/18 - 0s - loss: 0.3404 - acc: 0.8500 - precision: 0.9565 - recall: 0.7333 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4667 - val_acc: 0.7500 - val_precision: 0.8947 - val_recall: 0.5667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 116/500\n",
            "18/18 - 0s - loss: 0.3080 - acc: 0.8889 - precision: 0.8804 - recall: 0.9000 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4630 - val_acc: 0.7000 - val_precision: 0.8750 - val_recall: 0.4667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 117/500\n",
            "18/18 - 0s - loss: 0.3029 - acc: 0.8778 - precision: 0.8864 - recall: 0.8667 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3630 - val_acc: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 118/500\n",
            "18/18 - 0s - loss: 0.3331 - acc: 0.8722 - precision: 0.9136 - recall: 0.8222 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4683 - val_acc: 0.7167 - val_precision: 0.8824 - val_recall: 0.5000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 119/500\n",
            "18/18 - 0s - loss: 0.3784 - acc: 0.8500 - precision: 0.8987 - recall: 0.7889 - tn: 82.0000 - fp: 8.0000 - val_loss: 1.1181 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 120/500\n",
            "18/18 - 0s - loss: 0.2787 - acc: 0.8944 - precision: 0.9610 - recall: 0.8222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4164 - val_acc: 0.7500 - val_precision: 0.8947 - val_recall: 0.5667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 121/500\n",
            "18/18 - 0s - loss: 0.3550 - acc: 0.8667 - precision: 0.9024 - recall: 0.8222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4530 - val_acc: 0.7333 - val_precision: 0.6522 - val_recall: 1.0000 - val_tn: 14.0000 - val_fp: 16.0000\n",
            "Epoch 122/500\n",
            "18/18 - 0s - loss: 0.3024 - acc: 0.8889 - precision: 0.8723 - recall: 0.9111 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.6842 - val_acc: 0.7500 - val_precision: 0.8947 - val_recall: 0.5667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 123/500\n",
            "18/18 - 0s - loss: 0.2752 - acc: 0.9389 - precision: 0.9341 - recall: 0.9444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3340 - val_acc: 0.9167 - val_precision: 0.9310 - val_recall: 0.9000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 124/500\n",
            "18/18 - 0s - loss: 0.3886 - acc: 0.8389 - precision: 0.8675 - recall: 0.8000 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.3319 - val_acc: 0.9000 - val_precision: 0.9286 - val_recall: 0.8667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 125/500\n",
            "18/18 - 0s - loss: 0.3089 - acc: 0.9000 - precision: 0.9286 - recall: 0.8667 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3075 - val_acc: 0.9167 - val_precision: 0.9310 - val_recall: 0.9000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 126/500\n",
            "18/18 - 0s - loss: 0.3028 - acc: 0.8944 - precision: 0.9494 - recall: 0.8333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.8709 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 127/500\n",
            "18/18 - 0s - loss: 0.2966 - acc: 0.8667 - precision: 0.9024 - recall: 0.8222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.8849 - val_acc: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 128/500\n",
            "18/18 - 0s - loss: 0.3070 - acc: 0.8778 - precision: 0.8617 - recall: 0.9000 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.2809 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 129/500\n",
            "18/18 - 0s - loss: 0.3387 - acc: 0.8333 - precision: 0.9167 - recall: 0.7333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5808 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 130/500\n",
            "18/18 - 0s - loss: 0.3712 - acc: 0.8222 - precision: 0.8718 - recall: 0.7556 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5340 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 131/500\n",
            "18/18 - 0s - loss: 0.2523 - acc: 0.9056 - precision: 0.9506 - recall: 0.8556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4036 - val_acc: 0.8167 - val_precision: 1.0000 - val_recall: 0.6333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 132/500\n",
            "18/18 - 0s - loss: 0.2597 - acc: 0.9333 - precision: 0.9535 - recall: 0.9111 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2912 - val_acc: 0.9167 - val_precision: 0.9310 - val_recall: 0.9000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 133/500\n",
            "18/18 - 0s - loss: 0.2346 - acc: 0.9222 - precision: 0.9634 - recall: 0.8778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2622 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 134/500\n",
            "18/18 - 0s - loss: 0.3385 - acc: 0.8667 - precision: 0.8929 - recall: 0.8333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5307 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 135/500\n",
            "18/18 - 0s - loss: 0.3306 - acc: 0.8611 - precision: 0.9114 - recall: 0.8000 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5520 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 136/500\n",
            "18/18 - 0s - loss: 0.2831 - acc: 0.8944 - precision: 0.9176 - recall: 0.8667 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5257 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 137/500\n",
            "18/18 - 0s - loss: 0.2371 - acc: 0.9278 - precision: 0.9639 - recall: 0.8889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.3359 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 138/500\n",
            "18/18 - 0s - loss: 0.3433 - acc: 0.8944 - precision: 0.9080 - recall: 0.8778 - tn: 82.0000 - fp: 8.0000 - val_loss: 1.0701 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 139/500\n",
            "18/18 - 0s - loss: 0.2814 - acc: 0.9000 - precision: 0.9091 - recall: 0.8889 - tn: 82.0000 - fp: 8.0000 - val_loss: 1.0459 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 140/500\n",
            "18/18 - 0s - loss: 0.2440 - acc: 0.9333 - precision: 0.9432 - recall: 0.9222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2831 - val_acc: 0.8833 - val_precision: 0.8286 - val_recall: 0.9667 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 141/500\n",
            "18/18 - 0s - loss: 0.2544 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3589 - val_acc: 0.8500 - val_precision: 1.0000 - val_recall: 0.7000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 142/500\n",
            "18/18 - 0s - loss: 0.2287 - acc: 0.9333 - precision: 0.9756 - recall: 0.8889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3583 - val_acc: 0.7833 - val_precision: 0.6977 - val_recall: 1.0000 - val_tn: 17.0000 - val_fp: 13.0000\n",
            "Epoch 143/500\n",
            "18/18 - 0s - loss: 0.3076 - acc: 0.8778 - precision: 0.8953 - recall: 0.8556 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2648 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 144/500\n",
            "18/18 - 0s - loss: 0.3081 - acc: 0.8667 - precision: 0.9024 - recall: 0.8222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.2613 - val_acc: 0.9500 - val_precision: 0.9355 - val_recall: 0.9667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 145/500\n",
            "18/18 - 0s - loss: 0.2530 - acc: 0.9000 - precision: 0.9186 - recall: 0.8778 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2594 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 146/500\n",
            "18/18 - 0s - loss: 0.2120 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2315 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 147/500\n",
            "18/18 - 0s - loss: 0.1729 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2880 - val_acc: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 148/500\n",
            "18/18 - 0s - loss: 0.1966 - acc: 0.9444 - precision: 0.9651 - recall: 0.9222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2942 - val_acc: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 149/500\n",
            "18/18 - 0s - loss: 0.2866 - acc: 0.9167 - precision: 0.9032 - recall: 0.9333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2464 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 150/500\n",
            "18/18 - 0s - loss: 0.2430 - acc: 0.9167 - precision: 0.9412 - recall: 0.8889 - tn: 85.0000 - fp: 5.0000 - val_loss: 2.9894 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 151/500\n",
            "18/18 - 0s - loss: 0.2038 - acc: 0.9444 - precision: 0.9444 - recall: 0.9444 - tn: 85.0000 - fp: 5.0000 - val_loss: 1.0159 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 152/500\n",
            "18/18 - 0s - loss: 0.2420 - acc: 0.9278 - precision: 0.9529 - recall: 0.9000 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2944 - val_acc: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 153/500\n",
            "18/18 - 0s - loss: 0.2068 - acc: 0.9278 - precision: 0.9053 - recall: 0.9556 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2329 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 154/500\n",
            "18/18 - 0s - loss: 0.1887 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.7684 - val_acc: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 155/500\n",
            "18/18 - 0s - loss: 0.1990 - acc: 0.9444 - precision: 0.9348 - recall: 0.9556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2665 - val_acc: 0.8667 - val_precision: 0.8056 - val_recall: 0.9667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 156/500\n",
            "18/18 - 0s - loss: 0.2511 - acc: 0.9056 - precision: 0.9294 - recall: 0.8778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4098 - val_acc: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 157/500\n",
            "18/18 - 0s - loss: 0.2448 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 2.6155 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 158/500\n",
            "18/18 - 0s - loss: 0.3151 - acc: 0.8778 - precision: 0.8864 - recall: 0.8667 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3207 - val_acc: 0.8500 - val_precision: 1.0000 - val_recall: 0.7000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 159/500\n",
            "18/18 - 0s - loss: 0.3409 - acc: 0.8667 - precision: 0.8929 - recall: 0.8333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2595 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 160/500\n",
            "18/18 - 0s - loss: 0.2061 - acc: 0.9333 - precision: 1.0000 - recall: 0.8667 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.1917 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 161/500\n",
            "18/18 - 0s - loss: 0.1800 - acc: 0.9556 - precision: 0.9457 - recall: 0.9667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1812 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 162/500\n",
            "18/18 - 0s - loss: 0.1752 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2488 - val_acc: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 163/500\n",
            "18/18 - 0s - loss: 0.2019 - acc: 0.9333 - precision: 0.9333 - recall: 0.9333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.1866 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 164/500\n",
            "18/18 - 0s - loss: 0.1672 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1648 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 165/500\n",
            "18/18 - 0s - loss: 0.3256 - acc: 0.8611 - precision: 0.9114 - recall: 0.8000 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5112 - val_acc: 0.7333 - val_precision: 0.6522 - val_recall: 1.0000 - val_tn: 14.0000 - val_fp: 16.0000\n",
            "Epoch 166/500\n",
            "18/18 - 0s - loss: 0.2652 - acc: 0.8833 - precision: 0.8966 - recall: 0.8667 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2236 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 167/500\n",
            "18/18 - 0s - loss: 0.2004 - acc: 0.9389 - precision: 0.9247 - recall: 0.9556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2213 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 168/500\n",
            "18/18 - 0s - loss: 0.1820 - acc: 0.9611 - precision: 0.9770 - recall: 0.9444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2407 - val_acc: 0.8500 - val_precision: 0.7838 - val_recall: 0.9667 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 169/500\n",
            "18/18 - 0s - loss: 0.1623 - acc: 0.9556 - precision: 0.9659 - recall: 0.9444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1876 - val_acc: 0.9667 - val_precision: 0.9667 - val_recall: 0.9667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 170/500\n",
            "18/18 - 0s - loss: 0.1372 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1634 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 171/500\n",
            "18/18 - 0s - loss: 0.1348 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2048 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 172/500\n",
            "18/18 - 0s - loss: 0.1794 - acc: 0.9444 - precision: 0.9444 - recall: 0.9444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2057 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 173/500\n",
            "18/18 - 0s - loss: 0.1492 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1401 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 174/500\n",
            "18/18 - 0s - loss: 0.1379 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1447 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 175/500\n",
            "18/18 - 0s - loss: 0.2133 - acc: 0.9389 - precision: 0.9341 - recall: 0.9444 - tn: 84.0000 - fp: 6.0000 - val_loss: 1.3528 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 176/500\n",
            "18/18 - 0s - loss: 0.1541 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1419 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 177/500\n",
            "18/18 - 0s - loss: 0.1587 - acc: 0.9444 - precision: 0.9444 - recall: 0.9444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1727 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 178/500\n",
            "18/18 - 0s - loss: 0.1594 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1465 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 179/500\n",
            "18/18 - 0s - loss: 0.1611 - acc: 0.9444 - precision: 0.9444 - recall: 0.9444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1418 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 180/500\n",
            "18/18 - 0s - loss: 0.1199 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1759 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 181/500\n",
            "18/18 - 0s - loss: 0.1424 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1373 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 182/500\n",
            "18/18 - 0s - loss: 0.0967 - acc: 0.9944 - precision: 1.0000 - recall: 0.9889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.1462 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 183/500\n",
            "18/18 - 0s - loss: 0.1431 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1170 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 184/500\n",
            "18/18 - 0s - loss: 0.1180 - acc: 0.9667 - precision: 0.9565 - recall: 0.9778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1060 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 185/500\n",
            "18/18 - 0s - loss: 0.1460 - acc: 0.9611 - precision: 0.9770 - recall: 0.9444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1571 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 186/500\n",
            "18/18 - 0s - loss: 0.1079 - acc: 0.9778 - precision: 1.0000 - recall: 0.9556 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.4658 - val_acc: 0.9000 - val_precision: 0.8529 - val_recall: 0.9667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 187/500\n",
            "18/18 - 0s - loss: 0.1596 - acc: 0.9556 - precision: 0.9457 - recall: 0.9667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1530 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 188/500\n",
            "18/18 - 0s - loss: 0.1643 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1943 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 189/500\n",
            "18/18 - 0s - loss: 0.0985 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1248 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 190/500\n",
            "18/18 - 0s - loss: 0.0987 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1413 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 191/500\n",
            "18/18 - 0s - loss: 0.0866 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1557 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 192/500\n",
            "18/18 - 0s - loss: 0.0642 - acc: 0.9889 - precision: 1.0000 - recall: 0.9778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0916 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 193/500\n",
            "18/18 - 0s - loss: 0.0573 - acc: 0.9944 - precision: 0.9890 - recall: 1.0000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1516 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 194/500\n",
            "18/18 - 0s - loss: 0.0702 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4889 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 195/500\n",
            "18/18 - 0s - loss: 0.1940 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1307 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 196/500\n",
            "18/18 - 0s - loss: 0.1131 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0670 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 197/500\n",
            "18/18 - 0s - loss: 0.1501 - acc: 0.9444 - precision: 0.9762 - recall: 0.9111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.8664 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 198/500\n",
            "18/18 - 0s - loss: 0.1563 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1746 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 199/500\n",
            "18/18 - 0s - loss: 0.0498 - acc: 0.9944 - precision: 1.0000 - recall: 0.9889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.2276 - val_acc: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 200/500\n",
            "18/18 - 0s - loss: 0.2347 - acc: 0.9000 - precision: 0.9390 - recall: 0.8556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.0836 - val_acc: 0.9500 - val_precision: 0.9655 - val_recall: 0.9333 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 201/500\n",
            "18/18 - 0s - loss: 0.1032 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4882 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 202/500\n",
            "18/18 - 0s - loss: 0.1526 - acc: 0.9389 - precision: 0.9540 - recall: 0.9222 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2128 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 203/500\n",
            "18/18 - 0s - loss: 0.0978 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0952 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 204/500\n",
            "18/18 - 0s - loss: 0.0625 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0716 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 205/500\n",
            "18/18 - 0s - loss: 0.0607 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4397 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 206/500\n",
            "18/18 - 0s - loss: 0.0763 - acc: 0.9722 - precision: 0.9885 - recall: 0.9556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1349 - val_acc: 0.9667 - val_precision: 0.9667 - val_recall: 0.9667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 207/500\n",
            "18/18 - 0s - loss: 0.0439 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1046 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 208/500\n",
            "18/18 - 0s - loss: 0.0503 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0708 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 209/500\n",
            "18/18 - 0s - loss: 0.0648 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1103 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 210/500\n",
            "18/18 - 0s - loss: 0.0601 - acc: 0.9722 - precision: 0.9885 - recall: 0.9556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0570 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 211/500\n",
            "18/18 - 0s - loss: 0.0540 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 1.3070 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 212/500\n",
            "18/18 - 0s - loss: 0.1257 - acc: 0.9722 - precision: 0.9885 - recall: 0.9556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0666 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 213/500\n",
            "18/18 - 0s - loss: 0.0337 - acc: 0.9944 - precision: 0.9890 - recall: 1.0000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1342 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 214/500\n",
            "18/18 - 0s - loss: 0.0784 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 1.4916 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 215/500\n",
            "18/18 - 0s - loss: 0.1100 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 1.1762 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 216/500\n",
            "18/18 - 0s - loss: 0.0948 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1607 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 217/500\n",
            "18/18 - 0s - loss: 0.1024 - acc: 0.9667 - precision: 0.9565 - recall: 0.9778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0469 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 218/500\n",
            "18/18 - 0s - loss: 0.1264 - acc: 0.9500 - precision: 0.9655 - recall: 0.9333 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4028 - val_acc: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 219/500\n",
            "18/18 - 0s - loss: 0.0390 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 1.0830 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 220/500\n",
            "18/18 - 0s - loss: 0.1046 - acc: 0.9667 - precision: 0.9884 - recall: 0.9444 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0518 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 221/500\n",
            "18/18 - 0s - loss: 0.0483 - acc: 0.9722 - precision: 0.9570 - recall: 0.9889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1390 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 222/500\n",
            "18/18 - 0s - loss: 0.1064 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0402 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 223/500\n",
            "18/18 - 0s - loss: 0.1184 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2113 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 224/500\n",
            "18/18 - 0s - loss: 0.0770 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0838 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 225/500\n",
            "18/18 - 0s - loss: 0.0481 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0394 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 226/500\n",
            "18/18 - 0s - loss: 0.0890 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0404 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 227/500\n",
            "18/18 - 0s - loss: 0.0481 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2251 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 228/500\n",
            "18/18 - 0s - loss: 0.1121 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0431 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 229/500\n",
            "18/18 - 0s - loss: 0.0418 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1170 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 230/500\n",
            "18/18 - 0s - loss: 0.0338 - acc: 0.9944 - precision: 1.0000 - recall: 0.9889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0664 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 231/500\n",
            "18/18 - 0s - loss: 0.0614 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2294 - val_acc: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 232/500\n",
            "18/18 - 0s - loss: 0.0522 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0362 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 233/500\n",
            "18/18 - 0s - loss: 0.1053 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0337 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 234/500\n",
            "18/18 - 0s - loss: 0.0456 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 1.3388 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 235/500\n",
            "18/18 - 0s - loss: 0.0522 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 2.2832 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 236/500\n",
            "18/18 - 0s - loss: 0.0978 - acc: 0.9611 - precision: 0.9462 - recall: 0.9778 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.6190 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 237/500\n",
            "18/18 - 0s - loss: 0.0703 - acc: 0.9778 - precision: 1.0000 - recall: 0.9556 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0753 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 238/500\n",
            "18/18 - 0s - loss: 0.0480 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0554 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 239/500\n",
            "18/18 - 0s - loss: 0.0328 - acc: 0.9889 - precision: 1.0000 - recall: 0.9778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.2020 - val_acc: 0.8833 - val_precision: 0.8108 - val_recall: 1.0000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 240/500\n",
            "18/18 - 0s - loss: 0.0675 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.8591 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 241/500\n",
            "18/18 - 0s - loss: 0.0421 - acc: 0.9833 - precision: 1.0000 - recall: 0.9667 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.4400 - val_acc: 0.8667 - val_precision: 0.8056 - val_recall: 0.9667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 242/500\n",
            "18/18 - 0s - loss: 0.0425 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0293 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 243/500\n",
            "18/18 - 0s - loss: 0.0889 - acc: 0.9722 - precision: 0.9885 - recall: 0.9556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0691 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 244/500\n",
            "18/18 - 0s - loss: 0.1039 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2204 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 245/500\n",
            "18/18 - 0s - loss: 0.0412 - acc: 0.9944 - precision: 0.9890 - recall: 1.0000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0345 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 246/500\n",
            "18/18 - 0s - loss: 0.0731 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0940 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 247/500\n",
            "18/18 - 0s - loss: 0.0859 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1982 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 248/500\n",
            "18/18 - 0s - loss: 0.0268 - acc: 0.9889 - precision: 1.0000 - recall: 0.9778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6268 - val_acc: 0.9000 - val_precision: 0.8529 - val_recall: 0.9667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 249/500\n",
            "18/18 - 0s - loss: 0.0737 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.8896 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 250/500\n",
            "18/18 - 0s - loss: 0.0824 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.6054 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 251/500\n",
            "18/18 - 0s - loss: 0.0466 - acc: 0.9833 - precision: 0.9677 - recall: 1.0000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5018 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 252/500\n",
            "18/18 - 0s - loss: 0.0849 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4920 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 253/500\n",
            "18/18 - 0s - loss: 0.0562 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.8764 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 254/500\n",
            "18/18 - 0s - loss: 0.0432 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3749 - val_acc: 0.9667 - val_precision: 0.9667 - val_recall: 0.9667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 255/500\n",
            "18/18 - 0s - loss: 0.0179 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0402 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 256/500\n",
            "18/18 - 0s - loss: 0.0480 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0776 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 257/500\n",
            "18/18 - 0s - loss: 0.0794 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0987 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 258/500\n",
            "18/18 - 0s - loss: 0.0154 - acc: 0.9944 - precision: 1.0000 - recall: 0.9889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0609 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 259/500\n",
            "18/18 - 0s - loss: 0.0204 - acc: 0.9944 - precision: 0.9890 - recall: 1.0000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0331 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 260/500\n",
            "18/18 - 0s - loss: 0.0112 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0319 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 261/500\n",
            "18/18 - 0s - loss: 0.0942 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 1.6123 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 262/500\n",
            "18/18 - 0s - loss: 0.0584 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 1.1089 - val_acc: 0.9667 - val_precision: 0.9667 - val_recall: 0.9667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 263/500\n",
            "18/18 - 0s - loss: 0.0313 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4675 - val_acc: 0.9667 - val_precision: 0.9667 - val_recall: 0.9667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 264/500\n",
            "18/18 - 0s - loss: 0.0308 - acc: 0.9944 - precision: 1.0000 - recall: 0.9889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.9833 - val_precision: 0.9677 - val_recall: 1.0000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 265/500\n",
            "18/18 - 0s - loss: 0.0328 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4495 - val_acc: 0.9667 - val_precision: 0.9667 - val_recall: 0.9667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 266/500\n",
            "18/18 - 0s - loss: 0.0159 - acc: 0.9944 - precision: 1.0000 - recall: 0.9889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 1.2676 - val_acc: 0.9667 - val_precision: 0.9667 - val_recall: 0.9667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 267/500\n",
            "18/18 - 0s - loss: 0.0318 - acc: 0.9889 - precision: 0.9783 - recall: 1.0000 - tn: 88.0000 - fp: 2.0000 - val_loss: 1.3931 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0293 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.0000 - fp: 0.0000e+00    \n",
            "loss:\n",
            "[0.02932114340364933, 1.0, 1.0, 1.0, 30.0, 0.0]\n",
            "['loss', 'acc', 'precision', 'recall', 'tn', 'fp']\n",
            "Training and evaluating on fold 2 out of 8...\n",
            "train_index[  1   4   5   6   7   8   9  10  11  12  15  16  17  18  19  20  21  22\n",
            "  23  24  25  26  27  30  31  34  35  36  37  38  41  42  43  45  46  47\n",
            "  48  49  50  53  54  55  56  57  59  60  61  62  64  65  67  68  70  71\n",
            "  73  74  75  77  78  79  80  82  83  84  85  86  87  89  90  91  93  95\n",
            "  96  97 100 101 102 103 104 105 106 107 108 111 112 113 114 117 118 119\n",
            " 122 123 124 126 127 128 129 130 132 133 135 136 137 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 159 160 161 162\n",
            " 164 166 167 168 170 172 174 175 176 177 178 179 180 181 182 183 185 186\n",
            " 188 190 191 192 193 194 195 197 198 199 200 201 203 204 205 206 207 208\n",
            " 211 212 213 214 216 219 220 221 223 224 226 227 231 232 233 235 236 237]\n",
            "test_index[  0   2   3  13  14  28  29  32  33  39  40  44  51  52  58  63  66  69\n",
            "  72  76  81  88  92  94  98  99 109 110 115 116 120 121 125 131 134 138\n",
            " 158 163 165 169 171 173 184 187 189 196 202 209 210 215 217 218 222 225\n",
            " 228 229 230 234 238 239]\n",
            "Epoch 1/500\n",
            "18/18 - 2s - loss: 0.7181 - acc: 0.4444 - precision: 0.4706 - recall: 0.8889 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6992 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 2/500\n",
            "18/18 - 0s - loss: 0.7032 - acc: 0.4389 - precision: 0.4675 - recall: 0.8778 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/500\n",
            "18/18 - 0s - loss: 0.6968 - acc: 0.2278 - precision: 0.0196 - recall: 0.0111 - tn: 40.0000 - fp: 50.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 4/500\n",
            "18/18 - 0s - loss: 0.6940 - acc: 0.5222 - precision: 0.5833 - recall: 0.1556 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.6939 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 5/500\n",
            "18/18 - 0s - loss: 0.6964 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6949 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 6/500\n",
            "18/18 - 0s - loss: 0.6970 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6943 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 7/500\n",
            "18/18 - 0s - loss: 0.6944 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6937 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 8/500\n",
            "18/18 - 0s - loss: 0.6964 - acc: 0.4167 - precision: 0.4436 - recall: 0.6556 - tn: 16.0000 - fp: 74.0000 - val_loss: 0.6931 - val_acc: 0.5167 - val_precision: 1.0000 - val_recall: 0.0333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 9/500\n",
            "18/18 - 0s - loss: 0.6941 - acc: 0.2889 - precision: 0.3061 - recall: 0.3333 - tn: 22.0000 - fp: 68.0000 - val_loss: 0.6930 - val_acc: 0.5333 - val_precision: 0.6667 - val_recall: 0.1333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 10/500\n",
            "18/18 - 0s - loss: 0.6947 - acc: 0.4944 - precision: 0.3333 - recall: 0.0111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.6929 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 11/500\n",
            "18/18 - 0s - loss: 0.6956 - acc: 0.4667 - precision: 0.4808 - recall: 0.8333 - tn: 9.0000 - fp: 81.0000 - val_loss: 0.6928 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 12/500\n",
            "18/18 - 0s - loss: 0.6937 - acc: 0.4222 - precision: 0.2083 - recall: 0.0556 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.6929 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 13/500\n",
            "18/18 - 0s - loss: 0.6922 - acc: 0.4778 - precision: 0.4000 - recall: 0.0889 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.6929 - val_acc: 0.5167 - val_precision: 1.0000 - val_recall: 0.0333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 14/500\n",
            "18/18 - 0s - loss: 0.6899 - acc: 0.5556 - precision: 1.0000 - recall: 0.1111 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6927 - val_acc: 0.5333 - val_precision: 1.0000 - val_recall: 0.0667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 15/500\n",
            "18/18 - 0s - loss: 0.6890 - acc: 0.5056 - precision: 0.5263 - recall: 0.1111 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.6894 - val_acc: 0.5833 - val_precision: 0.7778 - val_recall: 0.2333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 16/500\n",
            "18/18 - 0s - loss: 0.6890 - acc: 0.4722 - precision: 0.4138 - recall: 0.1333 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.6913 - val_acc: 0.5167 - val_precision: 1.0000 - val_recall: 0.0333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 17/500\n",
            "18/18 - 0s - loss: 0.6760 - acc: 0.4556 - precision: 0.4565 - recall: 0.4667 - tn: 40.0000 - fp: 50.0000 - val_loss: 0.6805 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 18/500\n",
            "18/18 - 0s - loss: 0.6537 - acc: 0.5778 - precision: 0.6458 - recall: 0.3444 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.6537 - val_acc: 0.5833 - val_precision: 0.6316 - val_recall: 0.4000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 19/500\n",
            "18/18 - 0s - loss: 0.6512 - acc: 0.5444 - precision: 0.5556 - recall: 0.4444 - tn: 58.0000 - fp: 32.0000 - val_loss: 0.6350 - val_acc: 0.6000 - val_precision: 0.6500 - val_recall: 0.4333 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 20/500\n",
            "18/18 - 0s - loss: 0.6341 - acc: 0.5944 - precision: 0.6604 - recall: 0.3889 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.6461 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 21/500\n",
            "18/18 - 0s - loss: 0.6387 - acc: 0.5833 - precision: 0.7273 - recall: 0.2667 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.6308 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 22/500\n",
            "18/18 - 0s - loss: 0.6103 - acc: 0.6111 - precision: 0.6667 - recall: 0.4444 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.6252 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 23/500\n",
            "18/18 - 0s - loss: 0.6329 - acc: 0.5944 - precision: 0.8696 - recall: 0.2222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.6439 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 24/500\n",
            "18/18 - 0s - loss: 0.6047 - acc: 0.6444 - precision: 0.7955 - recall: 0.3889 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.6178 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 25/500\n",
            "18/18 - 0s - loss: 0.6186 - acc: 0.6389 - precision: 1.0000 - recall: 0.2778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6189 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 26/500\n",
            "18/18 - 0s - loss: 0.6127 - acc: 0.6389 - precision: 0.8788 - recall: 0.3222 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5968 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 27/500\n",
            "18/18 - 0s - loss: 0.5934 - acc: 0.6556 - precision: 0.7917 - recall: 0.4222 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5960 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 28/500\n",
            "18/18 - 0s - loss: 0.6070 - acc: 0.6833 - precision: 0.8367 - recall: 0.4556 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.6100 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 29/500\n",
            "18/18 - 0s - loss: 0.6092 - acc: 0.6444 - precision: 0.9643 - recall: 0.3000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6120 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 30/500\n",
            "18/18 - 0s - loss: 0.5924 - acc: 0.5722 - precision: 0.5802 - recall: 0.5222 - tn: 56.0000 - fp: 34.0000 - val_loss: 0.5815 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 31/500\n",
            "18/18 - 0s - loss: 0.5788 - acc: 0.6778 - precision: 0.9000 - recall: 0.4000 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5976 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 32/500\n",
            "18/18 - 0s - loss: 0.5646 - acc: 0.6833 - precision: 0.9231 - recall: 0.4000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5661 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 33/500\n",
            "18/18 - 0s - loss: 0.5901 - acc: 0.6611 - precision: 0.7959 - recall: 0.4333 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.6105 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 34/500\n",
            "18/18 - 0s - loss: 0.5782 - acc: 0.6778 - precision: 0.9706 - recall: 0.3667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5944 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 35/500\n",
            "18/18 - 0s - loss: 0.5635 - acc: 0.6722 - precision: 0.9429 - recall: 0.3667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5848 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 36/500\n",
            "18/18 - 0s - loss: 0.5698 - acc: 0.6889 - precision: 0.8696 - recall: 0.4444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5656 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 37/500\n",
            "18/18 - 0s - loss: 0.5573 - acc: 0.6778 - precision: 0.8636 - recall: 0.4222 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5874 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38/500\n",
            "18/18 - 0s - loss: 0.5633 - acc: 0.6833 - precision: 0.8837 - recall: 0.4222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5854 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 39/500\n",
            "18/18 - 0s - loss: 0.5429 - acc: 0.6944 - precision: 0.9268 - recall: 0.4222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5817 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 40/500\n",
            "18/18 - 0s - loss: 0.5489 - acc: 0.6944 - precision: 0.9268 - recall: 0.4222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5697 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 41/500\n",
            "18/18 - 0s - loss: 0.5522 - acc: 0.6778 - precision: 0.8636 - recall: 0.4222 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5662 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 42/500\n",
            "18/18 - 0s - loss: 0.5189 - acc: 0.7167 - precision: 0.9333 - recall: 0.4667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5756 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 43/500\n",
            "18/18 - 0s - loss: 0.5721 - acc: 0.6944 - precision: 0.8889 - recall: 0.4444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5704 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 44/500\n",
            "18/18 - 0s - loss: 0.5727 - acc: 0.6778 - precision: 1.0000 - recall: 0.3556 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5803 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 45/500\n",
            "18/18 - 0s - loss: 0.5469 - acc: 0.6667 - precision: 0.9167 - recall: 0.3667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5420 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 46/500\n",
            "18/18 - 0s - loss: 0.5345 - acc: 0.6778 - precision: 0.8200 - recall: 0.4556 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5620 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 47/500\n",
            "18/18 - 0s - loss: 0.5224 - acc: 0.7056 - precision: 0.9512 - recall: 0.4333 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5528 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 48/500\n",
            "18/18 - 0s - loss: 0.5100 - acc: 0.6944 - precision: 0.8070 - recall: 0.5111 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5567 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 49/500\n",
            "18/18 - 0s - loss: 0.5070 - acc: 0.7111 - precision: 0.9318 - recall: 0.4556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5412 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 50/500\n",
            "18/18 - 0s - loss: 0.5624 - acc: 0.6944 - precision: 0.9070 - recall: 0.4333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5635 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 51/500\n",
            "18/18 - 0s - loss: 0.4678 - acc: 0.7556 - precision: 0.9600 - recall: 0.5333 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5302 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 52/500\n",
            "18/18 - 0s - loss: 0.6270 - acc: 0.5833 - precision: 0.5652 - recall: 0.7222 - tn: 40.0000 - fp: 50.0000 - val_loss: 0.5714 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 53/500\n",
            "18/18 - 0s - loss: 0.5365 - acc: 0.6944 - precision: 1.0000 - recall: 0.3889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5839 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 54/500\n",
            "18/18 - 0s - loss: 0.5558 - acc: 0.6556 - precision: 1.0000 - recall: 0.3111 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5692 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 55/500\n",
            "18/18 - 0s - loss: 0.5241 - acc: 0.6889 - precision: 0.9474 - recall: 0.4000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5574 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 56/500\n",
            "18/18 - 0s - loss: 0.4970 - acc: 0.7056 - precision: 0.9744 - recall: 0.4222 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5429 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 57/500\n",
            "18/18 - 0s - loss: 0.4891 - acc: 0.7111 - precision: 0.9130 - recall: 0.4667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5128 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 58/500\n",
            "18/18 - 0s - loss: 0.5381 - acc: 0.6889 - precision: 0.8542 - recall: 0.4556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5480 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 59/500\n",
            "18/18 - 0s - loss: 0.5136 - acc: 0.6833 - precision: 0.9714 - recall: 0.3778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5409 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 60/500\n",
            "18/18 - 0s - loss: 0.5005 - acc: 0.7167 - precision: 0.9535 - recall: 0.4556 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5313 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 61/500\n",
            "18/18 - 0s - loss: 0.4708 - acc: 0.7722 - precision: 0.9298 - recall: 0.5889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5464 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 62/500\n",
            "18/18 - 0s - loss: 0.5318 - acc: 0.7000 - precision: 0.8333 - recall: 0.5000 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5395 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 63/500\n",
            "18/18 - 0s - loss: 0.4581 - acc: 0.7444 - precision: 0.9400 - recall: 0.5222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5266 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 64/500\n",
            "18/18 - 0s - loss: 0.4558 - acc: 0.7278 - precision: 0.9184 - recall: 0.5000 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5219 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 65/500\n",
            "18/18 - 0s - loss: 0.4751 - acc: 0.7444 - precision: 0.8793 - recall: 0.5667 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5567 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 66/500\n",
            "18/18 - 0s - loss: 0.4909 - acc: 0.7333 - precision: 0.8500 - recall: 0.5667 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5234 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 67/500\n",
            "18/18 - 0s - loss: 0.4500 - acc: 0.7500 - precision: 0.9245 - recall: 0.5444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5271 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 68/500\n",
            "18/18 - 0s - loss: 0.4675 - acc: 0.7278 - precision: 0.9362 - recall: 0.4889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5418 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 69/500\n",
            "18/18 - 0s - loss: 0.4645 - acc: 0.7444 - precision: 0.9783 - recall: 0.5000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5245 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 70/500\n",
            "18/18 - 0s - loss: 0.4714 - acc: 0.6944 - precision: 0.8431 - recall: 0.4778 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5212 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 71/500\n",
            "18/18 - 0s - loss: 0.4620 - acc: 0.7056 - precision: 0.8364 - recall: 0.5111 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4958 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 72/500\n",
            "18/18 - 0s - loss: 0.4498 - acc: 0.7222 - precision: 0.9000 - recall: 0.5000 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5020 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 73/500\n",
            "18/18 - 0s - loss: 0.4126 - acc: 0.7556 - precision: 0.7738 - recall: 0.7222 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.4930 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 74/500\n",
            "18/18 - 0s - loss: 0.4465 - acc: 0.7333 - precision: 0.9375 - recall: 0.5000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5370 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 75/500\n",
            "18/18 - 0s - loss: 0.4417 - acc: 0.7333 - precision: 0.9565 - recall: 0.4889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5230 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 76/500\n",
            "18/18 - 0s - loss: 0.4605 - acc: 0.7278 - precision: 0.7356 - recall: 0.7111 - tn: 67.0000 - fp: 23.0000 - val_loss: 0.5034 - val_acc: 0.7167 - val_precision: 0.6757 - val_recall: 0.8333 - val_tn: 18.0000 - val_fp: 12.0000\n",
            "Epoch 77/500\n",
            "18/18 - 0s - loss: 0.4636 - acc: 0.7111 - precision: 0.7794 - recall: 0.5889 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.4894 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 78/500\n",
            "18/18 - 0s - loss: 0.4387 - acc: 0.7167 - precision: 0.7468 - recall: 0.6556 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.5300 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 79/500\n",
            "18/18 - 0s - loss: 0.4691 - acc: 0.7278 - precision: 0.9767 - recall: 0.4667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5163 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 80/500\n",
            "18/18 - 0s - loss: 0.3735 - acc: 0.7778 - precision: 0.7604 - recall: 0.8111 - tn: 67.0000 - fp: 23.0000 - val_loss: 0.4950 - val_acc: 0.7167 - val_precision: 0.6757 - val_recall: 0.8333 - val_tn: 18.0000 - val_fp: 12.0000\n",
            "Epoch 81/500\n",
            "18/18 - 0s - loss: 0.3972 - acc: 0.7889 - precision: 0.7500 - recall: 0.8667 - tn: 64.0000 - fp: 26.0000 - val_loss: 0.5023 - val_acc: 0.6667 - val_precision: 0.6923 - val_recall: 0.6000 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 82/500\n",
            "18/18 - 0s - loss: 0.3630 - acc: 0.7444 - precision: 0.7340 - recall: 0.7667 - tn: 65.0000 - fp: 25.0000 - val_loss: 0.4974 - val_acc: 0.6833 - val_precision: 0.6222 - val_recall: 0.9333 - val_tn: 13.0000 - val_fp: 17.0000\n",
            "Epoch 83/500\n",
            "18/18 - 0s - loss: 0.4500 - acc: 0.7333 - precision: 0.6780 - recall: 0.8889 - tn: 52.0000 - fp: 38.0000 - val_loss: 0.4824 - val_acc: 0.7000 - val_precision: 0.6304 - val_recall: 0.9667 - val_tn: 13.0000 - val_fp: 17.0000\n",
            "Epoch 84/500\n",
            "18/18 - 0s - loss: 0.4125 - acc: 0.7611 - precision: 0.8052 - recall: 0.6889 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.4878 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 85/500\n",
            "18/18 - 0s - loss: 0.4519 - acc: 0.7500 - precision: 0.7647 - recall: 0.7222 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.4928 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 86/500\n",
            "18/18 - 0s - loss: 0.3747 - acc: 0.7444 - precision: 0.9400 - recall: 0.5222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5022 - val_acc: 0.7333 - val_precision: 0.8500 - val_recall: 0.5667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 87/500\n",
            "18/18 - 0s - loss: 0.3565 - acc: 0.8222 - precision: 0.7843 - recall: 0.8889 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.4711 - val_acc: 0.7667 - val_precision: 0.7000 - val_recall: 0.9333 - val_tn: 18.0000 - val_fp: 12.0000\n",
            "Epoch 88/500\n",
            "18/18 - 0s - loss: 0.3850 - acc: 0.7944 - precision: 0.7304 - recall: 0.9333 - tn: 59.0000 - fp: 31.0000 - val_loss: 0.4832 - val_acc: 0.6833 - val_precision: 0.6774 - val_recall: 0.7000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 89/500\n",
            "18/18 - 0s - loss: 0.4663 - acc: 0.7278 - precision: 0.8154 - recall: 0.5889 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.4838 - val_acc: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 90/500\n",
            "18/18 - 0s - loss: 0.4778 - acc: 0.6778 - precision: 0.6096 - recall: 0.9889 - tn: 33.0000 - fp: 57.0000 - val_loss: 0.5113 - val_acc: 0.6500 - val_precision: 0.5957 - val_recall: 0.9333 - val_tn: 11.0000 - val_fp: 19.0000\n",
            "Epoch 91/500\n",
            "18/18 - 0s - loss: 0.4852 - acc: 0.6722 - precision: 0.7385 - recall: 0.5333 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.5423 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 92/500\n",
            "18/18 - 0s - loss: 0.4145 - acc: 0.7722 - precision: 1.0000 - recall: 0.5444 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.4922 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 93/500\n",
            "18/18 - 0s - loss: 0.4856 - acc: 0.7056 - precision: 0.8364 - recall: 0.5111 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5508 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 94/500\n",
            "18/18 - 0s - loss: 0.4264 - acc: 0.7278 - precision: 1.0000 - recall: 0.4556 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5452 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 95/500\n",
            "18/18 - 0s - loss: 0.4078 - acc: 0.7500 - precision: 1.0000 - recall: 0.5000 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5237 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 96/500\n",
            "18/18 - 0s - loss: 0.4231 - acc: 0.7333 - precision: 0.7143 - recall: 0.7778 - tn: 62.0000 - fp: 28.0000 - val_loss: 0.4865 - val_acc: 0.7500 - val_precision: 0.6923 - val_recall: 0.9000 - val_tn: 18.0000 - val_fp: 12.0000\n",
            "Epoch 97/500\n",
            "18/18 - 0s - loss: 0.4231 - acc: 0.7889 - precision: 0.7321 - recall: 0.9111 - tn: 60.0000 - fp: 30.0000 - val_loss: 0.4805 - val_acc: 0.7000 - val_precision: 0.7143 - val_recall: 0.6667 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 98/500\n",
            "18/18 - 0s - loss: 0.3802 - acc: 0.7500 - precision: 0.7778 - recall: 0.7000 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.5013 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 99/500\n",
            "18/18 - 0s - loss: 0.3665 - acc: 0.8389 - precision: 0.8352 - recall: 0.8444 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.4646 - val_acc: 0.7333 - val_precision: 0.7333 - val_recall: 0.7333 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 100/500\n",
            "18/18 - 0s - loss: 0.3448 - acc: 0.8222 - precision: 0.7843 - recall: 0.8889 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.4284 - val_acc: 0.7167 - val_precision: 0.7241 - val_recall: 0.7000 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 101/500\n",
            "18/18 - 0s - loss: 0.3650 - acc: 0.8167 - precision: 0.7664 - recall: 0.9111 - tn: 65.0000 - fp: 25.0000 - val_loss: 0.4770 - val_acc: 0.7500 - val_precision: 0.8000 - val_recall: 0.6667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 102/500\n",
            "18/18 - 0s - loss: 0.4471 - acc: 0.7333 - precision: 0.9200 - recall: 0.5111 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4791 - val_acc: 0.7500 - val_precision: 0.8000 - val_recall: 0.6667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 103/500\n",
            "18/18 - 0s - loss: 0.3652 - acc: 0.8000 - precision: 0.7328 - recall: 0.9444 - tn: 59.0000 - fp: 31.0000 - val_loss: 0.4478 - val_acc: 0.7500 - val_precision: 0.7419 - val_recall: 0.7667 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 104/500\n",
            "18/18 - 0s - loss: 0.3318 - acc: 0.8167 - precision: 0.7879 - recall: 0.8667 - tn: 69.0000 - fp: 21.0000 - val_loss: 0.4322 - val_acc: 0.7500 - val_precision: 0.8571 - val_recall: 0.6000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 105/500\n",
            "18/18 - 0s - loss: 0.3960 - acc: 0.7778 - precision: 0.7778 - recall: 0.7778 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.4705 - val_acc: 0.7500 - val_precision: 0.8000 - val_recall: 0.6667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 106/500\n",
            "18/18 - 0s - loss: 0.3098 - acc: 0.8222 - precision: 0.7685 - recall: 0.9222 - tn: 65.0000 - fp: 25.0000 - val_loss: 0.4473 - val_acc: 0.7833 - val_precision: 0.7576 - val_recall: 0.8333 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 107/500\n",
            "18/18 - 0s - loss: 0.4253 - acc: 0.7722 - precision: 0.8182 - recall: 0.7000 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.4505 - val_acc: 0.7667 - val_precision: 0.7500 - val_recall: 0.8000 - val_tn: 22.0000 - val_fp: 8.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 108/500\n",
            "18/18 - 0s - loss: 0.4032 - acc: 0.7667 - precision: 0.7069 - recall: 0.9111 - tn: 56.0000 - fp: 34.0000 - val_loss: 0.5226 - val_acc: 0.7333 - val_precision: 0.6842 - val_recall: 0.8667 - val_tn: 18.0000 - val_fp: 12.0000\n",
            "Epoch 109/500\n",
            "18/18 - 0s - loss: 0.3626 - acc: 0.8278 - precision: 0.7864 - recall: 0.9000 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.4995 - val_acc: 0.7833 - val_precision: 0.8148 - val_recall: 0.7333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 110/500\n",
            "18/18 - 0s - loss: 0.3767 - acc: 0.8222 - precision: 0.7900 - recall: 0.8778 - tn: 69.0000 - fp: 21.0000 - val_loss: 0.4686 - val_acc: 0.8000 - val_precision: 0.8214 - val_recall: 0.7667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 111/500\n",
            "18/18 - 0s - loss: 0.2962 - acc: 0.8667 - precision: 0.8367 - recall: 0.9111 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4537 - val_acc: 0.7500 - val_precision: 0.8000 - val_recall: 0.6667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 112/500\n",
            "18/18 - 0s - loss: 0.3130 - acc: 0.7944 - precision: 0.8118 - recall: 0.7667 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4443 - val_acc: 0.7667 - val_precision: 0.8077 - val_recall: 0.7000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 113/500\n",
            "18/18 - 0s - loss: 0.3435 - acc: 0.8111 - precision: 0.7500 - recall: 0.9333 - tn: 62.0000 - fp: 28.0000 - val_loss: 0.4828 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 114/500\n",
            "18/18 - 0s - loss: 0.4085 - acc: 0.7556 - precision: 0.8710 - recall: 0.6000 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4605 - val_acc: 0.8167 - val_precision: 0.8276 - val_recall: 0.8000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 115/500\n",
            "18/18 - 0s - loss: 0.3531 - acc: 0.8056 - precision: 0.8022 - recall: 0.8111 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4179 - val_acc: 0.7667 - val_precision: 0.8077 - val_recall: 0.7000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 116/500\n",
            "18/18 - 0s - loss: 0.4620 - acc: 0.8056 - precision: 0.7778 - recall: 0.8556 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.4937 - val_acc: 0.8000 - val_precision: 0.8214 - val_recall: 0.7667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 117/500\n",
            "18/18 - 0s - loss: 0.4413 - acc: 0.8056 - precision: 0.7619 - recall: 0.8889 - tn: 65.0000 - fp: 25.0000 - val_loss: 0.4881 - val_acc: 0.7667 - val_precision: 0.7222 - val_recall: 0.8667 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 118/500\n",
            "18/18 - 0s - loss: 0.3397 - acc: 0.8333 - precision: 0.8000 - recall: 0.8889 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.4475 - val_acc: 0.8000 - val_precision: 0.8214 - val_recall: 0.7667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 119/500\n",
            "18/18 - 0s - loss: 0.2840 - acc: 0.8444 - precision: 0.8298 - recall: 0.8667 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4663 - val_acc: 0.7500 - val_precision: 0.8571 - val_recall: 0.6000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 120/500\n",
            "18/18 - 0s - loss: 0.3258 - acc: 0.8333 - precision: 0.8125 - recall: 0.8667 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4634 - val_acc: 0.8000 - val_precision: 0.7647 - val_recall: 0.8667 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 121/500\n",
            "18/18 - 0s - loss: 0.3314 - acc: 0.8278 - precision: 0.7980 - recall: 0.8778 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.4449 - val_acc: 0.8000 - val_precision: 0.8214 - val_recall: 0.7667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 122/500\n",
            "18/18 - 0s - loss: 0.3858 - acc: 0.7889 - precision: 0.7364 - recall: 0.9000 - tn: 61.0000 - fp: 29.0000 - val_loss: 0.4715 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 123/500\n",
            "18/18 - 0s - loss: 0.3462 - acc: 0.8111 - precision: 0.9667 - recall: 0.6444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4752 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 124/500\n",
            "18/18 - 0s - loss: 0.3458 - acc: 0.8167 - precision: 0.7879 - recall: 0.8667 - tn: 69.0000 - fp: 21.0000 - val_loss: 0.4457 - val_acc: 0.8167 - val_precision: 0.8276 - val_recall: 0.8000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 125/500\n",
            "18/18 - 0s - loss: 0.3360 - acc: 0.8389 - precision: 0.8588 - recall: 0.8111 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.4628 - val_acc: 0.7167 - val_precision: 0.7826 - val_recall: 0.6000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 126/500\n",
            "18/18 - 0s - loss: 0.3222 - acc: 0.8333 - precision: 0.8261 - recall: 0.8444 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4620 - val_acc: 0.7500 - val_precision: 0.8000 - val_recall: 0.6667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 127/500\n",
            "18/18 - 0s - loss: 0.2455 - acc: 0.8778 - precision: 0.8400 - recall: 0.9333 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4191 - val_acc: 0.8167 - val_precision: 0.8276 - val_recall: 0.8000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 128/500\n",
            "18/18 - 0s - loss: 0.2576 - acc: 0.8667 - precision: 0.8300 - recall: 0.9222 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.4001 - val_acc: 0.7667 - val_precision: 0.8077 - val_recall: 0.7000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 129/500\n",
            "18/18 - 0s - loss: 0.3725 - acc: 0.8278 - precision: 0.8242 - recall: 0.8333 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4923 - val_acc: 0.8000 - val_precision: 0.7647 - val_recall: 0.8667 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 130/500\n",
            "18/18 - 0s - loss: 0.3911 - acc: 0.7944 - precision: 0.7624 - recall: 0.8556 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.4978 - val_acc: 0.8000 - val_precision: 0.7647 - val_recall: 0.8667 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 131/500\n",
            "18/18 - 0s - loss: 0.3644 - acc: 0.7833 - precision: 0.7297 - recall: 0.9000 - tn: 60.0000 - fp: 30.0000 - val_loss: 0.4734 - val_acc: 0.8000 - val_precision: 0.7647 - val_recall: 0.8667 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 132/500\n",
            "18/18 - 0s - loss: 0.3469 - acc: 0.8167 - precision: 0.7568 - recall: 0.9333 - tn: 63.0000 - fp: 27.0000 - val_loss: 0.4381 - val_acc: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 133/500\n",
            "18/18 - 0s - loss: 0.2801 - acc: 0.8500 - precision: 0.8247 - recall: 0.8889 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.4357 - val_acc: 0.7667 - val_precision: 0.8077 - val_recall: 0.7000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 134/500\n",
            "18/18 - 0s - loss: 0.3082 - acc: 0.8333 - precision: 0.8061 - recall: 0.8778 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.4717 - val_acc: 0.7500 - val_precision: 0.8571 - val_recall: 0.6000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 135/500\n",
            "18/18 - 0s - loss: 0.3083 - acc: 0.8056 - precision: 0.9104 - recall: 0.6778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4534 - val_acc: 0.7500 - val_precision: 0.8000 - val_recall: 0.6667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 136/500\n",
            "18/18 - 0s - loss: 0.3018 - acc: 0.8444 - precision: 0.7925 - recall: 0.9333 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.4225 - val_acc: 0.8167 - val_precision: 0.8276 - val_recall: 0.8000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 137/500\n",
            "18/18 - 0s - loss: 0.2736 - acc: 0.9000 - precision: 0.8462 - recall: 0.9778 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4629 - val_acc: 0.7500 - val_precision: 0.8000 - val_recall: 0.6667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 138/500\n",
            "18/18 - 0s - loss: 0.3422 - acc: 0.8278 - precision: 0.8642 - recall: 0.7778 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4562 - val_acc: 0.7833 - val_precision: 0.8148 - val_recall: 0.7333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 139/500\n",
            "18/18 - 0s - loss: 0.3429 - acc: 0.8167 - precision: 0.7568 - recall: 0.9333 - tn: 63.0000 - fp: 27.0000 - val_loss: 0.4254 - val_acc: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 140/500\n",
            "18/18 - 0s - loss: 0.3211 - acc: 0.8056 - precision: 0.8022 - recall: 0.8111 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4496 - val_acc: 0.7333 - val_precision: 0.7917 - val_recall: 0.6333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 141/500\n",
            "18/18 - 0s - loss: 0.3661 - acc: 0.8111 - precision: 0.7979 - recall: 0.8333 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.4389 - val_acc: 0.7833 - val_precision: 0.8148 - val_recall: 0.7333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 142/500\n",
            "18/18 - 0s - loss: 0.3542 - acc: 0.8167 - precision: 0.7522 - recall: 0.9444 - tn: 62.0000 - fp: 28.0000 - val_loss: 0.4142 - val_acc: 0.8000 - val_precision: 0.7647 - val_recall: 0.8667 - val_tn: 22.0000 - val_fp: 8.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 143/500\n",
            "18/18 - 0s - loss: 0.3253 - acc: 0.8889 - precision: 0.8889 - recall: 0.8889 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4206 - val_acc: 0.7667 - val_precision: 0.8077 - val_recall: 0.7000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 144/500\n",
            "18/18 - 0s - loss: 0.2869 - acc: 0.8611 - precision: 0.9114 - recall: 0.8000 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4600 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 145/500\n",
            "18/18 - 0s - loss: 0.2270 - acc: 0.9056 - precision: 0.9294 - recall: 0.8778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5121 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 146/500\n",
            "18/18 - 0s - loss: 0.3452 - acc: 0.8111 - precision: 0.9375 - recall: 0.6667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4231 - val_acc: 0.8500 - val_precision: 0.8387 - val_recall: 0.8667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 147/500\n",
            "18/18 - 0s - loss: 0.3883 - acc: 0.8222 - precision: 0.7900 - recall: 0.8778 - tn: 69.0000 - fp: 21.0000 - val_loss: 0.4950 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 148/500\n",
            "18/18 - 0s - loss: 0.3449 - acc: 0.8500 - precision: 0.8795 - recall: 0.8111 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4680 - val_acc: 0.8000 - val_precision: 0.8214 - val_recall: 0.7667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 149/500\n",
            "18/18 - 0s - loss: 0.2590 - acc: 0.9000 - precision: 0.8333 - recall: 1.0000 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4235 - val_acc: 0.8167 - val_precision: 0.8276 - val_recall: 0.8000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 150/500\n",
            "18/18 - 0s - loss: 0.2799 - acc: 0.9000 - precision: 0.8600 - recall: 0.9556 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.6630 - val_acc: 0.6667 - val_precision: 0.8125 - val_recall: 0.4333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 151/500\n",
            "18/18 - 0s - loss: 0.3540 - acc: 0.8222 - precision: 0.8919 - recall: 0.7333 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4721 - val_acc: 0.7333 - val_precision: 0.7917 - val_recall: 0.6333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 152/500\n",
            "18/18 - 0s - loss: 0.2750 - acc: 0.8556 - precision: 0.8200 - recall: 0.9111 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4392 - val_acc: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 153/500\n",
            "18/18 - 0s - loss: 0.3448 - acc: 0.8111 - precision: 0.8333 - recall: 0.7778 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.4345 - val_acc: 0.8000 - val_precision: 0.8214 - val_recall: 0.7667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.4001 - acc: 0.7667 - precision: 0.8077 - recall: 0.7000 - tn: 25.0000 - fp: 5.0000   \n",
            "loss:\n",
            "[0.40008652210235596, 0.7666666507720947, 0.807692289352417, 0.699999988079071, 25.0, 5.0]\n",
            "['loss', 'acc', 'precision', 'recall', 'tn', 'fp']\n",
            "Training and evaluating on fold 3 out of 8...\n",
            "train_index[  0   1   2   3   4   5   6   7   8  12  13  14  15  16  17  18  19  20\n",
            "  21  22  23  24  26  27  28  29  30  31  32  33  34  35  36  38  39  40\n",
            "  42  43  44  50  51  52  53  54  55  56  58  59  60  62  63  64  65  66\n",
            "  68  69  71  72  74  75  76  77  80  81  84  88  89  90  91  92  93  94\n",
            "  96  97  98  99 100 103 105 106 107 109 110 111 112 113 115 116 118 119\n",
            " 120 121 122 123 124 125 126 127 129 130 131 133 134 135 136 137 138 140\n",
            " 144 145 146 149 153 156 158 159 160 163 164 165 166 169 171 172 173 175\n",
            " 176 177 179 180 181 182 183 184 185 186 187 188 189 190 191 193 195 196\n",
            " 199 200 202 203 204 205 206 207 209 210 211 212 214 215 217 218 219 220\n",
            " 221 222 223 224 225 226 227 228 229 230 231 232 234 235 236 237 238 239]\n",
            "test_index[  9  10  11  25  37  41  45  46  47  48  49  57  61  67  70  73  78  79\n",
            "  82  83  85  86  87  95 101 102 104 108 114 117 128 132 139 141 142 143\n",
            " 147 148 150 151 152 154 155 157 161 162 167 168 170 174 178 192 194 197\n",
            " 198 201 208 213 216 233]\n",
            "Epoch 1/500\n",
            "18/18 - 2s - loss: 0.7105 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6940 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 2/500\n",
            "18/18 - 0s - loss: 0.7028 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 3/500\n",
            "18/18 - 0s - loss: 0.6974 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6939 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 4/500\n",
            "18/18 - 0s - loss: 0.6971 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 5/500\n",
            "18/18 - 0s - loss: 0.6945 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 6/500\n",
            "18/18 - 0s - loss: 0.6962 - acc: 0.3556 - precision: 0.1176 - recall: 0.0444 - tn: 60.0000 - fp: 30.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 7/500\n",
            "18/18 - 0s - loss: 0.6941 - acc: 0.4944 - precision: 0.4972 - recall: 0.9889 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 8/500\n",
            "18/18 - 0s - loss: 0.6945 - acc: 0.2444 - precision: 0.0208 - recall: 0.0111 - tn: 43.0000 - fp: 47.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 9/500\n",
            "18/18 - 0s - loss: 0.6951 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 10/500\n",
            "18/18 - 0s - loss: 0.6931 - acc: 0.5056 - precision: 1.0000 - recall: 0.0111 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 11/500\n",
            "18/18 - 0s - loss: 0.6944 - acc: 0.3333 - precision: 0.4000 - recall: 0.6667 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 12/500\n",
            "18/18 - 0s - loss: 0.6932 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 13/500\n",
            "18/18 - 0s - loss: 0.6934 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 14/500\n",
            "18/18 - 0s - loss: 0.6938 - acc: 0.3000 - precision: 0.3085 - recall: 0.3222 - tn: 25.0000 - fp: 65.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 15/500\n",
            "18/18 - 0s - loss: 0.6932 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 16/500\n",
            "18/18 - 0s - loss: 0.6945 - acc: 0.2778 - precision: 0.3333 - recall: 0.4444 - tn: 10.0000 - fp: 80.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 17/500\n",
            "18/18 - 0s - loss: 0.6928 - acc: 0.3722 - precision: 0.2982 - recall: 0.1889 - tn: 50.0000 - fp: 40.0000 - val_loss: 0.6930 - val_acc: 0.6667 - val_precision: 0.7778 - val_recall: 0.4667 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 18/500\n",
            "18/18 - 0s - loss: 0.6976 - acc: 0.4944 - precision: 0.4972 - recall: 0.9889 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/500\n",
            "18/18 - 0s - loss: 0.6932 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 20/500\n",
            "18/18 - 0s - loss: 0.6926 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 21/500\n",
            "18/18 - 0s - loss: 0.6918 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 22/500\n",
            "18/18 - 0s - loss: 0.6928 - acc: 0.4556 - precision: 0.3571 - recall: 0.1111 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 23/500\n",
            "18/18 - 0s - loss: 0.6949 - acc: 0.2611 - precision: 0.2784 - recall: 0.3000 - tn: 20.0000 - fp: 70.0000 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 24/500\n",
            "18/18 - 0s - loss: 0.6918 - acc: 0.3056 - precision: 0.2989 - recall: 0.2889 - tn: 29.0000 - fp: 61.0000 - val_loss: 0.6929 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 25/500\n",
            "18/18 - 0s - loss: 0.6900 - acc: 0.3278 - precision: 0.2373 - recall: 0.1556 - tn: 45.0000 - fp: 45.0000 - val_loss: 0.6927 - val_acc: 0.5667 - val_precision: 0.6667 - val_recall: 0.2667 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 26/500\n",
            "18/18 - 0s - loss: 0.6889 - acc: 0.4833 - precision: 0.4776 - recall: 0.3556 - tn: 55.0000 - fp: 35.0000 - val_loss: 0.6929 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 27/500\n",
            "18/18 - 0s - loss: 0.6846 - acc: 0.3444 - precision: 0.3372 - recall: 0.3222 - tn: 33.0000 - fp: 57.0000 - val_loss: 0.6783 - val_acc: 0.6167 - val_precision: 0.7333 - val_recall: 0.3667 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 28/500\n",
            "18/18 - 0s - loss: 0.6765 - acc: 0.5000 - precision: 0.5000 - recall: 0.8889 - tn: 10.0000 - fp: 80.0000 - val_loss: 0.6721 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 29/500\n",
            "18/18 - 0s - loss: 0.6725 - acc: 0.4778 - precision: 0.4600 - recall: 0.2556 - tn: 63.0000 - fp: 27.0000 - val_loss: 0.6459 - val_acc: 0.6500 - val_precision: 0.6957 - val_recall: 0.5333 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 30/500\n",
            "18/18 - 0s - loss: 0.6580 - acc: 0.5222 - precision: 0.5417 - recall: 0.2889 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.6463 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 31/500\n",
            "18/18 - 0s - loss: 0.6476 - acc: 0.6000 - precision: 0.6216 - recall: 0.5111 - tn: 62.0000 - fp: 28.0000 - val_loss: 0.6153 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 32/500\n",
            "18/18 - 0s - loss: 0.6482 - acc: 0.6111 - precision: 0.7632 - recall: 0.3222 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.6314 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 33/500\n",
            "18/18 - 0s - loss: 0.6515 - acc: 0.6000 - precision: 0.6607 - recall: 0.4111 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.6133 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 34/500\n",
            "18/18 - 0s - loss: 0.6313 - acc: 0.6333 - precision: 0.7500 - recall: 0.4000 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.6067 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 35/500\n",
            "18/18 - 0s - loss: 0.6045 - acc: 0.6333 - precision: 0.7000 - recall: 0.4667 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.5969 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 36/500\n",
            "18/18 - 0s - loss: 0.6134 - acc: 0.6389 - precision: 0.7660 - recall: 0.4000 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5994 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 37/500\n",
            "18/18 - 0s - loss: 0.6083 - acc: 0.6222 - precision: 0.7200 - recall: 0.4000 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.5879 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 38/500\n",
            "18/18 - 0s - loss: 0.5956 - acc: 0.6500 - precision: 0.7755 - recall: 0.4222 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5860 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 39/500\n",
            "18/18 - 0s - loss: 0.5869 - acc: 0.6611 - precision: 0.7636 - recall: 0.4667 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5854 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 40/500\n",
            "18/18 - 0s - loss: 0.6148 - acc: 0.7111 - precision: 0.8654 - recall: 0.5000 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5875 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 41/500\n",
            "18/18 - 0s - loss: 0.6188 - acc: 0.6222 - precision: 1.0000 - recall: 0.2444 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5926 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 42/500\n",
            "18/18 - 0s - loss: 0.6095 - acc: 0.6389 - precision: 0.9630 - recall: 0.2889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5774 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 43/500\n",
            "18/18 - 0s - loss: 0.5681 - acc: 0.6778 - precision: 0.8478 - recall: 0.4333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5715 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 44/500\n",
            "18/18 - 0s - loss: 0.5934 - acc: 0.6500 - precision: 0.7547 - recall: 0.4444 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5790 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 45/500\n",
            "18/18 - 0s - loss: 0.5581 - acc: 0.7000 - precision: 0.9091 - recall: 0.4444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5723 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 46/500\n",
            "18/18 - 0s - loss: 0.5401 - acc: 0.7000 - precision: 0.8333 - recall: 0.5000 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5651 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 47/500\n",
            "18/18 - 0s - loss: 0.5307 - acc: 0.7333 - precision: 0.8750 - recall: 0.5444 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5599 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 48/500\n",
            "18/18 - 0s - loss: 0.5390 - acc: 0.6944 - precision: 0.8302 - recall: 0.4889 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5740 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 49/500\n",
            "18/18 - 0s - loss: 0.5166 - acc: 0.7444 - precision: 0.9583 - recall: 0.5111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5371 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 50/500\n",
            "18/18 - 0s - loss: 0.5258 - acc: 0.7167 - precision: 0.8197 - recall: 0.5556 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5680 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 51/500\n",
            "18/18 - 0s - loss: 0.5624 - acc: 0.6944 - precision: 0.8070 - recall: 0.5111 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5464 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 52/500\n",
            "18/18 - 0s - loss: 0.5133 - acc: 0.7333 - precision: 0.9375 - recall: 0.5000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5507 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 53/500\n",
            "18/18 - 0s - loss: 0.4854 - acc: 0.7389 - precision: 0.8525 - recall: 0.5778 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5153 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54/500\n",
            "18/18 - 0s - loss: 0.5444 - acc: 0.7056 - precision: 0.8936 - recall: 0.4667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5301 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 55/500\n",
            "18/18 - 0s - loss: 0.5633 - acc: 0.6944 - precision: 0.8723 - recall: 0.4556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5159 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 56/500\n",
            "18/18 - 0s - loss: 0.5585 - acc: 0.6889 - precision: 0.8036 - recall: 0.5000 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5464 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 57/500\n",
            "18/18 - 0s - loss: 0.5414 - acc: 0.7056 - precision: 0.9111 - recall: 0.4556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5288 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 58/500\n",
            "18/18 - 0s - loss: 0.5418 - acc: 0.6833 - precision: 0.7324 - recall: 0.5778 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.5171 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 59/500\n",
            "18/18 - 0s - loss: 0.4857 - acc: 0.7444 - precision: 0.9400 - recall: 0.5222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5470 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 60/500\n",
            "18/18 - 0s - loss: 0.4650 - acc: 0.7556 - precision: 0.9107 - recall: 0.5667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5168 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 61/500\n",
            "18/18 - 0s - loss: 0.5255 - acc: 0.7278 - precision: 0.9184 - recall: 0.5000 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5383 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 62/500\n",
            "18/18 - 0s - loss: 0.4555 - acc: 0.7556 - precision: 0.8966 - recall: 0.5778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5056 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 63/500\n",
            "18/18 - 0s - loss: 0.5043 - acc: 0.7389 - precision: 0.8772 - recall: 0.5556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5165 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 64/500\n",
            "18/18 - 0s - loss: 0.5200 - acc: 0.7333 - precision: 0.8088 - recall: 0.6111 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5186 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 65/500\n",
            "18/18 - 0s - loss: 0.4959 - acc: 0.7333 - precision: 0.9565 - recall: 0.4889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5366 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 66/500\n",
            "18/18 - 0s - loss: 0.4878 - acc: 0.7333 - precision: 0.9565 - recall: 0.4889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4985 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 67/500\n",
            "18/18 - 0s - loss: 0.4897 - acc: 0.7444 - precision: 0.8438 - recall: 0.6000 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5004 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 68/500\n",
            "18/18 - 0s - loss: 0.4746 - acc: 0.7611 - precision: 0.8730 - recall: 0.6111 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4814 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 69/500\n",
            "18/18 - 0s - loss: 0.4561 - acc: 0.7556 - precision: 0.8485 - recall: 0.6222 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4634 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 70/500\n",
            "18/18 - 0s - loss: 0.5075 - acc: 0.7444 - precision: 0.9583 - recall: 0.5111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4809 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 71/500\n",
            "18/18 - 0s - loss: 0.5363 - acc: 0.7000 - precision: 0.7647 - recall: 0.5778 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5113 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 72/500\n",
            "18/18 - 0s - loss: 0.4907 - acc: 0.7444 - precision: 0.8929 - recall: 0.5556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5025 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 73/500\n",
            "18/18 - 0s - loss: 0.4761 - acc: 0.7389 - precision: 0.9574 - recall: 0.5000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5030 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 74/500\n",
            "18/18 - 0s - loss: 0.4265 - acc: 0.8278 - precision: 0.9403 - recall: 0.7000 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4864 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 75/500\n",
            "18/18 - 0s - loss: 0.4184 - acc: 0.7833 - precision: 0.9048 - recall: 0.6333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4816 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 76/500\n",
            "18/18 - 0s - loss: 0.4433 - acc: 0.7667 - precision: 0.8750 - recall: 0.6222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5226 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 77/500\n",
            "18/18 - 0s - loss: 0.4711 - acc: 0.7389 - precision: 0.9778 - recall: 0.4889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5114 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 78/500\n",
            "18/18 - 0s - loss: 0.4636 - acc: 0.7444 - precision: 0.7973 - recall: 0.6556 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.5183 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 79/500\n",
            "18/18 - 0s - loss: 0.4854 - acc: 0.7389 - precision: 1.0000 - recall: 0.4778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5213 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 80/500\n",
            "18/18 - 0s - loss: 0.4092 - acc: 0.7889 - precision: 0.9815 - recall: 0.5889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4735 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 81/500\n",
            "18/18 - 0s - loss: 0.4769 - acc: 0.7444 - precision: 0.8056 - recall: 0.6444 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.4813 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 82/500\n",
            "18/18 - 0s - loss: 0.4318 - acc: 0.7722 - precision: 0.9804 - recall: 0.5556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4941 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 83/500\n",
            "18/18 - 0s - loss: 0.4459 - acc: 0.7722 - precision: 0.9298 - recall: 0.5889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4702 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 84/500\n",
            "18/18 - 0s - loss: 0.3774 - acc: 0.8278 - precision: 0.8831 - recall: 0.7556 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4291 - val_acc: 0.7833 - val_precision: 1.0000 - val_recall: 0.5667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 85/500\n",
            "18/18 - 0s - loss: 0.4413 - acc: 0.7611 - precision: 0.8983 - recall: 0.5889 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4755 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 86/500\n",
            "18/18 - 0s - loss: 0.4648 - acc: 0.7500 - precision: 0.8814 - recall: 0.5778 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4523 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 87/500\n",
            "18/18 - 0s - loss: 0.4267 - acc: 0.7722 - precision: 0.9804 - recall: 0.5556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4659 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 88/500\n",
            "18/18 - 0s - loss: 0.3996 - acc: 0.8167 - precision: 0.8701 - recall: 0.7444 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4751 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 89/500\n",
            "18/18 - 0s - loss: 0.3462 - acc: 0.8444 - precision: 0.9306 - recall: 0.7444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4682 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 90/500\n",
            "18/18 - 0s - loss: 0.3893 - acc: 0.7889 - precision: 0.9643 - recall: 0.6000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4581 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 91/500\n",
            "18/18 - 0s - loss: 0.4072 - acc: 0.7833 - precision: 0.9474 - recall: 0.6000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4306 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 92/500\n",
            "18/18 - 0s - loss: 0.4347 - acc: 0.7611 - precision: 0.8133 - recall: 0.6778 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.4940 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 93/500\n",
            "18/18 - 0s - loss: 0.4290 - acc: 0.7778 - precision: 0.9808 - recall: 0.5667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4585 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 94/500\n",
            "18/18 - 0s - loss: 0.4242 - acc: 0.7278 - precision: 0.7204 - recall: 0.7444 - tn: 64.0000 - fp: 26.0000 - val_loss: 0.4394 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 95/500\n",
            "18/18 - 0s - loss: 0.3932 - acc: 0.7944 - precision: 0.9492 - recall: 0.6222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4445 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 96/500\n",
            "18/18 - 0s - loss: 0.3353 - acc: 0.8444 - precision: 0.9079 - recall: 0.7667 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4528 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 97/500\n",
            "18/18 - 0s - loss: 0.3803 - acc: 0.8056 - precision: 0.9825 - recall: 0.6222 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4190 - val_acc: 0.8000 - val_precision: 1.0000 - val_recall: 0.6000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 98/500\n",
            "18/18 - 0s - loss: 0.3089 - acc: 0.8389 - precision: 0.8588 - recall: 0.8111 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.4532 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 99/500\n",
            "18/18 - 0s - loss: 0.3944 - acc: 0.7889 - precision: 0.9643 - recall: 0.6000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4406 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 100/500\n",
            "18/18 - 0s - loss: 0.4271 - acc: 0.7833 - precision: 0.8228 - recall: 0.7222 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.3947 - val_acc: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 101/500\n",
            "18/18 - 0s - loss: 0.3882 - acc: 0.7944 - precision: 0.9206 - recall: 0.6444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4480 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 102/500\n",
            "18/18 - 0s - loss: 0.4116 - acc: 0.8167 - precision: 0.9524 - recall: 0.6667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4262 - val_acc: 0.8167 - val_precision: 0.7879 - val_recall: 0.8667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 103/500\n",
            "18/18 - 0s - loss: 0.3881 - acc: 0.8167 - precision: 0.8904 - recall: 0.7222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4449 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 104/500\n",
            "18/18 - 0s - loss: 0.4534 - acc: 0.6889 - precision: 0.6604 - recall: 0.7778 - tn: 54.0000 - fp: 36.0000 - val_loss: 0.4368 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 105/500\n",
            "18/18 - 0s - loss: 0.3467 - acc: 0.8222 - precision: 0.9677 - recall: 0.6667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4640 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 106/500\n",
            "18/18 - 0s - loss: 0.3548 - acc: 0.8278 - precision: 0.9538 - recall: 0.6889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4004 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 107/500\n",
            "18/18 - 0s - loss: 0.4257 - acc: 0.8222 - precision: 0.8295 - recall: 0.8111 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.4365 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 108/500\n",
            "18/18 - 0s - loss: 0.3966 - acc: 0.7722 - precision: 0.9804 - recall: 0.5556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4462 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 109/500\n",
            "18/18 - 0s - loss: 0.3346 - acc: 0.8000 - precision: 0.8857 - recall: 0.6889 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4257 - val_acc: 0.7833 - val_precision: 0.7297 - val_recall: 0.9000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 110/500\n",
            "18/18 - 0s - loss: 0.3101 - acc: 0.8444 - precision: 0.8163 - recall: 0.8889 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4199 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 111/500\n",
            "18/18 - 0s - loss: 0.3517 - acc: 0.8167 - precision: 0.8800 - recall: 0.7333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4057 - val_acc: 0.7833 - val_precision: 0.7297 - val_recall: 0.9000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 112/500\n",
            "18/18 - 0s - loss: 0.3669 - acc: 0.8167 - precision: 0.7664 - recall: 0.9111 - tn: 65.0000 - fp: 25.0000 - val_loss: 0.4201 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 113/500\n",
            "18/18 - 0s - loss: 0.3202 - acc: 0.8333 - precision: 0.9167 - recall: 0.7333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4171 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 114/500\n",
            "18/18 - 0s - loss: 0.3647 - acc: 0.8000 - precision: 0.9500 - recall: 0.6333 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4321 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 115/500\n",
            "18/18 - 0s - loss: 0.3831 - acc: 0.7889 - precision: 0.7708 - recall: 0.8222 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.4111 - val_acc: 0.8333 - val_precision: 0.7941 - val_recall: 0.9000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 116/500\n",
            "18/18 - 0s - loss: 0.3758 - acc: 0.7944 - precision: 0.8841 - recall: 0.6778 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4261 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 117/500\n",
            "18/18 - 0s - loss: 0.2589 - acc: 0.8833 - precision: 0.9481 - recall: 0.8111 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3988 - val_acc: 0.8000 - val_precision: 1.0000 - val_recall: 0.6000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 118/500\n",
            "18/18 - 0s - loss: 0.2923 - acc: 0.8611 - precision: 0.8916 - recall: 0.8222 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3871 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 119/500\n",
            "18/18 - 0s - loss: 0.3572 - acc: 0.8111 - precision: 0.8590 - recall: 0.7444 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4243 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 120/500\n",
            "18/18 - 0s - loss: 0.3260 - acc: 0.8333 - precision: 0.8846 - recall: 0.7667 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4090 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 121/500\n",
            "18/18 - 0s - loss: 0.3255 - acc: 0.8389 - precision: 0.9067 - recall: 0.7556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4465 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 122/500\n",
            "18/18 - 0s - loss: 0.2570 - acc: 0.8611 - precision: 0.9452 - recall: 0.7667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4045 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 123/500\n",
            "18/18 - 0s - loss: 0.2966 - acc: 0.8556 - precision: 0.9324 - recall: 0.7667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4162 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 124/500\n",
            "18/18 - 0s - loss: 0.3662 - acc: 0.8278 - precision: 0.9275 - recall: 0.7111 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4115 - val_acc: 0.9000 - val_precision: 0.9615 - val_recall: 0.8333 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 125/500\n",
            "18/18 - 0s - loss: 0.3253 - acc: 0.8389 - precision: 0.7798 - recall: 0.9444 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.4219 - val_acc: 0.8167 - val_precision: 0.7879 - val_recall: 0.8667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 126/500\n",
            "18/18 - 0s - loss: 0.3258 - acc: 0.8389 - precision: 0.9296 - recall: 0.7333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4219 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 127/500\n",
            "18/18 - 0s - loss: 0.2948 - acc: 0.8389 - precision: 0.8020 - recall: 0.9000 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.4009 - val_acc: 0.8500 - val_precision: 0.8621 - val_recall: 0.8333 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 128/500\n",
            "18/18 - 0s - loss: 0.2367 - acc: 0.9000 - precision: 0.9615 - recall: 0.8333 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4079 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 129/500\n",
            "18/18 - 0s - loss: 0.2135 - acc: 0.9000 - precision: 0.9286 - recall: 0.8667 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3770 - val_acc: 0.8500 - val_precision: 0.8621 - val_recall: 0.8333 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 130/500\n",
            "18/18 - 0s - loss: 0.3352 - acc: 0.8667 - precision: 0.8667 - recall: 0.8667 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.4628 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 131/500\n",
            "18/18 - 0s - loss: 0.3404 - acc: 0.8111 - precision: 0.8333 - recall: 0.7778 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.4331 - val_acc: 0.8000 - val_precision: 0.7812 - val_recall: 0.8333 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 132/500\n",
            "18/18 - 0s - loss: 0.2816 - acc: 0.8611 - precision: 0.8283 - recall: 0.9111 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.4155 - val_acc: 0.7833 - val_precision: 1.0000 - val_recall: 0.5667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 133/500\n",
            "18/18 - 0s - loss: 0.2723 - acc: 0.8667 - precision: 0.9125 - recall: 0.8111 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4171 - val_acc: 0.7833 - val_precision: 1.0000 - val_recall: 0.5667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 134/500\n",
            "18/18 - 0s - loss: 0.3116 - acc: 0.8500 - precision: 0.9315 - recall: 0.7556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3982 - val_acc: 0.7833 - val_precision: 1.0000 - val_recall: 0.5667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 135/500\n",
            "18/18 - 0s - loss: 0.3111 - acc: 0.8833 - precision: 0.8966 - recall: 0.8667 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3619 - val_acc: 0.8833 - val_precision: 0.9600 - val_recall: 0.8000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 136/500\n",
            "18/18 - 0s - loss: 0.3321 - acc: 0.8389 - precision: 0.9067 - recall: 0.7556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4171 - val_acc: 0.8167 - val_precision: 0.7879 - val_recall: 0.8667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 137/500\n",
            "18/18 - 0s - loss: 0.2956 - acc: 0.8556 - precision: 0.8137 - recall: 0.9222 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.4032 - val_acc: 0.7667 - val_precision: 0.7222 - val_recall: 0.8667 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 138/500\n",
            "18/18 - 0s - loss: 0.2365 - acc: 0.8944 - precision: 0.8817 - recall: 0.9111 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.3673 - val_acc: 0.8000 - val_precision: 0.8462 - val_recall: 0.7333 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 139/500\n",
            "18/18 - 0s - loss: 0.2515 - acc: 0.9000 - precision: 0.9000 - recall: 0.9000 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3677 - val_acc: 0.8500 - val_precision: 0.9565 - val_recall: 0.7333 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 140/500\n",
            "18/18 - 0s - loss: 0.2483 - acc: 0.8833 - precision: 0.8876 - recall: 0.8778 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3332 - val_acc: 0.8667 - val_precision: 0.8667 - val_recall: 0.8667 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 141/500\n",
            "18/18 - 0s - loss: 0.2304 - acc: 0.9000 - precision: 0.9500 - recall: 0.8444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3249 - val_acc: 0.8500 - val_precision: 1.0000 - val_recall: 0.7000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 142/500\n",
            "18/18 - 0s - loss: 0.2519 - acc: 0.8889 - precision: 0.9268 - recall: 0.8444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3572 - val_acc: 0.8667 - val_precision: 0.8667 - val_recall: 0.8667 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 143/500\n",
            "18/18 - 0s - loss: 0.3236 - acc: 0.8778 - precision: 0.8778 - recall: 0.8778 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4135 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 144/500\n",
            "18/18 - 0s - loss: 0.2914 - acc: 0.8722 - precision: 0.8454 - recall: 0.9111 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.3858 - val_acc: 0.8167 - val_precision: 0.7879 - val_recall: 0.8667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 145/500\n",
            "18/18 - 0s - loss: 0.2716 - acc: 0.8667 - precision: 0.9024 - recall: 0.8222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3849 - val_acc: 0.7833 - val_precision: 1.0000 - val_recall: 0.5667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 146/500\n",
            "18/18 - 0s - loss: 0.2862 - acc: 0.8556 - precision: 0.9103 - recall: 0.7889 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3640 - val_acc: 0.8000 - val_precision: 1.0000 - val_recall: 0.6000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 147/500\n",
            "18/18 - 0s - loss: 0.2792 - acc: 0.8556 - precision: 0.8137 - recall: 0.9222 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.3967 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 148/500\n",
            "18/18 - 0s - loss: 0.2908 - acc: 0.8167 - precision: 0.9672 - recall: 0.6556 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4076 - val_acc: 0.8000 - val_precision: 0.7812 - val_recall: 0.8333 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 149/500\n",
            "18/18 - 0s - loss: 0.2486 - acc: 0.9111 - precision: 0.8854 - recall: 0.9444 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4004 - val_acc: 0.7667 - val_precision: 0.7222 - val_recall: 0.8667 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 150/500\n",
            "18/18 - 0s - loss: 0.2581 - acc: 0.9389 - precision: 0.9341 - recall: 0.9444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3736 - val_acc: 0.8167 - val_precision: 0.7879 - val_recall: 0.8667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 151/500\n",
            "18/18 - 0s - loss: 0.2048 - acc: 0.9222 - precision: 0.9130 - recall: 0.9333 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3490 - val_acc: 0.8667 - val_precision: 0.8667 - val_recall: 0.8667 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 152/500\n",
            "18/18 - 0s - loss: 0.2528 - acc: 0.8889 - precision: 0.8646 - recall: 0.9222 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.3530 - val_acc: 0.8667 - val_precision: 0.8667 - val_recall: 0.8667 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 153/500\n",
            "18/18 - 0s - loss: 0.2565 - acc: 0.8778 - precision: 0.8864 - recall: 0.8667 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3644 - val_acc: 0.8167 - val_precision: 0.7879 - val_recall: 0.8667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 154/500\n",
            "18/18 - 0s - loss: 0.2472 - acc: 0.8889 - precision: 0.8889 - recall: 0.8889 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3377 - val_acc: 0.8167 - val_precision: 0.7879 - val_recall: 0.8667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 155/500\n",
            "18/18 - 0s - loss: 0.2376 - acc: 0.8889 - precision: 0.8646 - recall: 0.9222 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.3316 - val_acc: 0.9167 - val_precision: 0.9630 - val_recall: 0.8667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 156/500\n",
            "18/18 - 0s - loss: 0.2531 - acc: 0.8667 - precision: 0.9342 - recall: 0.7889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3338 - val_acc: 0.8167 - val_precision: 0.7879 - val_recall: 0.8667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 157/500\n",
            "18/18 - 0s - loss: 0.1814 - acc: 0.9278 - precision: 0.8738 - recall: 1.0000 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.3070 - val_acc: 0.8667 - val_precision: 0.8667 - val_recall: 0.8667 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 158/500\n",
            "18/18 - 0s - loss: 0.2455 - acc: 0.9167 - precision: 0.9412 - recall: 0.8889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3047 - val_acc: 0.9167 - val_precision: 0.9630 - val_recall: 0.8667 - val_tn: 29.0000 - val_fp: 1.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 159/500\n",
            "18/18 - 0s - loss: 0.2716 - acc: 0.8667 - precision: 0.8750 - recall: 0.8556 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.3495 - val_acc: 0.9167 - val_precision: 0.9630 - val_recall: 0.8667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 160/500\n",
            "18/18 - 0s - loss: 0.2024 - acc: 0.9278 - precision: 0.9231 - recall: 0.9333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3291 - val_acc: 0.8333 - val_precision: 0.7941 - val_recall: 0.9000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 161/500\n",
            "18/18 - 0s - loss: 0.2340 - acc: 0.8889 - precision: 0.8977 - recall: 0.8778 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2793 - val_acc: 0.9333 - val_precision: 0.9643 - val_recall: 0.9000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 162/500\n",
            "18/18 - 0s - loss: 0.3400 - acc: 0.9167 - precision: 0.8947 - recall: 0.9444 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3103 - val_acc: 0.9167 - val_precision: 0.9630 - val_recall: 0.8667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 163/500\n",
            "18/18 - 0s - loss: 0.3122 - acc: 0.8556 - precision: 0.8200 - recall: 0.9111 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.3685 - val_acc: 0.8333 - val_precision: 0.7941 - val_recall: 0.9000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 164/500\n",
            "18/18 - 0s - loss: 0.2874 - acc: 0.8889 - precision: 0.9375 - recall: 0.8333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3446 - val_acc: 0.9167 - val_precision: 0.9630 - val_recall: 0.8667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 165/500\n",
            "18/18 - 0s - loss: 0.2202 - acc: 0.9167 - precision: 0.9032 - recall: 0.9333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3231 - val_acc: 0.8667 - val_precision: 0.8667 - val_recall: 0.8667 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 166/500\n",
            "18/18 - 0s - loss: 0.2583 - acc: 0.9167 - precision: 0.8788 - recall: 0.9667 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.2935 - val_acc: 0.9167 - val_precision: 0.9630 - val_recall: 0.8667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 167/500\n",
            "18/18 - 0s - loss: 0.2134 - acc: 0.8944 - precision: 0.8989 - recall: 0.8889 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2891 - val_acc: 0.9167 - val_precision: 0.9630 - val_recall: 0.8667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 168/500\n",
            "18/18 - 0s - loss: 0.2213 - acc: 0.9111 - precision: 0.9022 - recall: 0.9222 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2986 - val_acc: 0.8667 - val_precision: 0.8667 - val_recall: 0.8667 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 169/500\n",
            "18/18 - 0s - loss: 0.2869 - acc: 0.8944 - precision: 0.9080 - recall: 0.8778 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3309 - val_acc: 0.8333 - val_precision: 0.7941 - val_recall: 0.9000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 170/500\n",
            "18/18 - 0s - loss: 0.1922 - acc: 0.9278 - precision: 0.9231 - recall: 0.9333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2932 - val_acc: 0.8833 - val_precision: 0.8710 - val_recall: 0.9000 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 171/500\n",
            "18/18 - 0s - loss: 0.1725 - acc: 0.9167 - precision: 0.8788 - recall: 0.9667 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.3268 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 172/500\n",
            "18/18 - 0s - loss: 0.3542 - acc: 0.8833 - precision: 0.8710 - recall: 0.9000 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.2922 - val_acc: 0.9333 - val_precision: 0.9643 - val_recall: 0.9000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 173/500\n",
            "18/18 - 0s - loss: 0.1961 - acc: 0.9444 - precision: 0.9651 - recall: 0.9222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2925 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 174/500\n",
            "18/18 - 0s - loss: 0.1582 - acc: 0.9444 - precision: 0.9348 - recall: 0.9556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2632 - val_acc: 0.8833 - val_precision: 0.8710 - val_recall: 0.9000 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 175/500\n",
            "18/18 - 0s - loss: 0.2078 - acc: 0.8889 - precision: 0.8889 - recall: 0.8889 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.2650 - val_acc: 0.9500 - val_precision: 0.9655 - val_recall: 0.9333 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 176/500\n",
            "18/18 - 0s - loss: 0.1819 - acc: 0.9500 - precision: 0.9175 - recall: 0.9889 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.2733 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 177/500\n",
            "18/18 - 0s - loss: 0.2174 - acc: 0.9167 - precision: 0.9213 - recall: 0.9111 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2589 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 178/500\n",
            "18/18 - 0s - loss: 0.1480 - acc: 0.9389 - precision: 0.9341 - recall: 0.9444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2502 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 179/500\n",
            "18/18 - 0s - loss: 0.1758 - acc: 0.9167 - precision: 0.9412 - recall: 0.8889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2867 - val_acc: 0.8500 - val_precision: 0.8000 - val_recall: 0.9333 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 180/500\n",
            "18/18 - 0s - loss: 0.2084 - acc: 0.9000 - precision: 0.8830 - recall: 0.9222 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.2798 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 181/500\n",
            "18/18 - 0s - loss: 0.1871 - acc: 0.9278 - precision: 0.9053 - recall: 0.9556 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2752 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 182/500\n",
            "18/18 - 0s - loss: 0.1604 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2633 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 183/500\n",
            "18/18 - 0s - loss: 0.1591 - acc: 0.9389 - precision: 0.9341 - recall: 0.9444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2521 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 184/500\n",
            "18/18 - 0s - loss: 0.1155 - acc: 0.9444 - precision: 0.9762 - recall: 0.9111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2364 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 185/500\n",
            "18/18 - 0s - loss: 0.2645 - acc: 0.9056 - precision: 0.8925 - recall: 0.9222 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.2473 - val_acc: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 186/500\n",
            "18/18 - 0s - loss: 0.1526 - acc: 0.9500 - precision: 0.9880 - recall: 0.9111 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.2368 - val_acc: 0.9000 - val_precision: 0.8750 - val_recall: 0.9333 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 187/500\n",
            "18/18 - 0s - loss: 0.1377 - acc: 0.9389 - precision: 0.9247 - recall: 0.9556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2222 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 188/500\n",
            "18/18 - 0s - loss: 0.2015 - acc: 0.9000 - precision: 0.9000 - recall: 0.9000 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2460 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 189/500\n",
            "18/18 - 0s - loss: 0.1466 - acc: 0.9111 - precision: 0.9205 - recall: 0.9000 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2385 - val_acc: 0.9000 - val_precision: 0.8750 - val_recall: 0.9333 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 190/500\n",
            "18/18 - 0s - loss: 0.2323 - acc: 0.9278 - precision: 0.9425 - recall: 0.9111 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2564 - val_acc: 0.8833 - val_precision: 0.8710 - val_recall: 0.9000 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 191/500\n",
            "18/18 - 0s - loss: 0.1304 - acc: 0.9444 - precision: 0.9255 - recall: 0.9667 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2365 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 192/500\n",
            "18/18 - 0s - loss: 0.1885 - acc: 0.9167 - precision: 0.9412 - recall: 0.8889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2578 - val_acc: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 193/500\n",
            "18/18 - 0s - loss: 0.2223 - acc: 0.8889 - precision: 0.8431 - recall: 0.9556 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.2745 - val_acc: 0.8500 - val_precision: 0.8000 - val_recall: 0.9333 - val_tn: 23.0000 - val_fp: 7.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 194/500\n",
            "18/18 - 0s - loss: 0.1982 - acc: 0.9222 - precision: 0.9419 - recall: 0.9000 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2491 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 195/500\n",
            "18/18 - 0s - loss: 0.1840 - acc: 0.9167 - precision: 0.8947 - recall: 0.9444 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.2753 - val_acc: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 196/500\n",
            "18/18 - 0s - loss: 0.2018 - acc: 0.9056 - precision: 0.9294 - recall: 0.8778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2628 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 197/500\n",
            "18/18 - 0s - loss: 0.1397 - acc: 0.9556 - precision: 0.9362 - recall: 0.9778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2426 - val_acc: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 198/500\n",
            "18/18 - 0s - loss: 0.1238 - acc: 0.9556 - precision: 0.9457 - recall: 0.9667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2265 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 199/500\n",
            "18/18 - 0s - loss: 0.1229 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2465 - val_acc: 0.8833 - val_precision: 0.8286 - val_recall: 0.9667 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 200/500\n",
            "18/18 - 0s - loss: 0.1946 - acc: 0.9389 - precision: 0.9247 - recall: 0.9556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2156 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 201/500\n",
            "18/18 - 0s - loss: 0.1716 - acc: 0.9444 - precision: 0.9545 - recall: 0.9333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2034 - val_acc: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 202/500\n",
            "18/18 - 0s - loss: 0.1340 - acc: 0.9444 - precision: 0.9167 - recall: 0.9778 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.2067 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 203/500\n",
            "18/18 - 0s - loss: 0.1631 - acc: 0.9444 - precision: 0.9545 - recall: 0.9333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2329 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 204/500\n",
            "18/18 - 0s - loss: 0.1335 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2261 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 205/500\n",
            "18/18 - 0s - loss: 0.2677 - acc: 0.9056 - precision: 0.8925 - recall: 0.9222 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.2072 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 206/500\n",
            "18/18 - 0s - loss: 0.1391 - acc: 0.9333 - precision: 0.9432 - recall: 0.9222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1991 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 207/500\n",
            "18/18 - 0s - loss: 0.2007 - acc: 0.9222 - precision: 0.9130 - recall: 0.9333 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.2007 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 208/500\n",
            "18/18 - 0s - loss: 0.1957 - acc: 0.9500 - precision: 0.9451 - recall: 0.9556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2040 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 209/500\n",
            "18/18 - 0s - loss: 0.1754 - acc: 0.9278 - precision: 0.9231 - recall: 0.9333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2073 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 210/500\n",
            "18/18 - 0s - loss: 0.1000 - acc: 0.9667 - precision: 0.9884 - recall: 0.9444 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.2189 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 211/500\n",
            "18/18 - 0s - loss: 0.2336 - acc: 0.9111 - precision: 0.9022 - recall: 0.9222 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2627 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 212/500\n",
            "18/18 - 0s - loss: 0.1836 - acc: 0.9222 - precision: 0.9419 - recall: 0.9000 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3056 - val_acc: 0.8667 - val_precision: 0.8056 - val_recall: 0.9667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 213/500\n",
            "18/18 - 0s - loss: 0.1700 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2384 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 214/500\n",
            "18/18 - 0s - loss: 0.1178 - acc: 0.9667 - precision: 0.9565 - recall: 0.9778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2335 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 215/500\n",
            "18/18 - 0s - loss: 0.1922 - acc: 0.9222 - precision: 0.9419 - recall: 0.9000 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2074 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 216/500\n",
            "18/18 - 0s - loss: 0.1241 - acc: 0.9556 - precision: 0.9767 - recall: 0.9333 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1828 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 217/500\n",
            "18/18 - 0s - loss: 0.0811 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1658 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 218/500\n",
            "18/18 - 0s - loss: 0.1976 - acc: 0.9278 - precision: 0.9140 - recall: 0.9444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.1607 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 219/500\n",
            "18/18 - 0s - loss: 0.1674 - acc: 0.9389 - precision: 0.9647 - recall: 0.9111 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2163 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 220/500\n",
            "18/18 - 0s - loss: 0.0975 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1844 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 221/500\n",
            "18/18 - 0s - loss: 0.1059 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2033 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 222/500\n",
            "18/18 - 0s - loss: 0.0683 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1803 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 223/500\n",
            "18/18 - 0s - loss: 0.0889 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1482 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 224/500\n",
            "18/18 - 0s - loss: 0.0859 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1524 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 225/500\n",
            "18/18 - 0s - loss: 0.1562 - acc: 0.9444 - precision: 0.9545 - recall: 0.9333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1389 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 226/500\n",
            "18/18 - 0s - loss: 0.0661 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1399 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 227/500\n",
            "18/18 - 0s - loss: 0.1208 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1433 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 228/500\n",
            "18/18 - 0s - loss: 0.0985 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1548 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 229/500\n",
            "18/18 - 0s - loss: 0.1149 - acc: 0.9556 - precision: 0.9457 - recall: 0.9667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1368 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 230/500\n",
            "18/18 - 0s - loss: 0.1937 - acc: 0.9389 - precision: 0.9540 - recall: 0.9222 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1620 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 231/500\n",
            "18/18 - 0s - loss: 0.1928 - acc: 0.9444 - precision: 0.9545 - recall: 0.9333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1439 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 232/500\n",
            "18/18 - 0s - loss: 0.1128 - acc: 0.9611 - precision: 0.9770 - recall: 0.9444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1595 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 233/500\n",
            "18/18 - 0s - loss: 0.1402 - acc: 0.9611 - precision: 0.9368 - recall: 0.9889 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2067 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 234/500\n",
            "18/18 - 0s - loss: 0.1482 - acc: 0.9278 - precision: 0.9231 - recall: 0.9333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.1688 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 235/500\n",
            "18/18 - 0s - loss: 0.0996 - acc: 0.9500 - precision: 0.9451 - recall: 0.9556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1327 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 236/500\n",
            "18/18 - 0s - loss: 0.1532 - acc: 0.9444 - precision: 0.9444 - recall: 0.9444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1360 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 237/500\n",
            "18/18 - 0s - loss: 0.0892 - acc: 0.9722 - precision: 0.9570 - recall: 0.9889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1346 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 238/500\n",
            "18/18 - 0s - loss: 0.1160 - acc: 0.9611 - precision: 0.9770 - recall: 0.9444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1265 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 239/500\n",
            "18/18 - 0s - loss: 0.0568 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1170 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 240/500\n",
            "18/18 - 0s - loss: 0.0739 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1095 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 241/500\n",
            "18/18 - 0s - loss: 0.1023 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1067 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 242/500\n",
            "18/18 - 0s - loss: 0.0627 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0961 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 243/500\n",
            "18/18 - 0s - loss: 0.1872 - acc: 0.9333 - precision: 0.9239 - recall: 0.9444 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.1482 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 244/500\n",
            "18/18 - 0s - loss: 0.1078 - acc: 0.9667 - precision: 0.9884 - recall: 0.9444 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1598 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 245/500\n",
            "18/18 - 0s - loss: 0.1283 - acc: 0.9611 - precision: 0.9278 - recall: 1.0000 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.1563 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 246/500\n",
            "18/18 - 0s - loss: 0.1449 - acc: 0.9556 - precision: 0.9767 - recall: 0.9333 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1243 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 247/500\n",
            "18/18 - 0s - loss: 0.0765 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1224 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 248/500\n",
            "18/18 - 0s - loss: 0.0939 - acc: 0.9667 - precision: 0.9884 - recall: 0.9444 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1100 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 249/500\n",
            "18/18 - 0s - loss: 0.1187 - acc: 0.9722 - precision: 0.9885 - recall: 0.9556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1126 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 250/500\n",
            "18/18 - 0s - loss: 0.0842 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1250 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 251/500\n",
            "18/18 - 0s - loss: 0.0464 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1185 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 252/500\n",
            "18/18 - 0s - loss: 0.0688 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0938 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 253/500\n",
            "18/18 - 0s - loss: 0.0670 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0982 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 254/500\n",
            "18/18 - 0s - loss: 0.1397 - acc: 0.9444 - precision: 0.9651 - recall: 0.9222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1027 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 255/500\n",
            "18/18 - 0s - loss: 0.1210 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1180 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 256/500\n",
            "18/18 - 0s - loss: 0.1572 - acc: 0.9167 - precision: 0.9032 - recall: 0.9333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.1183 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 257/500\n",
            "18/18 - 0s - loss: 0.1030 - acc: 0.9667 - precision: 0.9884 - recall: 0.9444 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1035 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 258/500\n",
            "18/18 - 0s - loss: 0.0773 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1458 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 259/500\n",
            "18/18 - 0s - loss: 0.1232 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1032 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 260/500\n",
            "18/18 - 0s - loss: 0.0730 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1163 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 261/500\n",
            "18/18 - 0s - loss: 0.1178 - acc: 0.9556 - precision: 0.9659 - recall: 0.9444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1015 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 262/500\n",
            "18/18 - 0s - loss: 0.1358 - acc: 0.9611 - precision: 0.9770 - recall: 0.9444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0921 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 263/500\n",
            "18/18 - 0s - loss: 0.0752 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1310 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 264/500\n",
            "18/18 - 0s - loss: 0.0471 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0768 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 265/500\n",
            "18/18 - 0s - loss: 0.0410 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0794 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 266/500\n",
            "18/18 - 0s - loss: 0.0833 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0695 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 267/500\n",
            "18/18 - 0s - loss: 0.0409 - acc: 0.9944 - precision: 1.0000 - recall: 0.9889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0569 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 268/500\n",
            "18/18 - 0s - loss: 0.0957 - acc: 0.9667 - precision: 0.9773 - recall: 0.9556 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0761 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 269/500\n",
            "18/18 - 0s - loss: 0.0936 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0745 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 270/500\n",
            "18/18 - 0s - loss: 0.0444 - acc: 0.9944 - precision: 0.9890 - recall: 1.0000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0690 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 271/500\n",
            "18/18 - 0s - loss: 0.0667 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0992 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 272/500\n",
            "18/18 - 0s - loss: 0.1082 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0712 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 273/500\n",
            "18/18 - 0s - loss: 0.0544 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0831 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 274/500\n",
            "18/18 - 0s - loss: 0.0472 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0660 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 275/500\n",
            "18/18 - 0s - loss: 0.0858 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1632 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 276/500\n",
            "18/18 - 0s - loss: 0.0681 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0631 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 277/500\n",
            "18/18 - 0s - loss: 0.0896 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0892 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 278/500\n",
            "18/18 - 0s - loss: 0.0683 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0738 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 279/500\n",
            "18/18 - 0s - loss: 0.0768 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0804 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 280/500\n",
            "18/18 - 0s - loss: 0.1154 - acc: 0.9611 - precision: 0.9770 - recall: 0.9444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0777 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 281/500\n",
            "18/18 - 0s - loss: 0.1384 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0745 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 282/500\n",
            "18/18 - 0s - loss: 0.0787 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0493 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 283/500\n",
            "18/18 - 0s - loss: 0.0247 - acc: 0.9889 - precision: 0.9783 - recall: 1.0000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0927 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 284/500\n",
            "18/18 - 0s - loss: 0.0694 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0788 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 285/500\n",
            "18/18 - 0s - loss: 0.0668 - acc: 0.9889 - precision: 1.0000 - recall: 0.9778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0446 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 286/500\n",
            "18/18 - 0s - loss: 0.1038 - acc: 0.9611 - precision: 0.9462 - recall: 0.9778 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.0532 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 287/500\n",
            "18/18 - 0s - loss: 0.0606 - acc: 0.9722 - precision: 0.9885 - recall: 0.9556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0568 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 288/500\n",
            "18/18 - 0s - loss: 0.1501 - acc: 0.9444 - precision: 0.9545 - recall: 0.9333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0922 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 289/500\n",
            "18/18 - 0s - loss: 0.0982 - acc: 0.9667 - precision: 0.9565 - recall: 0.9778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0890 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 290/500\n",
            "18/18 - 0s - loss: 0.0763 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0844 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 291/500\n",
            "18/18 - 0s - loss: 0.0411 - acc: 0.9833 - precision: 1.0000 - recall: 0.9667 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0718 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 292/500\n",
            "18/18 - 0s - loss: 0.1117 - acc: 0.9611 - precision: 0.9462 - recall: 0.9778 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1257 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 293/500\n",
            "18/18 - 0s - loss: 0.0610 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0705 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 294/500\n",
            "18/18 - 0s - loss: 0.0454 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0756 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 295/500\n",
            "18/18 - 0s - loss: 0.0455 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0698 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 296/500\n",
            "18/18 - 0s - loss: 0.0670 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0588 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 297/500\n",
            "18/18 - 0s - loss: 0.0541 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0764 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 298/500\n",
            "18/18 - 0s - loss: 0.0406 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0425 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 299/500\n",
            "18/18 - 0s - loss: 0.0969 - acc: 0.9667 - precision: 0.9565 - recall: 0.9778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0865 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 300/500\n",
            "18/18 - 0s - loss: 0.0823 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1158 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 301/500\n",
            "18/18 - 0s - loss: 0.0677 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0563 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 302/500\n",
            "18/18 - 0s - loss: 0.1057 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0757 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 303/500\n",
            "18/18 - 0s - loss: 0.1215 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0506 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 304/500\n",
            "18/18 - 0s - loss: 0.0705 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0652 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 305/500\n",
            "18/18 - 0s - loss: 0.0700 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0695 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 306/500\n",
            "18/18 - 0s - loss: 0.0749 - acc: 0.9667 - precision: 0.9773 - recall: 0.9556 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0536 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 307/500\n",
            "18/18 - 0s - loss: 0.0748 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0388 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 308/500\n",
            "18/18 - 0s - loss: 0.0813 - acc: 0.9833 - precision: 1.0000 - recall: 0.9667 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0384 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 309/500\n",
            "18/18 - 0s - loss: 0.0518 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0453 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 310/500\n",
            "18/18 - 0s - loss: 0.0706 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0325 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 311/500\n",
            "18/18 - 0s - loss: 0.0871 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0309 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 312/500\n",
            "18/18 - 0s - loss: 0.0195 - acc: 0.9944 - precision: 0.9890 - recall: 1.0000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0318 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 313/500\n",
            "18/18 - 0s - loss: 0.0409 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0403 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 314/500\n",
            "18/18 - 0s - loss: 0.0514 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 315/500\n",
            "18/18 - 0s - loss: 0.0227 - acc: 0.9944 - precision: 0.9890 - recall: 1.0000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0594 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 316/500\n",
            "18/18 - 0s - loss: 0.0281 - acc: 0.9889 - precision: 1.0000 - recall: 0.9778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0180 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 317/500\n",
            "18/18 - 0s - loss: 0.0613 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0342 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 318/500\n",
            "18/18 - 0s - loss: 0.1049 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0224 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 319/500\n",
            "18/18 - 0s - loss: 0.1586 - acc: 0.9500 - precision: 0.9655 - recall: 0.9333 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0362 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 320/500\n",
            "18/18 - 0s - loss: 0.1000 - acc: 0.9556 - precision: 0.9457 - recall: 0.9667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.0595 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 321/500\n",
            "18/18 - 0s - loss: 0.0634 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0406 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 322/500\n",
            "18/18 - 0s - loss: 0.0506 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0356 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 323/500\n",
            "18/18 - 0s - loss: 0.0564 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0423 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 324/500\n",
            "18/18 - 0s - loss: 0.0635 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0282 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 325/500\n",
            "18/18 - 0s - loss: 0.0497 - acc: 0.9889 - precision: 1.0000 - recall: 0.9778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0260 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 326/500\n",
            "18/18 - 0s - loss: 0.0856 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0468 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 327/500\n",
            "18/18 - 0s - loss: 0.0681 - acc: 0.9611 - precision: 0.9462 - recall: 0.9778 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.0388 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 328/500\n",
            "18/18 - 0s - loss: 0.0512 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0406 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 329/500\n",
            "18/18 - 0s - loss: 0.0382 - acc: 0.9889 - precision: 1.0000 - recall: 0.9778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0323 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 330/500\n",
            "18/18 - 0s - loss: 0.0655 - acc: 0.9722 - precision: 0.9570 - recall: 0.9889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0857 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 331/500\n",
            "18/18 - 0s - loss: 0.1058 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0505 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 332/500\n",
            "18/18 - 0s - loss: 0.0602 - acc: 0.9833 - precision: 1.0000 - recall: 0.9667 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0428 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 333/500\n",
            "18/18 - 0s - loss: 0.0396 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0406 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 334/500\n",
            "18/18 - 0s - loss: 0.0247 - acc: 0.9944 - precision: 0.9890 - recall: 1.0000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0626 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 335/500\n",
            "18/18 - 0s - loss: 0.0926 - acc: 0.9500 - precision: 0.9451 - recall: 0.9556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.0436 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 336/500\n",
            "18/18 - 0s - loss: 0.0110 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0608 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 337/500\n",
            "18/18 - 0s - loss: 0.0352 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0300 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 338/500\n",
            "18/18 - 0s - loss: 0.0591 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0345 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 339/500\n",
            "18/18 - 0s - loss: 0.0465 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0243 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 340/500\n",
            "18/18 - 0s - loss: 0.0310 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 341/500\n",
            "18/18 - 0s - loss: 0.0378 - acc: 0.9889 - precision: 1.0000 - recall: 0.9778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0250 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0180 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.0000 - fp: 0.0000e+00    \n",
            "loss:\n",
            "[0.018027830868959427, 1.0, 1.0, 1.0, 30.0, 0.0]\n",
            "['loss', 'acc', 'precision', 'recall', 'tn', 'fp']\n",
            "Training and evaluating on fold 4 out of 8...\n",
            "train_index[  0   2   3   6   7   9  10  11  12  13  14  17  18  19  20  21  22  24\n",
            "  25  27  28  29  30  32  33  36  37  39  40  41  42  44  45  46  47  48\n",
            "  49  51  52  56  57  58  59  60  61  63  65  66  67  68  69  70  71  72\n",
            "  73  76  78  79  80  81  82  83  84  85  86  87  88  90  92  94  95  96\n",
            "  97  98  99 100 101 102 103 104 105 106 108 109 110 111 114 115 116 117\n",
            " 120 121 122 124 125 126 128 129 130 131 132 133 134 135 138 139 141 142\n",
            " 143 144 146 147 148 150 151 152 154 155 157 158 159 160 161 162 163 165\n",
            " 166 167 168 169 170 171 173 174 175 176 178 184 186 187 189 190 191 192\n",
            " 194 195 196 197 198 200 201 202 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 222 224 225 226 228 229 230 232 233 234 235 236 237 238 239]\n",
            "test_index[  1   4   5   8  15  16  23  26  31  34  35  38  43  50  53  54  55  62\n",
            "  64  74  75  77  89  91  93 107 112 113 118 119 123 127 136 137 140 145\n",
            " 149 153 156 164 172 177 179 180 181 182 183 185 188 193 199 203 204 205\n",
            " 219 220 221 223 227 231]\n",
            "Epoch 1/500\n",
            "18/18 - 2s - loss: 0.7419 - acc: 0.4444 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.6942 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 2/500\n",
            "18/18 - 0s - loss: 0.6976 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 3/500\n",
            "18/18 - 0s - loss: 0.6936 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 4/500\n",
            "18/18 - 0s - loss: 0.6967 - acc: 0.3278 - precision: 0.3578 - recall: 0.4333 - tn: 20.0000 - fp: 70.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 5/500\n",
            "18/18 - 0s - loss: 0.6953 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 6/500\n",
            "18/18 - 0s - loss: 0.7015 - acc: 0.3000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 54.0000 - fp: 36.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 7/500\n",
            "18/18 - 0s - loss: 0.6958 - acc: 0.4000 - precision: 0.3548 - recall: 0.2444 - tn: 50.0000 - fp: 40.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 8/500\n",
            "18/18 - 0s - loss: 0.6962 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 9/500\n",
            "18/18 - 0s - loss: 0.6955 - acc: 0.4556 - precision: 0.4767 - recall: 0.9111 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 10/500\n",
            "18/18 - 0s - loss: 0.6953 - acc: 0.4000 - precision: 0.3548 - recall: 0.2444 - tn: 50.0000 - fp: 40.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 11/500\n",
            "18/18 - 0s - loss: 0.6942 - acc: 0.5056 - precision: 0.6667 - recall: 0.0222 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 0.0333 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 12/500\n",
            "18/18 - 0s - loss: 0.6938 - acc: 0.3778 - precision: 0.3429 - recall: 0.2667 - tn: 44.0000 - fp: 46.0000 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 13/500\n",
            "18/18 - 0s - loss: 0.6928 - acc: 0.5167 - precision: 1.0000 - recall: 0.0333 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 14/500\n",
            "18/18 - 0s - loss: 0.6924 - acc: 0.5222 - precision: 0.8333 - recall: 0.0556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6926 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 15/500\n",
            "18/18 - 0s - loss: 0.6965 - acc: 0.4056 - precision: 0.4261 - recall: 0.5444 - tn: 24.0000 - fp: 66.0000 - val_loss: 0.6929 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 16/500\n",
            "18/18 - 0s - loss: 0.6884 - acc: 0.5500 - precision: 0.5918 - recall: 0.3222 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.6911 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 17/500\n",
            "18/18 - 0s - loss: 0.6989 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6924 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 18/500\n",
            "18/18 - 0s - loss: 0.6898 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6907 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 19/500\n",
            "18/18 - 0s - loss: 0.6614 - acc: 0.6167 - precision: 0.6296 - recall: 0.5667 - tn: 60.0000 - fp: 30.0000 - val_loss: 0.6882 - val_acc: 0.5833 - val_precision: 1.0000 - val_recall: 0.1667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 20/500\n",
            "18/18 - 0s - loss: 0.6599 - acc: 0.4778 - precision: 0.4821 - recall: 0.6000 - tn: 32.0000 - fp: 58.0000 - val_loss: 0.6887 - val_acc: 0.5500 - val_precision: 1.0000 - val_recall: 0.1000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 21/500\n",
            "18/18 - 0s - loss: 0.6440 - acc: 0.6167 - precision: 0.9565 - recall: 0.2444 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6902 - val_acc: 0.5333 - val_precision: 1.0000 - val_recall: 0.0667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/500\n",
            "18/18 - 0s - loss: 0.6272 - acc: 0.6444 - precision: 1.0000 - recall: 0.2889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6790 - val_acc: 0.5833 - val_precision: 1.0000 - val_recall: 0.1667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 23/500\n",
            "18/18 - 0s - loss: 0.6256 - acc: 0.6167 - precision: 0.6479 - recall: 0.5111 - tn: 65.0000 - fp: 25.0000 - val_loss: 0.6679 - val_acc: 0.5833 - val_precision: 0.7778 - val_recall: 0.2333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 24/500\n",
            "18/18 - 0s - loss: 0.6081 - acc: 0.6444 - precision: 0.7600 - recall: 0.4222 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.6711 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 25/500\n",
            "18/18 - 0s - loss: 0.5929 - acc: 0.6722 - precision: 0.8780 - recall: 0.4000 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.6668 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 26/500\n",
            "18/18 - 0s - loss: 0.5766 - acc: 0.6778 - precision: 0.7963 - recall: 0.4778 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.6704 - val_acc: 0.5833 - val_precision: 1.0000 - val_recall: 0.1667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 27/500\n",
            "18/18 - 0s - loss: 0.5905 - acc: 0.6389 - precision: 0.7551 - recall: 0.4111 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.6636 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 28/500\n",
            "18/18 - 0s - loss: 0.5539 - acc: 0.7222 - precision: 0.8704 - recall: 0.5222 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.6737 - val_acc: 0.5667 - val_precision: 1.0000 - val_recall: 0.1333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 29/500\n",
            "18/18 - 0s - loss: 0.5789 - acc: 0.6722 - precision: 0.9429 - recall: 0.3667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.6724 - val_acc: 0.5667 - val_precision: 1.0000 - val_recall: 0.1333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 30/500\n",
            "18/18 - 0s - loss: 0.5755 - acc: 0.6722 - precision: 0.7818 - recall: 0.4778 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.6580 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 31/500\n",
            "18/18 - 0s - loss: 0.5543 - acc: 0.7111 - precision: 0.8958 - recall: 0.4778 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.6386 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 32/500\n",
            "18/18 - 0s - loss: 0.5304 - acc: 0.7167 - precision: 0.8421 - recall: 0.5333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.6441 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 33/500\n",
            "18/18 - 0s - loss: 0.5984 - acc: 0.7056 - precision: 0.7937 - recall: 0.5556 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.6489 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 34/500\n",
            "18/18 - 0s - loss: 0.5403 - acc: 0.7333 - precision: 0.9375 - recall: 0.5000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.6339 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 35/500\n",
            "18/18 - 0s - loss: 0.5358 - acc: 0.7111 - precision: 0.8393 - recall: 0.5222 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.6297 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 36/500\n",
            "18/18 - 0s - loss: 0.4983 - acc: 0.7556 - precision: 0.9259 - recall: 0.5556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5929 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 37/500\n",
            "18/18 - 0s - loss: 0.4899 - acc: 0.8000 - precision: 0.8462 - recall: 0.7333 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.6481 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 38/500\n",
            "18/18 - 0s - loss: 0.5664 - acc: 0.6778 - precision: 0.9211 - recall: 0.3889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.6598 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 39/500\n",
            "18/18 - 0s - loss: 0.5595 - acc: 0.6944 - precision: 0.8182 - recall: 0.5000 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.6520 - val_acc: 0.5833 - val_precision: 1.0000 - val_recall: 0.1667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 40/500\n",
            "18/18 - 0s - loss: 0.5301 - acc: 0.7222 - precision: 0.9000 - recall: 0.5000 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.6046 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 41/500\n",
            "18/18 - 0s - loss: 0.5000 - acc: 0.7556 - precision: 0.8382 - recall: 0.6333 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.6056 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 42/500\n",
            "18/18 - 0s - loss: 0.4718 - acc: 0.7833 - precision: 0.9474 - recall: 0.6000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5951 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 43/500\n",
            "18/18 - 0s - loss: 0.4543 - acc: 0.8056 - precision: 0.8395 - recall: 0.7556 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.6378 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 44/500\n",
            "18/18 - 0s - loss: 0.4995 - acc: 0.7444 - precision: 0.9400 - recall: 0.5222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5848 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 45/500\n",
            "18/18 - 0s - loss: 0.4806 - acc: 0.7167 - precision: 0.7746 - recall: 0.6111 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5847 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 46/500\n",
            "18/18 - 0s - loss: 0.5326 - acc: 0.7667 - precision: 0.8636 - recall: 0.6333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5790 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 47/500\n",
            "18/18 - 0s - loss: 0.4664 - acc: 0.7500 - precision: 0.9412 - recall: 0.5333 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.6005 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 48/500\n",
            "18/18 - 0s - loss: 0.4516 - acc: 0.7722 - precision: 0.9298 - recall: 0.5889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5534 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 49/500\n",
            "18/18 - 0s - loss: 0.5639 - acc: 0.6944 - precision: 0.7778 - recall: 0.5444 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.5772 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 50/500\n",
            "18/18 - 0s - loss: 0.4643 - acc: 0.7667 - precision: 0.9286 - recall: 0.5778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5756 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 51/500\n",
            "18/18 - 0s - loss: 0.4363 - acc: 0.7833 - precision: 0.8592 - recall: 0.6778 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5699 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 52/500\n",
            "18/18 - 0s - loss: 0.3886 - acc: 0.8111 - precision: 0.8684 - recall: 0.7333 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.6168 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 53/500\n",
            "18/18 - 0s - loss: 0.4366 - acc: 0.7833 - precision: 0.8806 - recall: 0.6556 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5947 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 54/500\n",
            "18/18 - 0s - loss: 0.4318 - acc: 0.8056 - precision: 0.8667 - recall: 0.7222 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5949 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 55/500\n",
            "18/18 - 0s - loss: 0.4061 - acc: 0.8000 - precision: 0.9500 - recall: 0.6333 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.6221 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 56/500\n",
            "18/18 - 0s - loss: 0.3845 - acc: 0.8222 - precision: 0.9028 - recall: 0.7222 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5779 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57/500\n",
            "18/18 - 0s - loss: 0.3604 - acc: 0.8389 - precision: 0.9296 - recall: 0.7333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.6164 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 58/500\n",
            "18/18 - 0s - loss: 0.3687 - acc: 0.8556 - precision: 0.9324 - recall: 0.7667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.6565 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 59/500\n",
            "18/18 - 0s - loss: 0.4447 - acc: 0.8111 - precision: 0.9516 - recall: 0.6556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5511 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 60/500\n",
            "18/18 - 0s - loss: 0.4830 - acc: 0.8111 - precision: 0.8182 - recall: 0.8000 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5840 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 61/500\n",
            "18/18 - 0s - loss: 0.4188 - acc: 0.7889 - precision: 0.9194 - recall: 0.6333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5794 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 62/500\n",
            "18/18 - 0s - loss: 0.4089 - acc: 0.8167 - precision: 0.9385 - recall: 0.6778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5715 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 63/500\n",
            "18/18 - 0s - loss: 0.3948 - acc: 0.8056 - precision: 0.9231 - recall: 0.6667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5920 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 64/500\n",
            "18/18 - 0s - loss: 0.3472 - acc: 0.8611 - precision: 0.8571 - recall: 0.8667 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5631 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 65/500\n",
            "18/18 - 0s - loss: 0.3566 - acc: 0.8389 - precision: 0.9420 - recall: 0.7222 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5942 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 66/500\n",
            "18/18 - 0s - loss: 0.3841 - acc: 0.8278 - precision: 0.8831 - recall: 0.7556 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5812 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 67/500\n",
            "18/18 - 0s - loss: 0.4618 - acc: 0.7889 - precision: 0.9194 - recall: 0.6333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5509 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 68/500\n",
            "18/18 - 0s - loss: 0.3506 - acc: 0.8556 - precision: 0.9444 - recall: 0.7556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5849 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 69/500\n",
            "18/18 - 0s - loss: 0.4172 - acc: 0.8056 - precision: 0.9231 - recall: 0.6667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5397 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 70/500\n",
            "18/18 - 0s - loss: 0.4681 - acc: 0.7833 - precision: 0.8312 - recall: 0.7111 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5613 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 71/500\n",
            "18/18 - 0s - loss: 0.3768 - acc: 0.8278 - precision: 0.9403 - recall: 0.7000 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5411 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 72/500\n",
            "18/18 - 0s - loss: 0.3181 - acc: 0.8556 - precision: 0.9103 - recall: 0.7889 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5661 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 73/500\n",
            "18/18 - 0s - loss: 0.4033 - acc: 0.8111 - precision: 0.8889 - recall: 0.7111 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5801 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 74/500\n",
            "18/18 - 0s - loss: 0.3570 - acc: 0.8278 - precision: 0.8831 - recall: 0.7556 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.6247 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 75/500\n",
            "18/18 - 0s - loss: 0.3762 - acc: 0.8167 - precision: 0.9254 - recall: 0.6889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5868 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 76/500\n",
            "18/18 - 0s - loss: 0.3634 - acc: 0.8222 - precision: 0.8452 - recall: 0.7889 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.6021 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 77/500\n",
            "18/18 - 0s - loss: 0.3683 - acc: 0.8278 - precision: 0.9683 - recall: 0.6778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5545 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 78/500\n",
            "18/18 - 0s - loss: 0.4638 - acc: 0.8222 - precision: 0.8021 - recall: 0.8556 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.6244 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 79/500\n",
            "18/18 - 0s - loss: 0.5611 - acc: 0.7000 - precision: 1.0000 - recall: 0.4000 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6463 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 80/500\n",
            "18/18 - 0s - loss: 0.5047 - acc: 0.7333 - precision: 1.0000 - recall: 0.4667 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5622 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 81/500\n",
            "18/18 - 0s - loss: 0.4648 - acc: 0.7778 - precision: 0.9032 - recall: 0.6222 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5467 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 82/500\n",
            "18/18 - 0s - loss: 0.4261 - acc: 0.8111 - precision: 0.9516 - recall: 0.6556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5459 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 83/500\n",
            "18/18 - 0s - loss: 0.4015 - acc: 0.8056 - precision: 0.8873 - recall: 0.7000 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4939 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 84/500\n",
            "18/18 - 0s - loss: 0.3758 - acc: 0.8500 - precision: 0.8621 - recall: 0.8333 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.5519 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 85/500\n",
            "18/18 - 0s - loss: 0.3551 - acc: 0.8278 - precision: 0.8831 - recall: 0.7556 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5686 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 86/500\n",
            "18/18 - 0s - loss: 0.3927 - acc: 0.8222 - precision: 0.9394 - recall: 0.6889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5206 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 87/500\n",
            "18/18 - 0s - loss: 0.3827 - acc: 0.8167 - precision: 0.8701 - recall: 0.7444 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5598 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 88/500\n",
            "18/18 - 0s - loss: 0.3374 - acc: 0.8333 - precision: 0.9412 - recall: 0.7111 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5116 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 89/500\n",
            "18/18 - 0s - loss: 0.3416 - acc: 0.8278 - precision: 0.8471 - recall: 0.8000 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.6010 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 90/500\n",
            "18/18 - 0s - loss: 0.3244 - acc: 0.8833 - precision: 0.9859 - recall: 0.7778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5200 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 91/500\n",
            "18/18 - 0s - loss: 0.3442 - acc: 0.8444 - precision: 0.8605 - recall: 0.8222 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.5982 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 92/500\n",
            "18/18 - 0s - loss: 0.2772 - acc: 0.8944 - precision: 0.9733 - recall: 0.8111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4922 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 93/500\n",
            "18/18 - 0s - loss: 0.3372 - acc: 0.8444 - precision: 0.8780 - recall: 0.8000 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5538 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 94/500\n",
            "18/18 - 0s - loss: 0.2530 - acc: 0.9167 - precision: 0.9630 - recall: 0.8667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5133 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 95/500\n",
            "18/18 - 0s - loss: 0.3752 - acc: 0.8500 - precision: 0.9315 - recall: 0.7556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.6000 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 96/500\n",
            "18/18 - 0s - loss: 0.2380 - acc: 0.9000 - precision: 0.9737 - recall: 0.8222 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5131 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 97/500\n",
            "18/18 - 0s - loss: 0.2884 - acc: 0.8778 - precision: 0.9250 - recall: 0.8222 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5654 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 98/500\n",
            "18/18 - 0s - loss: 0.3210 - acc: 0.8778 - precision: 0.9048 - recall: 0.8444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4925 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 99/500\n",
            "18/18 - 0s - loss: 0.3717 - acc: 0.8278 - precision: 0.9155 - recall: 0.7222 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5494 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 100/500\n",
            "18/18 - 0s - loss: 0.3055 - acc: 0.8667 - precision: 0.9459 - recall: 0.7778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4782 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 101/500\n",
            "18/18 - 0s - loss: 0.2797 - acc: 0.8778 - precision: 0.9474 - recall: 0.8000 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4799 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 102/500\n",
            "18/18 - 0s - loss: 0.3024 - acc: 0.8444 - precision: 0.9189 - recall: 0.7556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4528 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 103/500\n",
            "18/18 - 0s - loss: 0.3236 - acc: 0.8333 - precision: 0.8947 - recall: 0.7556 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4708 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 104/500\n",
            "18/18 - 0s - loss: 0.2865 - acc: 0.8889 - precision: 0.8977 - recall: 0.8778 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5087 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 105/500\n",
            "18/18 - 0s - loss: 0.2751 - acc: 0.8667 - precision: 0.8929 - recall: 0.8333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5034 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 106/500\n",
            "18/18 - 0s - loss: 0.2441 - acc: 0.9111 - precision: 0.9744 - recall: 0.8444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4795 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 107/500\n",
            "18/18 - 0s - loss: 0.3692 - acc: 0.8444 - precision: 0.9079 - recall: 0.7667 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5942 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 108/500\n",
            "18/18 - 0s - loss: 0.4088 - acc: 0.8333 - precision: 0.9054 - recall: 0.7444 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4778 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 109/500\n",
            "18/18 - 0s - loss: 0.3010 - acc: 0.8944 - precision: 0.9383 - recall: 0.8444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5572 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 110/500\n",
            "18/18 - 0s - loss: 0.2800 - acc: 0.8667 - precision: 0.9459 - recall: 0.7778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5272 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 111/500\n",
            "18/18 - 0s - loss: 0.2226 - acc: 0.9111 - precision: 0.9625 - recall: 0.8556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5424 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 112/500\n",
            "18/18 - 0s - loss: 0.2537 - acc: 0.8889 - precision: 0.9070 - recall: 0.8667 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5386 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 113/500\n",
            "18/18 - 0s - loss: 0.2866 - acc: 0.8556 - precision: 0.9211 - recall: 0.7778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5095 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 114/500\n",
            "18/18 - 0s - loss: 0.2402 - acc: 0.9111 - precision: 0.9205 - recall: 0.9000 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5271 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 115/500\n",
            "18/18 - 0s - loss: 0.2375 - acc: 0.9000 - precision: 0.9500 - recall: 0.8444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5057 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 116/500\n",
            "18/18 - 0s - loss: 0.2182 - acc: 0.9111 - precision: 0.9625 - recall: 0.8556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5491 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 117/500\n",
            "18/18 - 0s - loss: 0.2150 - acc: 0.9111 - precision: 0.9625 - recall: 0.8556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5073 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 118/500\n",
            "18/18 - 0s - loss: 0.3091 - acc: 0.8889 - precision: 0.9730 - recall: 0.8000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4976 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 119/500\n",
            "18/18 - 0s - loss: 0.2251 - acc: 0.9111 - precision: 0.9302 - recall: 0.8889 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5182 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 120/500\n",
            "18/18 - 0s - loss: 0.3198 - acc: 0.8500 - precision: 0.8795 - recall: 0.8111 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4865 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 121/500\n",
            "18/18 - 0s - loss: 0.2582 - acc: 0.8889 - precision: 0.9375 - recall: 0.8333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5339 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 122/500\n",
            "18/18 - 0s - loss: 0.2275 - acc: 0.9167 - precision: 0.9412 - recall: 0.8889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5209 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 123/500\n",
            "18/18 - 0s - loss: 0.2135 - acc: 0.9222 - precision: 0.9872 - recall: 0.8556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4944 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 124/500\n",
            "18/18 - 0s - loss: 0.2882 - acc: 0.9000 - precision: 0.9286 - recall: 0.8667 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5110 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 125/500\n",
            "18/18 - 0s - loss: 0.2345 - acc: 0.9000 - precision: 0.9390 - recall: 0.8556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5271 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 126/500\n",
            "18/18 - 0s - loss: 0.1505 - acc: 0.9278 - precision: 0.9753 - recall: 0.8778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4118 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 127/500\n",
            "18/18 - 0s - loss: 0.2567 - acc: 0.8778 - precision: 0.8953 - recall: 0.8556 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4775 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 128/500\n",
            "18/18 - 0s - loss: 0.2011 - acc: 0.9111 - precision: 0.9302 - recall: 0.8889 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4951 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 129/500\n",
            "18/18 - 0s - loss: 0.2996 - acc: 0.8444 - precision: 0.9079 - recall: 0.7667 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4580 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 130/500\n",
            "18/18 - 0s - loss: 0.1767 - acc: 0.9278 - precision: 0.9326 - recall: 0.9222 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4833 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 131/500\n",
            "18/18 - 0s - loss: 0.2244 - acc: 0.9111 - precision: 0.9625 - recall: 0.8556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4602 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 132/500\n",
            "18/18 - 0s - loss: 0.2530 - acc: 0.9167 - precision: 0.9121 - recall: 0.9222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4600 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 133/500\n",
            "18/18 - 0s - loss: 0.1944 - acc: 0.9333 - precision: 0.9535 - recall: 0.9111 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5287 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 134/500\n",
            "18/18 - 0s - loss: 0.1609 - acc: 0.9389 - precision: 1.0000 - recall: 0.8778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.4268 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 135/500\n",
            "18/18 - 0s - loss: 0.2122 - acc: 0.9056 - precision: 0.9294 - recall: 0.8778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5234 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 136/500\n",
            "18/18 - 0s - loss: 0.1515 - acc: 0.9444 - precision: 0.9878 - recall: 0.9000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4449 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 137/500\n",
            "18/18 - 0s - loss: 0.2745 - acc: 0.8667 - precision: 0.9024 - recall: 0.8222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4976 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 138/500\n",
            "18/18 - 0s - loss: 0.2487 - acc: 0.8944 - precision: 0.9277 - recall: 0.8556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4661 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 139/500\n",
            "18/18 - 0s - loss: 0.1402 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4579 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 140/500\n",
            "18/18 - 0s - loss: 0.1948 - acc: 0.9222 - precision: 0.9524 - recall: 0.8889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4192 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 141/500\n",
            "18/18 - 0s - loss: 0.1967 - acc: 0.9222 - precision: 0.9419 - recall: 0.9000 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5074 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 142/500\n",
            "18/18 - 0s - loss: 0.2658 - acc: 0.8944 - precision: 0.9277 - recall: 0.8556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4593 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 143/500\n",
            "18/18 - 0s - loss: 0.1524 - acc: 0.9389 - precision: 0.9877 - recall: 0.8889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4547 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 144/500\n",
            "18/18 - 0s - loss: 0.2086 - acc: 0.9111 - precision: 0.9111 - recall: 0.9111 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4975 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 145/500\n",
            "18/18 - 0s - loss: 0.2601 - acc: 0.8889 - precision: 0.8804 - recall: 0.9000 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5482 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 146/500\n",
            "18/18 - 0s - loss: 0.1920 - acc: 0.9167 - precision: 0.9630 - recall: 0.8667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4459 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 147/500\n",
            "18/18 - 0s - loss: 0.1459 - acc: 0.9556 - precision: 0.9659 - recall: 0.9444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4122 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 148/500\n",
            "18/18 - 0s - loss: 0.1877 - acc: 0.9444 - precision: 0.9651 - recall: 0.9222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4632 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 149/500\n",
            "18/18 - 0s - loss: 0.1795 - acc: 0.9278 - precision: 0.9639 - recall: 0.8889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4023 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 150/500\n",
            "18/18 - 0s - loss: 0.2231 - acc: 0.9056 - precision: 0.9011 - recall: 0.9111 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5335 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 151/500\n",
            "18/18 - 0s - loss: 0.1265 - acc: 0.9500 - precision: 1.0000 - recall: 0.9000 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.4831 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 152/500\n",
            "18/18 - 0s - loss: 0.1465 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4407 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 153/500\n",
            "18/18 - 0s - loss: 0.1936 - acc: 0.9056 - precision: 0.9195 - recall: 0.8889 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4311 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 154/500\n",
            "18/18 - 0s - loss: 0.2116 - acc: 0.9278 - precision: 0.9425 - recall: 0.9111 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4311 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 155/500\n",
            "18/18 - 0s - loss: 0.1805 - acc: 0.9056 - precision: 0.9195 - recall: 0.8889 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3756 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 156/500\n",
            "18/18 - 0s - loss: 0.1210 - acc: 0.9556 - precision: 0.9659 - recall: 0.9444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4043 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 157/500\n",
            "18/18 - 0s - loss: 0.1374 - acc: 0.9611 - precision: 0.9882 - recall: 0.9333 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.3905 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 158/500\n",
            "18/18 - 0s - loss: 0.1360 - acc: 0.9444 - precision: 0.9545 - recall: 0.9333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4277 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 159/500\n",
            "18/18 - 0s - loss: 0.2266 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4622 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 160/500\n",
            "18/18 - 0s - loss: 0.1489 - acc: 0.9389 - precision: 0.9247 - recall: 0.9556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4901 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 161/500\n",
            "18/18 - 0s - loss: 0.1455 - acc: 0.9333 - precision: 0.9875 - recall: 0.8778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4122 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 162/500\n",
            "18/18 - 0s - loss: 0.1886 - acc: 0.9278 - precision: 0.9639 - recall: 0.8889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4989 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 163/500\n",
            "18/18 - 0s - loss: 0.1580 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5484 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 164/500\n",
            "18/18 - 0s - loss: 0.1121 - acc: 0.9611 - precision: 0.9882 - recall: 0.9333 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4777 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 165/500\n",
            "18/18 - 0s - loss: 0.1432 - acc: 0.9444 - precision: 0.9348 - recall: 0.9556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5847 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 166/500\n",
            "18/18 - 0s - loss: 0.0836 - acc: 0.9722 - precision: 0.9885 - recall: 0.9556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4642 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 167/500\n",
            "18/18 - 0s - loss: 0.1228 - acc: 0.9611 - precision: 0.9770 - recall: 0.9444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5443 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 168/500\n",
            "18/18 - 0s - loss: 0.1631 - acc: 0.9222 - precision: 0.9419 - recall: 0.9000 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5496 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 169/500\n",
            "18/18 - 0s - loss: 0.1210 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4220 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 170/500\n",
            "18/18 - 0s - loss: 0.1473 - acc: 0.9222 - precision: 0.9222 - recall: 0.9222 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4411 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 171/500\n",
            "18/18 - 0s - loss: 0.1003 - acc: 0.9556 - precision: 0.9659 - recall: 0.9444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4159 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 172/500\n",
            "18/18 - 0s - loss: 0.1170 - acc: 0.9389 - precision: 0.9759 - recall: 0.9000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4452 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 173/500\n",
            "18/18 - 0s - loss: 0.1482 - acc: 0.9278 - precision: 0.9231 - recall: 0.9333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4082 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 174/500\n",
            "18/18 - 0s - loss: 0.1113 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4441 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 175/500\n",
            "18/18 - 0s - loss: 0.1404 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4527 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 176/500\n",
            "18/18 - 0s - loss: 0.1178 - acc: 0.9556 - precision: 0.9659 - recall: 0.9444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5921 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 177/500\n",
            "18/18 - 0s - loss: 0.1212 - acc: 0.9500 - precision: 0.9451 - recall: 0.9556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4277 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 178/500\n",
            "18/18 - 0s - loss: 0.0662 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.7020 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 179/500\n",
            "18/18 - 0s - loss: 0.1846 - acc: 0.9389 - precision: 0.9540 - recall: 0.9222 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4911 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 180/500\n",
            "18/18 - 0s - loss: 0.1091 - acc: 0.9667 - precision: 0.9884 - recall: 0.9444 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5543 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.3756 - acc: 0.7167 - precision: 1.0000 - recall: 0.4333 - tn: 30.0000 - fp: 0.0000e+00    \n",
            "loss:\n",
            "[0.37562689185142517, 0.7166666388511658, 1.0, 0.4333333373069763, 30.0, 0.0]\n",
            "['loss', 'acc', 'precision', 'recall', 'tn', 'fp']\n",
            "Training and evaluating on fold 5 out of 8...\n",
            "train_index[  0   1   3   5   6   8   9  10  11  12  13  14  15  17  18  20  23  24\n",
            "  25  27  28  29  30  31  33  34  35  36  37  38  39  40  41  44  45  46\n",
            "  47  48  49  50  51  52  54  55  56  57  58  60  61  62  64  65  69  73\n",
            "  75  77  78  79  81  82  83  84  85  86  88  89  90  92  94  95  96  97\n",
            "  98  99 101 102 103 104 106 107 108 111 112 113 114 115 116 117 118 119\n",
            " 120 122 124 125 126 127 128 129 130 131 132 133 134 136 137 138 140 141\n",
            " 142 143 144 145 146 147 148 149 150 153 155 156 158 159 160 161 162 163\n",
            " 164 165 166 169 171 173 175 177 179 180 181 183 184 185 186 187 188 189\n",
            " 190 191 192 194 195 196 197 198 199 201 204 205 208 209 210 212 213 214\n",
            " 215 217 219 221 222 223 224 225 227 228 229 231 233 234 235 237 238 239]\n",
            "test_index[  2   4   7  16  19  21  22  26  32  42  43  53  59  63  66  67  68  70\n",
            "  71  72  74  76  80  87  91  93 100 105 109 110 121 123 135 139 151 152\n",
            " 154 157 167 168 170 172 174 176 178 182 193 200 202 203 206 207 211 216\n",
            " 218 220 226 230 232 236]\n",
            "Epoch 1/500\n",
            "18/18 - 2s - loss: 0.7045 - acc: 0.3667 - precision: 0.0385 - recall: 0.0111 - tn: 65.0000 - fp: 25.0000 - val_loss: 0.6943 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 2/500\n",
            "18/18 - 0s - loss: 0.6945 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6935 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 3/500\n",
            "18/18 - 0s - loss: 0.6970 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6935 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 4/500\n",
            "18/18 - 0s - loss: 0.6944 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 5/500\n",
            "18/18 - 0s - loss: 0.6956 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 6/500\n",
            "18/18 - 0s - loss: 0.6937 - acc: 0.5056 - precision: 1.0000 - recall: 0.0111 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 7/500\n",
            "18/18 - 0s - loss: 0.6941 - acc: 0.3056 - precision: 0.2840 - recall: 0.2556 - tn: 32.0000 - fp: 58.0000 - val_loss: 0.6931 - val_acc: 0.5167 - val_precision: 0.5455 - val_recall: 0.2000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 8/500\n",
            "18/18 - 0s - loss: 0.6954 - acc: 0.5000 - precision: 0.5000 - recall: 0.0222 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.6930 - val_acc: 0.5167 - val_precision: 0.5714 - val_recall: 0.1333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 9/500\n",
            "18/18 - 0s - loss: 0.6943 - acc: 0.3444 - precision: 0.3793 - recall: 0.4889 - tn: 18.0000 - fp: 72.0000 - val_loss: 0.6930 - val_acc: 0.5333 - val_precision: 1.0000 - val_recall: 0.0667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 10/500\n",
            "18/18 - 0s - loss: 0.6938 - acc: 0.4167 - precision: 0.4540 - recall: 0.8222 - tn: 1.0000 - fp: 89.0000 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/500\n",
            "18/18 - 0s - loss: 0.6944 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 12/500\n",
            "18/18 - 0s - loss: 0.6949 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6929 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 13/500\n",
            "18/18 - 0s - loss: 0.6909 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6926 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 14/500\n",
            "18/18 - 0s - loss: 0.6887 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6888 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 15/500\n",
            "18/18 - 0s - loss: 0.6815 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6844 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 16/500\n",
            "18/18 - 0s - loss: 0.6863 - acc: 0.3222 - precision: 0.3519 - recall: 0.4222 - tn: 20.0000 - fp: 70.0000 - val_loss: 0.6873 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 17/500\n",
            "18/18 - 0s - loss: 0.6622 - acc: 0.4889 - precision: 0.4937 - recall: 0.8667 - tn: 10.0000 - fp: 80.0000 - val_loss: 0.6532 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 18/500\n",
            "18/18 - 0s - loss: 0.7351 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6725 - val_acc: 0.6333 - val_precision: 0.7857 - val_recall: 0.3667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 19/500\n",
            "18/18 - 0s - loss: 0.6630 - acc: 0.6278 - precision: 0.7805 - recall: 0.3556 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.6674 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 20/500\n",
            "18/18 - 0s - loss: 0.6785 - acc: 0.3944 - precision: 0.4410 - recall: 0.7889 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6618 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 21/500\n",
            "18/18 - 0s - loss: 0.6416 - acc: 0.6556 - precision: 0.8889 - recall: 0.3556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.6546 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 22/500\n",
            "18/18 - 0s - loss: 0.6330 - acc: 0.6111 - precision: 0.6515 - recall: 0.4778 - tn: 67.0000 - fp: 23.0000 - val_loss: 0.6406 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 23/500\n",
            "18/18 - 0s - loss: 0.6473 - acc: 0.5444 - precision: 0.5465 - recall: 0.5222 - tn: 51.0000 - fp: 39.0000 - val_loss: 0.6327 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 24/500\n",
            "18/18 - 0s - loss: 0.6082 - acc: 0.6722 - precision: 0.7818 - recall: 0.4778 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.6255 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 25/500\n",
            "18/18 - 0s - loss: 0.6072 - acc: 0.6444 - precision: 0.7031 - recall: 0.5000 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.6099 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 26/500\n",
            "18/18 - 0s - loss: 0.5695 - acc: 0.6889 - precision: 0.8036 - recall: 0.5000 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.6139 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 27/500\n",
            "18/18 - 0s - loss: 0.5635 - acc: 0.6667 - precision: 0.7500 - recall: 0.5000 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.6152 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 28/500\n",
            "18/18 - 0s - loss: 0.5445 - acc: 0.7333 - precision: 0.8621 - recall: 0.5556 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.6070 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 29/500\n",
            "18/18 - 0s - loss: 0.6205 - acc: 0.6333 - precision: 0.7609 - recall: 0.3889 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.6313 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 30/500\n",
            "18/18 - 0s - loss: 0.5869 - acc: 0.6722 - precision: 0.9429 - recall: 0.3667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.6024 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 31/500\n",
            "18/18 - 0s - loss: 0.5873 - acc: 0.6556 - precision: 0.8043 - recall: 0.4111 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5976 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 32/500\n",
            "18/18 - 0s - loss: 0.5665 - acc: 0.6778 - precision: 0.8077 - recall: 0.4667 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5880 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 33/500\n",
            "18/18 - 0s - loss: 0.5537 - acc: 0.6833 - precision: 0.8113 - recall: 0.4778 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5873 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 34/500\n",
            "18/18 - 0s - loss: 0.5563 - acc: 0.6889 - precision: 0.8400 - recall: 0.4667 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5667 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 35/500\n",
            "18/18 - 0s - loss: 0.5101 - acc: 0.7333 - precision: 0.8088 - recall: 0.6111 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5993 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 36/500\n",
            "18/18 - 0s - loss: 0.5376 - acc: 0.7056 - precision: 0.8936 - recall: 0.4667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5632 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 37/500\n",
            "18/18 - 0s - loss: 0.5058 - acc: 0.7444 - precision: 0.7619 - recall: 0.7111 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.5867 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 38/500\n",
            "18/18 - 0s - loss: 0.5738 - acc: 0.6778 - precision: 1.0000 - recall: 0.3556 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6105 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 39/500\n",
            "18/18 - 0s - loss: 0.5450 - acc: 0.7056 - precision: 0.9111 - recall: 0.4556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5780 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 40/500\n",
            "18/18 - 0s - loss: 0.5326 - acc: 0.7222 - precision: 0.8448 - recall: 0.5444 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5764 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 41/500\n",
            "18/18 - 0s - loss: 0.4969 - acc: 0.7500 - precision: 0.9245 - recall: 0.5444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5685 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 42/500\n",
            "18/18 - 0s - loss: 0.5570 - acc: 0.7222 - precision: 0.8226 - recall: 0.5667 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.6034 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 43/500\n",
            "18/18 - 0s - loss: 0.5490 - acc: 0.6889 - precision: 0.9474 - recall: 0.4000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5761 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 44/500\n",
            "18/18 - 0s - loss: 0.5064 - acc: 0.7500 - precision: 0.8462 - recall: 0.6111 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5701 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 45/500\n",
            "18/18 - 0s - loss: 0.4972 - acc: 0.7500 - precision: 0.9592 - recall: 0.5222 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5723 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46/500\n",
            "18/18 - 0s - loss: 0.5063 - acc: 0.7667 - precision: 0.8529 - recall: 0.6444 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5705 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 47/500\n",
            "18/18 - 0s - loss: 0.4825 - acc: 0.7611 - precision: 0.9123 - recall: 0.5778 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5782 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 48/500\n",
            "18/18 - 0s - loss: 0.4793 - acc: 0.7556 - precision: 0.8710 - recall: 0.6000 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5653 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 49/500\n",
            "18/18 - 0s - loss: 0.4658 - acc: 0.7889 - precision: 0.8824 - recall: 0.6667 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5842 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 50/500\n",
            "18/18 - 0s - loss: 0.4761 - acc: 0.7667 - precision: 0.9615 - recall: 0.5556 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5676 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 51/500\n",
            "18/18 - 0s - loss: 0.5636 - acc: 0.7000 - precision: 0.7647 - recall: 0.5778 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5841 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 52/500\n",
            "18/18 - 0s - loss: 0.5237 - acc: 0.7278 - precision: 0.9362 - recall: 0.4889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5628 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 53/500\n",
            "18/18 - 0s - loss: 0.4555 - acc: 0.7778 - precision: 0.8472 - recall: 0.6778 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5538 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 54/500\n",
            "18/18 - 0s - loss: 0.4558 - acc: 0.7889 - precision: 0.8333 - recall: 0.7222 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5569 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 55/500\n",
            "18/18 - 0s - loss: 0.4221 - acc: 0.8222 - precision: 0.9833 - recall: 0.6556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5861 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 56/500\n",
            "18/18 - 0s - loss: 0.5010 - acc: 0.7444 - precision: 0.9583 - recall: 0.5111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5760 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 57/500\n",
            "18/18 - 0s - loss: 0.5033 - acc: 0.7667 - precision: 0.8077 - recall: 0.7000 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.5614 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 58/500\n",
            "18/18 - 0s - loss: 0.5498 - acc: 0.6944 - precision: 1.0000 - recall: 0.3889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5552 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 59/500\n",
            "18/18 - 0s - loss: 0.4935 - acc: 0.7667 - precision: 0.8636 - recall: 0.6333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5423 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 60/500\n",
            "18/18 - 0s - loss: 0.4629 - acc: 0.7889 - precision: 0.9194 - recall: 0.6333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5376 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 61/500\n",
            "18/18 - 0s - loss: 0.4821 - acc: 0.7667 - precision: 0.7927 - recall: 0.7222 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.5235 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 62/500\n",
            "18/18 - 0s - loss: 0.4346 - acc: 0.7500 - precision: 0.8689 - recall: 0.5889 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5053 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 63/500\n",
            "18/18 - 0s - loss: 0.4722 - acc: 0.7833 - precision: 0.9180 - recall: 0.6222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5046 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 64/500\n",
            "18/18 - 0s - loss: 0.4422 - acc: 0.7722 - precision: 0.7882 - recall: 0.7444 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.5652 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 65/500\n",
            "18/18 - 0s - loss: 0.4441 - acc: 0.7944 - precision: 0.9649 - recall: 0.6111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5586 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 66/500\n",
            "18/18 - 0s - loss: 0.4262 - acc: 0.7778 - precision: 0.8289 - recall: 0.7000 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5426 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 67/500\n",
            "18/18 - 0s - loss: 0.4533 - acc: 0.7833 - precision: 1.0000 - recall: 0.5667 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5651 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 68/500\n",
            "18/18 - 0s - loss: 0.4258 - acc: 0.8111 - precision: 0.8182 - recall: 0.8000 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5427 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 69/500\n",
            "18/18 - 0s - loss: 0.3991 - acc: 0.8389 - precision: 0.9692 - recall: 0.7000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5484 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 70/500\n",
            "18/18 - 0s - loss: 0.3750 - acc: 0.8444 - precision: 0.9697 - recall: 0.7111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.5702 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 71/500\n",
            "18/18 - 0s - loss: 0.3841 - acc: 0.8389 - precision: 0.9296 - recall: 0.7333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5410 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 72/500\n",
            "18/18 - 0s - loss: 0.4635 - acc: 0.7722 - precision: 0.9298 - recall: 0.5889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5517 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 73/500\n",
            "18/18 - 0s - loss: 0.3559 - acc: 0.8222 - precision: 0.8718 - recall: 0.7556 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4892 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 74/500\n",
            "18/18 - 0s - loss: 0.3974 - acc: 0.7833 - precision: 0.8228 - recall: 0.7222 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.5580 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 75/500\n",
            "18/18 - 0s - loss: 0.3525 - acc: 0.8444 - precision: 0.9559 - recall: 0.7222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4906 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 76/500\n",
            "18/18 - 0s - loss: 0.4004 - acc: 0.8111 - precision: 0.8500 - recall: 0.7556 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.6006 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 77/500\n",
            "18/18 - 0s - loss: 0.4385 - acc: 0.7667 - precision: 0.9444 - recall: 0.5667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4842 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 78/500\n",
            "18/18 - 0s - loss: 0.3795 - acc: 0.8500 - precision: 0.9091 - recall: 0.7778 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5364 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 79/500\n",
            "18/18 - 0s - loss: 0.3845 - acc: 0.7889 - precision: 0.9062 - recall: 0.6444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5007 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 80/500\n",
            "18/18 - 0s - loss: 0.3077 - acc: 0.8778 - precision: 0.9048 - recall: 0.8444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5050 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 81/500\n",
            "18/18 - 0s - loss: 0.3522 - acc: 0.8389 - precision: 0.9296 - recall: 0.7333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5337 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 82/500\n",
            "18/18 - 0s - loss: 0.4136 - acc: 0.8111 - precision: 0.8333 - recall: 0.7778 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.5008 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 83/500\n",
            "18/18 - 0s - loss: 0.3225 - acc: 0.8444 - precision: 0.9697 - recall: 0.7111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4642 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 84/500\n",
            "18/18 - 0s - loss: 0.3243 - acc: 0.8500 - precision: 0.8795 - recall: 0.8111 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5068 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 85/500\n",
            "18/18 - 0s - loss: 0.3419 - acc: 0.8278 - precision: 0.9683 - recall: 0.6778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4263 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 86/500\n",
            "18/18 - 0s - loss: 0.4157 - acc: 0.7556 - precision: 0.7556 - recall: 0.7556 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.4959 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 87/500\n",
            "18/18 - 0s - loss: 0.4047 - acc: 0.7889 - precision: 1.0000 - recall: 0.5778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.4341 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 88/500\n",
            "18/18 - 0s - loss: 0.4444 - acc: 0.7556 - precision: 0.6885 - recall: 0.9333 - tn: 52.0000 - fp: 38.0000 - val_loss: 0.4791 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 89/500\n",
            "18/18 - 0s - loss: 0.4344 - acc: 0.7722 - precision: 0.9804 - recall: 0.5556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4928 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 90/500\n",
            "18/18 - 0s - loss: 0.3811 - acc: 0.7667 - precision: 0.8529 - recall: 0.6444 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4259 - val_acc: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 91/500\n",
            "18/18 - 0s - loss: 0.3212 - acc: 0.8444 - precision: 0.8370 - recall: 0.8556 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.4596 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 92/500\n",
            "18/18 - 0s - loss: 0.3351 - acc: 0.8389 - precision: 0.8961 - recall: 0.7667 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4717 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 93/500\n",
            "18/18 - 0s - loss: 0.3691 - acc: 0.8167 - precision: 0.9014 - recall: 0.7111 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5106 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 94/500\n",
            "18/18 - 0s - loss: 0.3148 - acc: 0.8722 - precision: 0.9718 - recall: 0.7667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4337 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 95/500\n",
            "18/18 - 0s - loss: 0.3335 - acc: 0.8500 - precision: 0.8706 - recall: 0.8222 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4366 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 96/500\n",
            "18/18 - 0s - loss: 0.2733 - acc: 0.8778 - precision: 0.9595 - recall: 0.7889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4295 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 97/500\n",
            "18/18 - 0s - loss: 0.3309 - acc: 0.8333 - precision: 0.9286 - recall: 0.7222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4233 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 98/500\n",
            "18/18 - 0s - loss: 0.3151 - acc: 0.8833 - precision: 0.8876 - recall: 0.8778 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4419 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 99/500\n",
            "18/18 - 0s - loss: 0.3366 - acc: 0.8444 - precision: 0.9429 - recall: 0.7333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4122 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 100/500\n",
            "18/18 - 0s - loss: 0.3683 - acc: 0.8389 - precision: 0.9178 - recall: 0.7444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4651 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 101/500\n",
            "18/18 - 0s - loss: 0.3023 - acc: 0.8722 - precision: 0.9036 - recall: 0.8333 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4245 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 102/500\n",
            "18/18 - 0s - loss: 0.2893 - acc: 0.8722 - precision: 0.9718 - recall: 0.7667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4430 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 103/500\n",
            "18/18 - 0s - loss: 0.2549 - acc: 0.8833 - precision: 0.8966 - recall: 0.8667 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4483 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 104/500\n",
            "18/18 - 0s - loss: 0.2892 - acc: 0.8722 - precision: 0.9036 - recall: 0.8333 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4230 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 105/500\n",
            "18/18 - 0s - loss: 0.3020 - acc: 0.8444 - precision: 0.9189 - recall: 0.7556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4364 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 106/500\n",
            "18/18 - 0s - loss: 0.2715 - acc: 0.8667 - precision: 0.9125 - recall: 0.8111 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4119 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 107/500\n",
            "18/18 - 0s - loss: 0.3147 - acc: 0.8722 - precision: 0.8764 - recall: 0.8667 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4544 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 108/500\n",
            "18/18 - 0s - loss: 0.2850 - acc: 0.8778 - precision: 1.0000 - recall: 0.7556 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.4166 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 109/500\n",
            "18/18 - 0s - loss: 0.3097 - acc: 0.9111 - precision: 0.9022 - recall: 0.9222 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4889 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 110/500\n",
            "18/18 - 0s - loss: 0.3575 - acc: 0.8056 - precision: 0.9365 - recall: 0.6556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4047 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 111/500\n",
            "18/18 - 0s - loss: 0.3073 - acc: 0.8944 - precision: 0.9080 - recall: 0.8778 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3640 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 112/500\n",
            "18/18 - 0s - loss: 0.2195 - acc: 0.8944 - precision: 0.8586 - recall: 0.9444 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.3861 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 113/500\n",
            "18/18 - 0s - loss: 0.2996 - acc: 0.8722 - precision: 0.9589 - recall: 0.7778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.3891 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 114/500\n",
            "18/18 - 0s - loss: 0.2725 - acc: 0.8500 - precision: 0.8706 - recall: 0.8222 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4233 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 115/500\n",
            "18/18 - 0s - loss: 0.3038 - acc: 0.8722 - precision: 0.9036 - recall: 0.8333 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4834 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 116/500\n",
            "18/18 - 0s - loss: 0.2236 - acc: 0.8944 - precision: 0.9277 - recall: 0.8556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3696 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 117/500\n",
            "18/18 - 0s - loss: 0.2515 - acc: 0.8833 - precision: 0.9259 - recall: 0.8333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3544 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 118/500\n",
            "18/18 - 0s - loss: 0.2605 - acc: 0.9056 - precision: 0.9620 - recall: 0.8444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.3518 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 119/500\n",
            "18/18 - 0s - loss: 0.2679 - acc: 0.8833 - precision: 0.8876 - recall: 0.8778 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3816 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 120/500\n",
            "18/18 - 0s - loss: 0.1839 - acc: 0.9333 - precision: 0.9875 - recall: 0.8778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4079 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 121/500\n",
            "18/18 - 0s - loss: 0.2072 - acc: 0.8944 - precision: 0.9176 - recall: 0.8667 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4088 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 122/500\n",
            "18/18 - 0s - loss: 0.1922 - acc: 0.9222 - precision: 0.9222 - recall: 0.9222 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4418 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 123/500\n",
            "18/18 - 0s - loss: 0.2514 - acc: 0.8667 - precision: 0.8667 - recall: 0.8667 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.3759 - val_acc: 0.8000 - val_precision: 0.9091 - val_recall: 0.6667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 124/500\n",
            "18/18 - 0s - loss: 0.1772 - acc: 0.9056 - precision: 0.9398 - recall: 0.8667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4070 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 125/500\n",
            "18/18 - 0s - loss: 0.2009 - acc: 0.9167 - precision: 0.9747 - recall: 0.8556 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4021 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 126/500\n",
            "18/18 - 0s - loss: 0.1879 - acc: 0.9333 - precision: 0.9643 - recall: 0.9000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.3615 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 127/500\n",
            "18/18 - 0s - loss: 0.2792 - acc: 0.8889 - precision: 0.9070 - recall: 0.8667 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3472 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 128/500\n",
            "18/18 - 0s - loss: 0.2592 - acc: 0.8833 - precision: 0.9481 - recall: 0.8111 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3843 - val_acc: 0.8000 - val_precision: 0.9091 - val_recall: 0.6667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 129/500\n",
            "18/18 - 0s - loss: 0.2155 - acc: 0.9000 - precision: 0.8913 - recall: 0.9111 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3663 - val_acc: 0.8000 - val_precision: 0.9091 - val_recall: 0.6667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 130/500\n",
            "18/18 - 0s - loss: 0.2573 - acc: 0.8833 - precision: 0.9059 - recall: 0.8556 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3019 - val_acc: 0.8833 - val_precision: 0.9259 - val_recall: 0.8333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 131/500\n",
            "18/18 - 0s - loss: 0.3414 - acc: 0.8333 - precision: 0.8571 - recall: 0.8000 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.3866 - val_acc: 0.8167 - val_precision: 0.9130 - val_recall: 0.7000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 132/500\n",
            "18/18 - 0s - loss: 0.2562 - acc: 0.9056 - precision: 0.9195 - recall: 0.8889 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3395 - val_acc: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 133/500\n",
            "18/18 - 0s - loss: 0.2622 - acc: 0.8722 - precision: 0.8602 - recall: 0.8889 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.3438 - val_acc: 0.8000 - val_precision: 0.9091 - val_recall: 0.6667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 134/500\n",
            "18/18 - 0s - loss: 0.3030 - acc: 0.8444 - precision: 0.8523 - recall: 0.8333 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.3237 - val_acc: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 135/500\n",
            "18/18 - 0s - loss: 0.2127 - acc: 0.9222 - precision: 0.9043 - recall: 0.9444 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3641 - val_acc: 0.8000 - val_precision: 0.9091 - val_recall: 0.6667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 136/500\n",
            "18/18 - 0s - loss: 0.2768 - acc: 0.8944 - precision: 0.8660 - recall: 0.9333 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.3685 - val_acc: 0.8000 - val_precision: 0.9091 - val_recall: 0.6667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 137/500\n",
            "18/18 - 0s - loss: 0.2667 - acc: 0.9000 - precision: 0.9865 - recall: 0.8111 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.3507 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 138/500\n",
            "18/18 - 0s - loss: 0.2521 - acc: 0.9056 - precision: 0.8842 - recall: 0.9333 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4112 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 139/500\n",
            "18/18 - 0s - loss: 0.1999 - acc: 0.9000 - precision: 0.9390 - recall: 0.8556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3771 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 140/500\n",
            "18/18 - 0s - loss: 0.2212 - acc: 0.8889 - precision: 0.9487 - recall: 0.8222 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3922 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 141/500\n",
            "18/18 - 0s - loss: 0.2348 - acc: 0.9056 - precision: 0.9011 - recall: 0.9111 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3548 - val_acc: 0.8167 - val_precision: 0.9130 - val_recall: 0.7000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 142/500\n",
            "18/18 - 0s - loss: 0.1698 - acc: 0.9333 - precision: 0.9535 - recall: 0.9111 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3219 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 143/500\n",
            "18/18 - 0s - loss: 0.1758 - acc: 0.9278 - precision: 0.9425 - recall: 0.9111 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3312 - val_acc: 0.8167 - val_precision: 0.9130 - val_recall: 0.7000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 144/500\n",
            "18/18 - 0s - loss: 0.2849 - acc: 0.8833 - precision: 0.8557 - recall: 0.9222 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.3331 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 145/500\n",
            "18/18 - 0s - loss: 0.1699 - acc: 0.9333 - precision: 0.9432 - recall: 0.9222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3046 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 146/500\n",
            "18/18 - 0s - loss: 0.2023 - acc: 0.9056 - precision: 0.9101 - recall: 0.9000 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.2951 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 147/500\n",
            "18/18 - 0s - loss: 0.2218 - acc: 0.9111 - precision: 0.8776 - recall: 0.9556 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.3423 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 148/500\n",
            "18/18 - 0s - loss: 0.1464 - acc: 0.9222 - precision: 0.9634 - recall: 0.8778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.3454 - val_acc: 0.8000 - val_precision: 0.9091 - val_recall: 0.6667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 149/500\n",
            "18/18 - 0s - loss: 0.1281 - acc: 0.9389 - precision: 0.9540 - recall: 0.9222 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3562 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 150/500\n",
            "18/18 - 0s - loss: 0.1418 - acc: 0.9444 - precision: 0.9348 - recall: 0.9556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4645 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 151/500\n",
            "18/18 - 0s - loss: 0.1493 - acc: 0.9389 - precision: 0.9759 - recall: 0.9000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4411 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 152/500\n",
            "18/18 - 0s - loss: 0.2101 - acc: 0.9278 - precision: 0.9753 - recall: 0.8778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3562 - val_acc: 0.8167 - val_precision: 0.9130 - val_recall: 0.7000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 153/500\n",
            "18/18 - 0s - loss: 0.1861 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3636 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 154/500\n",
            "18/18 - 0s - loss: 0.1703 - acc: 0.9389 - precision: 0.9540 - recall: 0.9222 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3287 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 155/500\n",
            "18/18 - 0s - loss: 0.1980 - acc: 0.9278 - precision: 0.9231 - recall: 0.9333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5954 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 156/500\n",
            "18/18 - 0s - loss: 0.3639 - acc: 0.8389 - precision: 0.8427 - recall: 0.8333 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.3894 - val_acc: 0.9000 - val_precision: 0.9286 - val_recall: 0.8667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 157/500\n",
            "18/18 - 0s - loss: 0.2113 - acc: 0.9167 - precision: 0.9121 - recall: 0.9222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4326 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 158/500\n",
            "18/18 - 0s - loss: 0.1374 - acc: 0.9556 - precision: 0.9659 - recall: 0.9444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4548 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 159/500\n",
            "18/18 - 0s - loss: 0.2629 - acc: 0.8944 - precision: 0.9277 - recall: 0.8556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5525 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 160/500\n",
            "18/18 - 0s - loss: 0.1430 - acc: 0.9389 - precision: 0.9877 - recall: 0.8889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.3446 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 161/500\n",
            "18/18 - 0s - loss: 0.1914 - acc: 0.8944 - precision: 0.8660 - recall: 0.9333 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.3876 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 162/500\n",
            "18/18 - 0s - loss: 0.1715 - acc: 0.9333 - precision: 0.9535 - recall: 0.9111 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3843 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 163/500\n",
            "18/18 - 0s - loss: 0.2019 - acc: 0.9222 - precision: 0.9750 - recall: 0.8667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3937 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 164/500\n",
            "18/18 - 0s - loss: 0.1785 - acc: 0.9333 - precision: 0.9062 - recall: 0.9667 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3464 - val_acc: 0.8167 - val_precision: 0.9130 - val_recall: 0.7000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 165/500\n",
            "18/18 - 0s - loss: 0.1795 - acc: 0.9333 - precision: 0.9432 - recall: 0.9222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3441 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 166/500\n",
            "18/18 - 0s - loss: 0.1545 - acc: 0.9500 - precision: 0.9263 - recall: 0.9778 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3569 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 167/500\n",
            "18/18 - 0s - loss: 0.1215 - acc: 0.9556 - precision: 0.9767 - recall: 0.9333 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3551 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 168/500\n",
            "18/18 - 0s - loss: 0.1218 - acc: 0.9333 - precision: 0.9432 - recall: 0.9222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4349 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 169/500\n",
            "18/18 - 0s - loss: 0.2571 - acc: 0.8944 - precision: 0.9277 - recall: 0.8556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3197 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 170/500\n",
            "18/18 - 0s - loss: 0.1451 - acc: 0.9444 - precision: 0.9255 - recall: 0.9667 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4140 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 171/500\n",
            "18/18 - 0s - loss: 0.2056 - acc: 0.9167 - precision: 0.9518 - recall: 0.8778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2916 - val_acc: 0.8833 - val_precision: 0.9259 - val_recall: 0.8333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 172/500\n",
            "18/18 - 0s - loss: 0.1736 - acc: 0.9111 - precision: 0.9022 - recall: 0.9222 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3054 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 173/500\n",
            "18/18 - 0s - loss: 0.1188 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2723 - val_acc: 0.8833 - val_precision: 0.9259 - val_recall: 0.8333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 174/500\n",
            "18/18 - 0s - loss: 0.1764 - acc: 0.9389 - precision: 0.9247 - recall: 0.9556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4013 - val_acc: 0.7833 - val_precision: 0.9048 - val_recall: 0.6333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 175/500\n",
            "18/18 - 0s - loss: 0.2062 - acc: 0.8889 - precision: 0.9070 - recall: 0.8667 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.2792 - val_acc: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 176/500\n",
            "18/18 - 0s - loss: 0.1261 - acc: 0.9444 - precision: 0.9255 - recall: 0.9667 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3242 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 177/500\n",
            "18/18 - 0s - loss: 0.1546 - acc: 0.9333 - precision: 0.9535 - recall: 0.9111 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3102 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 178/500\n",
            "18/18 - 0s - loss: 0.1805 - acc: 0.9278 - precision: 0.9425 - recall: 0.9111 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4098 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 179/500\n",
            "18/18 - 0s - loss: 0.1888 - acc: 0.9000 - precision: 0.8830 - recall: 0.9222 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.3767 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 180/500\n",
            "18/18 - 0s - loss: 0.1379 - acc: 0.9278 - precision: 0.9639 - recall: 0.8889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2788 - val_acc: 0.9167 - val_precision: 0.9310 - val_recall: 0.9000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 181/500\n",
            "18/18 - 0s - loss: 0.1633 - acc: 0.9389 - precision: 0.9072 - recall: 0.9778 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3499 - val_acc: 0.8000 - val_precision: 0.9091 - val_recall: 0.6667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 182/500\n",
            "18/18 - 0s - loss: 0.2070 - acc: 0.9000 - precision: 0.9091 - recall: 0.8889 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.2829 - val_acc: 0.8833 - val_precision: 0.9259 - val_recall: 0.8333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 183/500\n",
            "18/18 - 0s - loss: 0.1873 - acc: 0.9278 - precision: 0.9326 - recall: 0.9222 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3023 - val_acc: 0.8833 - val_precision: 0.9259 - val_recall: 0.8333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 184/500\n",
            "18/18 - 0s - loss: 0.1519 - acc: 0.9278 - precision: 0.9140 - recall: 0.9444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3325 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 185/500\n",
            "18/18 - 0s - loss: 0.0904 - acc: 0.9556 - precision: 0.9457 - recall: 0.9667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3091 - val_acc: 0.7833 - val_precision: 1.0000 - val_recall: 0.5667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 186/500\n",
            "18/18 - 0s - loss: 0.1253 - acc: 0.9333 - precision: 0.9333 - recall: 0.9333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2922 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 187/500\n",
            "18/18 - 0s - loss: 0.1683 - acc: 0.9111 - precision: 0.9205 - recall: 0.9000 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2955 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 188/500\n",
            "18/18 - 0s - loss: 0.1254 - acc: 0.9389 - precision: 0.9341 - recall: 0.9444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2677 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 189/500\n",
            "18/18 - 0s - loss: 0.1011 - acc: 0.9556 - precision: 0.9362 - recall: 0.9778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2920 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 190/500\n",
            "18/18 - 0s - loss: 0.1230 - acc: 0.9444 - precision: 0.9545 - recall: 0.9333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3318 - val_acc: 0.8167 - val_precision: 0.9130 - val_recall: 0.7000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 191/500\n",
            "18/18 - 0s - loss: 0.2558 - acc: 0.8944 - precision: 0.9080 - recall: 0.8778 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3795 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 192/500\n",
            "18/18 - 0s - loss: 0.1431 - acc: 0.9278 - precision: 0.9231 - recall: 0.9333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2846 - val_acc: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 193/500\n",
            "18/18 - 0s - loss: 0.1482 - acc: 0.9500 - precision: 0.9451 - recall: 0.9556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2839 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 194/500\n",
            "18/18 - 0s - loss: 0.2050 - acc: 0.9222 - precision: 0.9318 - recall: 0.9111 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2812 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 195/500\n",
            "18/18 - 0s - loss: 0.0913 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2559 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 196/500\n",
            "18/18 - 0s - loss: 0.1629 - acc: 0.9389 - precision: 0.9540 - recall: 0.9222 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2426 - val_acc: 0.8833 - val_precision: 0.9259 - val_recall: 0.8333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 197/500\n",
            "18/18 - 0s - loss: 0.1385 - acc: 0.9444 - precision: 0.9444 - recall: 0.9444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2744 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 198/500\n",
            "18/18 - 0s - loss: 0.1122 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2544 - val_acc: 0.8833 - val_precision: 0.9259 - val_recall: 0.8333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 199/500\n",
            "18/18 - 0s - loss: 0.1184 - acc: 0.9500 - precision: 0.9451 - recall: 0.9556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3226 - val_acc: 0.8167 - val_precision: 0.9130 - val_recall: 0.7000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 200/500\n",
            "18/18 - 0s - loss: 0.1896 - acc: 0.9111 - precision: 0.9111 - recall: 0.9111 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.2649 - val_acc: 0.8833 - val_precision: 0.9259 - val_recall: 0.8333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 201/500\n",
            "18/18 - 0s - loss: 0.1387 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3478 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 202/500\n",
            "18/18 - 0s - loss: 0.1714 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2831 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 203/500\n",
            "18/18 - 0s - loss: 0.1483 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3576 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 204/500\n",
            "18/18 - 0s - loss: 0.0852 - acc: 0.9722 - precision: 0.9570 - recall: 0.9889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3060 - val_acc: 0.8500 - val_precision: 1.0000 - val_recall: 0.7000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 205/500\n",
            "18/18 - 0s - loss: 0.1588 - acc: 0.9333 - precision: 0.9432 - recall: 0.9222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3696 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 206/500\n",
            "18/18 - 0s - loss: 0.1086 - acc: 0.9667 - precision: 0.9773 - recall: 0.9556 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3079 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 207/500\n",
            "18/18 - 0s - loss: 0.0695 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.3095 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 208/500\n",
            "18/18 - 0s - loss: 0.0915 - acc: 0.9611 - precision: 0.9770 - recall: 0.9444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3292 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 209/500\n",
            "18/18 - 0s - loss: 0.1090 - acc: 0.9611 - precision: 0.9882 - recall: 0.9333 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.3810 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 210/500\n",
            "18/18 - 0s - loss: 0.1358 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2408 - val_acc: 0.8833 - val_precision: 0.9259 - val_recall: 0.8333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 211/500\n",
            "18/18 - 0s - loss: 0.1332 - acc: 0.9444 - precision: 0.9444 - recall: 0.9444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3771 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 212/500\n",
            "18/18 - 0s - loss: 0.1612 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2857 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 213/500\n",
            "18/18 - 0s - loss: 0.1052 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3522 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 214/500\n",
            "18/18 - 0s - loss: 0.1081 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3278 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 215/500\n",
            "18/18 - 0s - loss: 0.1673 - acc: 0.9333 - precision: 0.9643 - recall: 0.9000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.3823 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 216/500\n",
            "18/18 - 0s - loss: 0.1464 - acc: 0.9444 - precision: 0.9444 - recall: 0.9444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3394 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 217/500\n",
            "18/18 - 0s - loss: 0.1204 - acc: 0.9611 - precision: 0.9368 - recall: 0.9889 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4386 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 218/500\n",
            "18/18 - 0s - loss: 0.1729 - acc: 0.9444 - precision: 0.9762 - recall: 0.9111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1948 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 219/500\n",
            "18/18 - 0s - loss: 0.1090 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2462 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 220/500\n",
            "18/18 - 0s - loss: 0.1355 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3391 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 221/500\n",
            "18/18 - 0s - loss: 0.0696 - acc: 0.9833 - precision: 0.9677 - recall: 1.0000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.3275 - val_acc: 0.8167 - val_precision: 1.0000 - val_recall: 0.6333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 222/500\n",
            "18/18 - 0s - loss: 0.1067 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2988 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 223/500\n",
            "18/18 - 0s - loss: 0.0468 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3835 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 224/500\n",
            "18/18 - 0s - loss: 0.0757 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.2993 - val_acc: 0.8500 - val_precision: 1.0000 - val_recall: 0.7000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 225/500\n",
            "18/18 - 0s - loss: 0.1557 - acc: 0.9444 - precision: 0.9651 - recall: 0.9222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2755 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 226/500\n",
            "18/18 - 0s - loss: 0.1132 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2951 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 227/500\n",
            "18/18 - 0s - loss: 0.0673 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.3352 - val_acc: 0.8000 - val_precision: 1.0000 - val_recall: 0.6000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 228/500\n",
            "18/18 - 0s - loss: 0.1070 - acc: 0.9556 - precision: 0.9659 - recall: 0.9444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2440 - val_acc: 0.8833 - val_precision: 1.0000 - val_recall: 0.7667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 229/500\n",
            "18/18 - 0s - loss: 0.0809 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2648 - val_acc: 0.8833 - val_precision: 1.0000 - val_recall: 0.7667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 230/500\n",
            "18/18 - 0s - loss: 0.1086 - acc: 0.9667 - precision: 0.9773 - recall: 0.9556 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2731 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 231/500\n",
            "18/18 - 0s - loss: 0.0491 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2212 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 232/500\n",
            "18/18 - 0s - loss: 0.1151 - acc: 0.9500 - precision: 0.9355 - recall: 0.9667 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4334 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 233/500\n",
            "18/18 - 0s - loss: 0.1293 - acc: 0.9556 - precision: 0.9767 - recall: 0.9333 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2197 - val_acc: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 234/500\n",
            "18/18 - 0s - loss: 0.0759 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4024 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 235/500\n",
            "18/18 - 0s - loss: 0.1034 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2290 - val_acc: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 236/500\n",
            "18/18 - 0s - loss: 0.0761 - acc: 0.9889 - precision: 1.0000 - recall: 0.9778 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.2881 - val_acc: 0.8500 - val_precision: 1.0000 - val_recall: 0.7000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 237/500\n",
            "18/18 - 0s - loss: 0.0638 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3544 - val_acc: 0.8167 - val_precision: 1.0000 - val_recall: 0.6333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 238/500\n",
            "18/18 - 0s - loss: 0.0735 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2814 - val_acc: 0.8500 - val_precision: 1.0000 - val_recall: 0.7000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 239/500\n",
            "18/18 - 0s - loss: 0.2075 - acc: 0.9278 - precision: 0.9873 - recall: 0.8667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.2182 - val_acc: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 240/500\n",
            "18/18 - 0s - loss: 0.1299 - acc: 0.9444 - precision: 0.9082 - recall: 0.9889 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2508 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 241/500\n",
            "18/18 - 0s - loss: 0.1235 - acc: 0.9500 - precision: 1.0000 - recall: 0.9000 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.2016 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 242/500\n",
            "18/18 - 0s - loss: 0.2147 - acc: 0.9111 - precision: 0.8936 - recall: 0.9333 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.2122 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 243/500\n",
            "18/18 - 0s - loss: 0.0828 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2346 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1948 - acc: 0.9833 - precision: 1.0000 - recall: 0.9667 - tn: 30.0000 - fp: 0.0000e+00    \n",
            "loss:\n",
            "[0.1948142647743225, 0.9833333492279053, 1.0, 0.9666666388511658, 30.0, 0.0]\n",
            "['loss', 'acc', 'precision', 'recall', 'tn', 'fp']\n",
            "Training and evaluating on fold 6 out of 8...\n",
            "train_index[  1   2   4   6   7   8   9  10  13  14  15  16  17  19  20  21  22  24\n",
            "  26  27  28  30  32  33  36  37  38  39  40  41  42  43  44  46  49  50\n",
            "  51  52  53  54  55  56  58  59  60  61  62  63  65  66  67  68  70  71\n",
            "  72  74  75  76  77  78  79  80  81  83  84  85  87  89  90  91  92  93\n",
            "  95  96  97  99 100 103 104 105 107 108 109 110 112 113 115 117 118 119\n",
            " 120 121 122 123 124 125 126 127 128 129 131 132 133 134 135 139 142 143\n",
            " 145 146 149 150 151 152 154 155 156 157 160 161 163 164 165 166 167 168\n",
            " 169 170 172 174 175 176 178 179 180 181 182 183 185 187 188 189 191 192\n",
            " 193 196 197 198 199 200 201 202 203 206 207 208 209 211 212 213 214 215\n",
            " 216 218 219 220 221 224 226 227 228 229 230 231 232 234 235 236 237 238]\n",
            "test_index[  0   3   5  11  12  18  23  25  29  31  34  35  45  47  48  57  64  69\n",
            "  73  82  86  88  94  98 101 102 106 111 114 116 130 136 137 138 140 141\n",
            " 144 147 148 153 158 159 162 171 173 177 184 186 190 194 195 204 205 210\n",
            " 217 222 223 225 233 239]\n",
            "Epoch 1/500\n",
            "18/18 - 2s - loss: 0.7010 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6948 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 2/500\n",
            "18/18 - 0s - loss: 0.6996 - acc: 0.3500 - precision: 0.2128 - recall: 0.1111 - tn: 53.0000 - fp: 37.0000 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 3/500\n",
            "18/18 - 0s - loss: 0.7005 - acc: 0.4444 - precision: 0.3333 - recall: 0.1111 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.6936 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 4/500\n",
            "18/18 - 0s - loss: 0.6963 - acc: 0.4611 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 5/500\n",
            "18/18 - 0s - loss: 0.6990 - acc: 0.3944 - precision: 0.4059 - recall: 0.4556 - tn: 30.0000 - fp: 60.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 6/500\n",
            "18/18 - 0s - loss: 0.6944 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/500\n",
            "18/18 - 0s - loss: 0.6963 - acc: 0.4444 - precision: 0.3438 - recall: 0.1222 - tn: 69.0000 - fp: 21.0000 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 8/500\n",
            "18/18 - 0s - loss: 0.7018 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6937 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 9/500\n",
            "18/18 - 0s - loss: 0.6956 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 10/500\n",
            "18/18 - 0s - loss: 0.6943 - acc: 0.4944 - precision: 0.4783 - recall: 0.1222 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.6928 - val_acc: 0.5333 - val_precision: 0.6000 - val_recall: 0.2000 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 11/500\n",
            "18/18 - 0s - loss: 0.6954 - acc: 0.5222 - precision: 0.5119 - recall: 0.9556 - tn: 8.0000 - fp: 82.0000 - val_loss: 0.6926 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 12/500\n",
            "18/18 - 0s - loss: 0.6935 - acc: 0.5111 - precision: 0.5096 - recall: 0.5889 - tn: 39.0000 - fp: 51.0000 - val_loss: 0.6914 - val_acc: 0.5167 - val_precision: 1.0000 - val_recall: 0.0333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 13/500\n",
            "18/18 - 0s - loss: 0.6894 - acc: 0.5556 - precision: 0.5962 - recall: 0.3444 - tn: 69.0000 - fp: 21.0000 - val_loss: 0.6905 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 14/500\n",
            "18/18 - 0s - loss: 0.7140 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6956 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 15/500\n",
            "18/18 - 0s - loss: 0.7163 - acc: 0.3667 - precision: 0.2778 - recall: 0.1667 - tn: 51.0000 - fp: 39.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 16/500\n",
            "18/18 - 0s - loss: 0.6931 - acc: 0.5444 - precision: 1.0000 - recall: 0.0889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6904 - val_acc: 0.5167 - val_precision: 1.0000 - val_recall: 0.0333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 17/500\n",
            "18/18 - 0s - loss: 0.6900 - acc: 0.5556 - precision: 1.0000 - recall: 0.1111 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6858 - val_acc: 0.5333 - val_precision: 1.0000 - val_recall: 0.0667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 18/500\n",
            "18/18 - 0s - loss: 0.7069 - acc: 0.3222 - precision: 0.3806 - recall: 0.5667 - tn: 7.0000 - fp: 83.0000 - val_loss: 0.6843 - val_acc: 0.5500 - val_precision: 1.0000 - val_recall: 0.1000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 19/500\n",
            "18/18 - 0s - loss: 0.6872 - acc: 0.5833 - precision: 0.9412 - recall: 0.1778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6820 - val_acc: 0.5333 - val_precision: 1.0000 - val_recall: 0.0667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 20/500\n",
            "18/18 - 0s - loss: 0.6839 - acc: 0.5333 - precision: 0.5938 - recall: 0.2111 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.6742 - val_acc: 0.5667 - val_precision: 1.0000 - val_recall: 0.1333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 21/500\n",
            "18/18 - 0s - loss: 0.6681 - acc: 0.6167 - precision: 0.7838 - recall: 0.3222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.6595 - val_acc: 0.5500 - val_precision: 0.7143 - val_recall: 0.1667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 22/500\n",
            "18/18 - 0s - loss: 0.6331 - acc: 0.6389 - precision: 0.6712 - recall: 0.5444 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.6313 - val_acc: 0.5500 - val_precision: 0.7143 - val_recall: 0.1667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 23/500\n",
            "18/18 - 0s - loss: 0.6803 - acc: 0.5389 - precision: 0.6400 - recall: 0.1778 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.6426 - val_acc: 0.6000 - val_precision: 0.8000 - val_recall: 0.2667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 24/500\n",
            "18/18 - 0s - loss: 0.6075 - acc: 0.6500 - precision: 0.6800 - recall: 0.5667 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.5939 - val_acc: 0.7667 - val_precision: 0.8077 - val_recall: 0.7000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 25/500\n",
            "18/18 - 0s - loss: 0.5961 - acc: 0.6056 - precision: 0.6234 - recall: 0.5333 - tn: 61.0000 - fp: 29.0000 - val_loss: 0.6196 - val_acc: 0.5833 - val_precision: 0.7778 - val_recall: 0.2333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 26/500\n",
            "18/18 - 0s - loss: 0.5931 - acc: 0.6389 - precision: 0.9032 - recall: 0.3111 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.6236 - val_acc: 0.5833 - val_precision: 1.0000 - val_recall: 0.1667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 27/500\n",
            "18/18 - 0s - loss: 0.5759 - acc: 0.6333 - precision: 0.6667 - recall: 0.5333 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.5430 - val_acc: 0.7667 - val_precision: 0.9000 - val_recall: 0.6000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 28/500\n",
            "18/18 - 0s - loss: 0.5827 - acc: 0.6778 - precision: 0.8333 - recall: 0.4444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5681 - val_acc: 0.6833 - val_precision: 0.8667 - val_recall: 0.4333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 29/500\n",
            "18/18 - 0s - loss: 0.5433 - acc: 0.7111 - precision: 0.6900 - recall: 0.7667 - tn: 59.0000 - fp: 31.0000 - val_loss: 0.5942 - val_acc: 0.6667 - val_precision: 0.8571 - val_recall: 0.4000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 30/500\n",
            "18/18 - 0s - loss: 0.5299 - acc: 0.7222 - precision: 0.8704 - recall: 0.5222 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5748 - val_acc: 0.6667 - val_precision: 0.8571 - val_recall: 0.4000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 31/500\n",
            "18/18 - 0s - loss: 0.5011 - acc: 0.7833 - precision: 0.8493 - recall: 0.6889 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5776 - val_acc: 0.6333 - val_precision: 0.8333 - val_recall: 0.3333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 32/500\n",
            "18/18 - 0s - loss: 0.5279 - acc: 0.7222 - precision: 0.9348 - recall: 0.4778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5143 - val_acc: 0.7500 - val_precision: 0.8947 - val_recall: 0.5667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 33/500\n",
            "18/18 - 0s - loss: 0.6808 - acc: 0.6611 - precision: 0.6408 - recall: 0.7333 - tn: 53.0000 - fp: 37.0000 - val_loss: 0.6228 - val_acc: 0.5833 - val_precision: 1.0000 - val_recall: 0.1667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 34/500\n",
            "18/18 - 0s - loss: 0.5878 - acc: 0.6167 - precision: 0.9565 - recall: 0.2444 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6173 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 35/500\n",
            "18/18 - 0s - loss: 0.5620 - acc: 0.6722 - precision: 0.9697 - recall: 0.3556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6038 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 36/500\n",
            "18/18 - 0s - loss: 0.5426 - acc: 0.6278 - precision: 0.7347 - recall: 0.4000 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5775 - val_acc: 0.6333 - val_precision: 0.8333 - val_recall: 0.3333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 37/500\n",
            "18/18 - 0s - loss: 0.5463 - acc: 0.6611 - precision: 0.8372 - recall: 0.4000 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5463 - val_acc: 0.7333 - val_precision: 0.6667 - val_recall: 0.9333 - val_tn: 16.0000 - val_fp: 14.0000\n",
            "Epoch 38/500\n",
            "18/18 - 0s - loss: 0.5189 - acc: 0.6889 - precision: 0.6491 - recall: 0.8222 - tn: 50.0000 - fp: 40.0000 - val_loss: 0.5357 - val_acc: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 39/500\n",
            "18/18 - 0s - loss: 0.5238 - acc: 0.6667 - precision: 0.6389 - recall: 0.7667 - tn: 51.0000 - fp: 39.0000 - val_loss: 0.5215 - val_acc: 0.8000 - val_precision: 0.8214 - val_recall: 0.7667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 40/500\n",
            "18/18 - 0s - loss: 0.5022 - acc: 0.7000 - precision: 0.7143 - recall: 0.6667 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.5080 - val_acc: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 41/500\n",
            "18/18 - 0s - loss: 0.4279 - acc: 0.7667 - precision: 0.7400 - recall: 0.8222 - tn: 64.0000 - fp: 26.0000 - val_loss: 0.4620 - val_acc: 0.8500 - val_precision: 0.8387 - val_recall: 0.8667 - val_tn: 25.0000 - val_fp: 5.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42/500\n",
            "18/18 - 0s - loss: 0.4570 - acc: 0.7611 - precision: 0.7701 - recall: 0.7444 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.4572 - val_acc: 0.8000 - val_precision: 0.8214 - val_recall: 0.7667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 43/500\n",
            "18/18 - 0s - loss: 0.4658 - acc: 0.8056 - precision: 0.7895 - recall: 0.8333 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.4652 - val_acc: 0.7333 - val_precision: 0.7917 - val_recall: 0.6333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 44/500\n",
            "18/18 - 0s - loss: 0.4978 - acc: 0.7278 - precision: 0.7158 - recall: 0.7556 - tn: 63.0000 - fp: 27.0000 - val_loss: 0.4610 - val_acc: 0.8333 - val_precision: 0.7632 - val_recall: 0.9667 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 45/500\n",
            "18/18 - 0s - loss: 0.4363 - acc: 0.7611 - precision: 0.8052 - recall: 0.6889 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.4806 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 46/500\n",
            "18/18 - 0s - loss: 0.4296 - acc: 0.7556 - precision: 0.7805 - recall: 0.7111 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4469 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 47/500\n",
            "18/18 - 0s - loss: 0.3915 - acc: 0.7778 - precision: 0.8125 - recall: 0.7222 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.4649 - val_acc: 0.8333 - val_precision: 0.8846 - val_recall: 0.7667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 48/500\n",
            "18/18 - 0s - loss: 0.4443 - acc: 0.7556 - precision: 0.7556 - recall: 0.7556 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.4426 - val_acc: 0.7167 - val_precision: 0.8421 - val_recall: 0.5333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 49/500\n",
            "18/18 - 0s - loss: 0.3907 - acc: 0.8222 - precision: 0.9028 - recall: 0.7222 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3828 - val_acc: 0.8333 - val_precision: 0.7778 - val_recall: 0.9333 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 50/500\n",
            "18/18 - 0s - loss: 0.4044 - acc: 0.8333 - precision: 0.8125 - recall: 0.8667 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4106 - val_acc: 0.8833 - val_precision: 0.8966 - val_recall: 0.8667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 51/500\n",
            "18/18 - 0s - loss: 0.3800 - acc: 0.8278 - precision: 0.8041 - recall: 0.8667 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.3866 - val_acc: 0.8833 - val_precision: 0.8485 - val_recall: 0.9333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 52/500\n",
            "18/18 - 0s - loss: 0.3849 - acc: 0.7833 - precision: 0.7802 - recall: 0.7889 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.3796 - val_acc: 0.8833 - val_precision: 0.8485 - val_recall: 0.9333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 53/500\n",
            "18/18 - 0s - loss: 0.4309 - acc: 0.8111 - precision: 0.8590 - recall: 0.7444 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.3912 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 54/500\n",
            "18/18 - 0s - loss: 0.3102 - acc: 0.8611 - precision: 0.8571 - recall: 0.8667 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.3569 - val_acc: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 55/500\n",
            "18/18 - 0s - loss: 0.3215 - acc: 0.8222 - precision: 0.8222 - recall: 0.8222 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.3309 - val_acc: 0.8667 - val_precision: 0.8235 - val_recall: 0.9333 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 56/500\n",
            "18/18 - 0s - loss: 0.3355 - acc: 0.8389 - precision: 0.8506 - recall: 0.8222 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.3263 - val_acc: 0.8667 - val_precision: 0.8235 - val_recall: 0.9333 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 57/500\n",
            "18/18 - 0s - loss: 0.3990 - acc: 0.8111 - precision: 0.7745 - recall: 0.8778 - tn: 67.0000 - fp: 23.0000 - val_loss: 0.4094 - val_acc: 0.8833 - val_precision: 0.8966 - val_recall: 0.8667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 58/500\n",
            "18/18 - 0s - loss: 0.3276 - acc: 0.8444 - precision: 0.8370 - recall: 0.8556 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.3762 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 59/500\n",
            "18/18 - 0s - loss: 0.4366 - acc: 0.7556 - precision: 0.7447 - recall: 0.7778 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.3927 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 60/500\n",
            "18/18 - 0s - loss: 0.3316 - acc: 0.8333 - precision: 0.8261 - recall: 0.8444 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.3791 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 61/500\n",
            "18/18 - 0s - loss: 0.2773 - acc: 0.8611 - precision: 0.8495 - recall: 0.8778 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.3306 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 62/500\n",
            "18/18 - 0s - loss: 0.2586 - acc: 0.8889 - precision: 0.8889 - recall: 0.8889 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.2900 - val_acc: 0.8667 - val_precision: 0.8929 - val_recall: 0.8333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 63/500\n",
            "18/18 - 0s - loss: 0.4032 - acc: 0.8611 - precision: 0.8824 - recall: 0.8333 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3286 - val_acc: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 64/500\n",
            "18/18 - 0s - loss: 0.2603 - acc: 0.8778 - precision: 0.8542 - recall: 0.9111 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.3167 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 65/500\n",
            "18/18 - 0s - loss: 0.4067 - acc: 0.8167 - precision: 0.8065 - recall: 0.8333 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.3714 - val_acc: 0.7500 - val_precision: 0.6667 - val_recall: 1.0000 - val_tn: 15.0000 - val_fp: 15.0000\n",
            "Epoch 66/500\n",
            "18/18 - 0s - loss: 0.3622 - acc: 0.8167 - precision: 0.8065 - recall: 0.8333 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.3597 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 67/500\n",
            "18/18 - 0s - loss: 0.3759 - acc: 0.8333 - precision: 0.8125 - recall: 0.8667 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.3789 - val_acc: 0.8000 - val_precision: 0.8750 - val_recall: 0.7000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 68/500\n",
            "18/18 - 0s - loss: 0.2992 - acc: 0.8278 - precision: 0.8391 - recall: 0.8111 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.3223 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 69/500\n",
            "18/18 - 0s - loss: 0.2832 - acc: 0.8667 - precision: 0.8511 - recall: 0.8889 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.2907 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 70/500\n",
            "18/18 - 0s - loss: 0.3219 - acc: 0.8500 - precision: 0.8621 - recall: 0.8333 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.3277 - val_acc: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 71/500\n",
            "18/18 - 0s - loss: 0.3114 - acc: 0.8500 - precision: 0.8316 - recall: 0.8778 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.2983 - val_acc: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 72/500\n",
            "18/18 - 0s - loss: 0.2136 - acc: 0.9222 - precision: 0.9222 - recall: 0.9222 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2611 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 73/500\n",
            "18/18 - 0s - loss: 0.2808 - acc: 0.8833 - precision: 0.8966 - recall: 0.8667 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3138 - val_acc: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 74/500\n",
            "18/18 - 0s - loss: 0.2391 - acc: 0.8944 - precision: 0.8660 - recall: 0.9333 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.2704 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 75/500\n",
            "18/18 - 0s - loss: 0.2128 - acc: 0.9167 - precision: 0.9032 - recall: 0.9333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2833 - val_acc: 0.8667 - val_precision: 0.9583 - val_recall: 0.7667 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 76/500\n",
            "18/18 - 0s - loss: 0.2640 - acc: 0.8889 - precision: 0.8977 - recall: 0.8778 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2641 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 77/500\n",
            "18/18 - 0s - loss: 0.2254 - acc: 0.8889 - precision: 0.9167 - recall: 0.8556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2560 - val_acc: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 78/500\n",
            "18/18 - 0s - loss: 0.2597 - acc: 0.9056 - precision: 0.9195 - recall: 0.8889 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2826 - val_acc: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 79/500\n",
            "18/18 - 0s - loss: 0.3232 - acc: 0.8667 - precision: 0.8056 - recall: 0.9667 - tn: 69.0000 - fp: 21.0000 - val_loss: 0.3285 - val_acc: 0.9333 - val_precision: 0.9643 - val_recall: 0.9000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 80/500\n",
            "18/18 - 0s - loss: 0.2460 - acc: 0.8833 - precision: 0.8876 - recall: 0.8778 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.2855 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 81/500\n",
            "18/18 - 0s - loss: 0.2845 - acc: 0.8944 - precision: 0.8901 - recall: 0.9000 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.2568 - val_acc: 0.9333 - val_precision: 0.9643 - val_recall: 0.9000 - val_tn: 29.0000 - val_fp: 1.0000\n",
            "Epoch 82/500\n",
            "18/18 - 0s - loss: 0.2016 - acc: 0.9167 - precision: 0.9412 - recall: 0.8889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2754 - val_acc: 0.8833 - val_precision: 0.8286 - val_recall: 0.9667 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 83/500\n",
            "18/18 - 0s - loss: 0.2199 - acc: 0.9111 - precision: 0.9302 - recall: 0.8889 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2445 - val_acc: 0.8833 - val_precision: 0.8286 - val_recall: 0.9667 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 84/500\n",
            "18/18 - 0s - loss: 0.1766 - acc: 0.9167 - precision: 0.8866 - recall: 0.9556 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.2524 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 85/500\n",
            "18/18 - 0s - loss: 0.1957 - acc: 0.9333 - precision: 0.9535 - recall: 0.9111 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3984 - val_acc: 0.7333 - val_precision: 0.6522 - val_recall: 1.0000 - val_tn: 14.0000 - val_fp: 16.0000\n",
            "Epoch 86/500\n",
            "18/18 - 0s - loss: 0.1935 - acc: 0.9333 - precision: 0.9239 - recall: 0.9444 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2674 - val_acc: 0.9167 - val_precision: 0.9310 - val_recall: 0.9000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 87/500\n",
            "18/18 - 0s - loss: 0.1812 - acc: 0.9333 - precision: 0.9756 - recall: 0.8889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3348 - val_acc: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000 - val_tn: 18.0000 - val_fp: 12.0000\n",
            "Epoch 88/500\n",
            "18/18 - 0s - loss: 0.2049 - acc: 0.9278 - precision: 0.8889 - recall: 0.9778 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.2582 - val_acc: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 89/500\n",
            "18/18 - 0s - loss: 0.2446 - acc: 0.8778 - precision: 0.9146 - recall: 0.8333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3870 - val_acc: 0.7667 - val_precision: 0.6818 - val_recall: 1.0000 - val_tn: 16.0000 - val_fp: 14.0000\n",
            "Epoch 90/500\n",
            "18/18 - 0s - loss: 0.1991 - acc: 0.9111 - precision: 0.8936 - recall: 0.9333 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.2640 - val_acc: 0.9167 - val_precision: 0.9310 - val_recall: 0.9000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 91/500\n",
            "18/18 - 0s - loss: 0.1430 - acc: 0.9500 - precision: 0.9765 - recall: 0.9222 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2806 - val_acc: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 92/500\n",
            "18/18 - 0s - loss: 0.1512 - acc: 0.9389 - precision: 0.9158 - recall: 0.9667 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.1852 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 93/500\n",
            "18/18 - 0s - loss: 0.1921 - acc: 0.9111 - precision: 0.9302 - recall: 0.8889 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3528 - val_acc: 0.7667 - val_precision: 0.6818 - val_recall: 1.0000 - val_tn: 16.0000 - val_fp: 14.0000\n",
            "Epoch 94/500\n",
            "18/18 - 0s - loss: 0.1477 - acc: 0.9389 - precision: 0.9341 - recall: 0.9444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.1860 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 95/500\n",
            "18/18 - 0s - loss: 0.2369 - acc: 0.9056 - precision: 0.9011 - recall: 0.9111 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2147 - val_acc: 0.9667 - val_precision: 0.9375 - val_recall: 1.0000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 96/500\n",
            "18/18 - 0s - loss: 0.1689 - acc: 0.9333 - precision: 0.9333 - recall: 0.9333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.1826 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 97/500\n",
            "18/18 - 0s - loss: 0.0971 - acc: 0.9778 - precision: 0.9886 - recall: 0.9667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.3609 - val_acc: 0.7667 - val_precision: 0.6818 - val_recall: 1.0000 - val_tn: 16.0000 - val_fp: 14.0000\n",
            "Epoch 98/500\n",
            "18/18 - 0s - loss: 0.2081 - acc: 0.9056 - precision: 0.8763 - recall: 0.9444 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.1604 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 99/500\n",
            "18/18 - 0s - loss: 0.1236 - acc: 0.9556 - precision: 1.0000 - recall: 0.9111 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.2583 - val_acc: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 100/500\n",
            "18/18 - 0s - loss: 0.2846 - acc: 0.9111 - precision: 0.9022 - recall: 0.9222 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.2253 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 101/500\n",
            "18/18 - 0s - loss: 0.1553 - acc: 0.9333 - precision: 0.8900 - recall: 0.9889 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.1937 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 102/500\n",
            "18/18 - 0s - loss: 0.1638 - acc: 0.9389 - precision: 0.9647 - recall: 0.9111 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1987 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 103/500\n",
            "18/18 - 0s - loss: 0.1493 - acc: 0.9611 - precision: 0.9770 - recall: 0.9444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1609 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 104/500\n",
            "18/18 - 0s - loss: 0.1338 - acc: 0.9500 - precision: 0.9263 - recall: 0.9778 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.1645 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 105/500\n",
            "18/18 - 0s - loss: 0.1054 - acc: 0.9833 - precision: 1.0000 - recall: 0.9667 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.2287 - val_acc: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 106/500\n",
            "18/18 - 0s - loss: 0.2171 - acc: 0.9278 - precision: 0.8969 - recall: 0.9667 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.2331 - val_acc: 0.8833 - val_precision: 1.0000 - val_recall: 0.7667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 107/500\n",
            "18/18 - 0s - loss: 0.2501 - acc: 0.9111 - precision: 0.9302 - recall: 0.8889 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2954 - val_acc: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 108/500\n",
            "18/18 - 0s - loss: 0.2287 - acc: 0.9167 - precision: 0.9518 - recall: 0.8778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2214 - val_acc: 0.8833 - val_precision: 0.8108 - val_recall: 1.0000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 109/500\n",
            "18/18 - 0s - loss: 0.2211 - acc: 0.9056 - precision: 0.8687 - recall: 0.9556 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.1957 - val_acc: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 110/500\n",
            "18/18 - 0s - loss: 0.2052 - acc: 0.9278 - precision: 0.9326 - recall: 0.9222 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2439 - val_acc: 0.8833 - val_precision: 0.8108 - val_recall: 1.0000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 111/500\n",
            "18/18 - 0s - loss: 0.0733 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1355 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 112/500\n",
            "18/18 - 0s - loss: 0.1610 - acc: 0.9278 - precision: 0.9140 - recall: 0.9444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.1539 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 113/500\n",
            "18/18 - 0s - loss: 0.1637 - acc: 0.9500 - precision: 0.9880 - recall: 0.9111 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1430 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 114/500\n",
            "18/18 - 0s - loss: 0.1135 - acc: 0.9556 - precision: 0.9362 - recall: 0.9778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.1339 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 115/500\n",
            "18/18 - 0s - loss: 0.1776 - acc: 0.9278 - precision: 0.9529 - recall: 0.9000 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2415 - val_acc: 0.8833 - val_precision: 0.8108 - val_recall: 1.0000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 116/500\n",
            "18/18 - 0s - loss: 0.0837 - acc: 0.9722 - precision: 0.9474 - recall: 1.0000 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1363 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 117/500\n",
            "18/18 - 0s - loss: 0.1068 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1111 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 118/500\n",
            "18/18 - 0s - loss: 0.0933 - acc: 0.9722 - precision: 1.0000 - recall: 0.9444 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.1398 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 119/500\n",
            "18/18 - 0s - loss: 0.2840 - acc: 0.8833 - precision: 0.9259 - recall: 0.8333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.1759 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 120/500\n",
            "18/18 - 0s - loss: 0.2234 - acc: 0.8944 - precision: 0.8447 - recall: 0.9667 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.1771 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 121/500\n",
            "18/18 - 0s - loss: 0.1227 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1563 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 122/500\n",
            "18/18 - 0s - loss: 0.0753 - acc: 0.9778 - precision: 1.0000 - recall: 0.9556 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.1348 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 123/500\n",
            "18/18 - 0s - loss: 0.1330 - acc: 0.9667 - precision: 0.9773 - recall: 0.9556 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1606 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 124/500\n",
            "18/18 - 0s - loss: 0.1477 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1437 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 125/500\n",
            "18/18 - 0s - loss: 0.1457 - acc: 0.9444 - precision: 0.9255 - recall: 0.9667 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.1227 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 126/500\n",
            "18/18 - 0s - loss: 0.0608 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1095 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 127/500\n",
            "18/18 - 0s - loss: 0.1037 - acc: 0.9556 - precision: 0.9767 - recall: 0.9333 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.2223 - val_acc: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 128/500\n",
            "18/18 - 0s - loss: 0.1211 - acc: 0.9278 - precision: 0.9140 - recall: 0.9444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.1068 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 129/500\n",
            "18/18 - 0s - loss: 0.1164 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0701 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 130/500\n",
            "18/18 - 0s - loss: 0.1786 - acc: 0.9222 - precision: 0.9524 - recall: 0.8889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2622 - val_acc: 0.8167 - val_precision: 0.7317 - val_recall: 1.0000 - val_tn: 19.0000 - val_fp: 11.0000\n",
            "Epoch 131/500\n",
            "18/18 - 0s - loss: 0.2368 - acc: 0.8944 - precision: 0.8901 - recall: 0.9000 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.1304 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 132/500\n",
            "18/18 - 0s - loss: 0.2119 - acc: 0.9167 - precision: 0.9121 - recall: 0.9222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.1558 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 133/500\n",
            "18/18 - 0s - loss: 0.1193 - acc: 0.9444 - precision: 0.9444 - recall: 0.9444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.1392 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 134/500\n",
            "18/18 - 0s - loss: 0.1244 - acc: 0.9444 - precision: 0.9878 - recall: 0.9000 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1784 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 135/500\n",
            "18/18 - 0s - loss: 0.1103 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1177 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 136/500\n",
            "18/18 - 0s - loss: 0.2490 - acc: 0.9278 - precision: 0.9231 - recall: 0.9333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.1431 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 137/500\n",
            "18/18 - 0s - loss: 0.2282 - acc: 0.9167 - precision: 0.9121 - recall: 0.9222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.1289 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 138/500\n",
            "18/18 - 0s - loss: 0.0878 - acc: 0.9722 - precision: 0.9885 - recall: 0.9556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.1330 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 139/500\n",
            "18/18 - 0s - loss: 0.0805 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1013 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 140/500\n",
            "18/18 - 0s - loss: 0.0739 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0908 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 141/500\n",
            "18/18 - 0s - loss: 0.0465 - acc: 0.9944 - precision: 1.0000 - recall: 0.9889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0587 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 142/500\n",
            "18/18 - 0s - loss: 0.1185 - acc: 0.9556 - precision: 0.9659 - recall: 0.9444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1032 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 143/500\n",
            "18/18 - 0s - loss: 0.0486 - acc: 0.9833 - precision: 0.9677 - recall: 1.0000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1196 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 144/500\n",
            "18/18 - 0s - loss: 0.1034 - acc: 0.9500 - precision: 0.9451 - recall: 0.9556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.0674 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 145/500\n",
            "18/18 - 0s - loss: 0.1564 - acc: 0.9556 - precision: 0.9659 - recall: 0.9444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2837 - val_acc: 0.7667 - val_precision: 0.6818 - val_recall: 1.0000 - val_tn: 16.0000 - val_fp: 14.0000\n",
            "Epoch 146/500\n",
            "18/18 - 0s - loss: 0.2629 - acc: 0.9111 - precision: 0.9111 - recall: 0.9111 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.1790 - val_acc: 0.9333 - val_precision: 0.8824 - val_recall: 1.0000 - val_tn: 26.0000 - val_fp: 4.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 147/500\n",
            "18/18 - 0s - loss: 0.1053 - acc: 0.9500 - precision: 0.9765 - recall: 0.9222 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1815 - val_acc: 0.9333 - val_precision: 0.8824 - val_recall: 1.0000 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 148/500\n",
            "18/18 - 0s - loss: 0.1222 - acc: 0.9556 - precision: 0.9457 - recall: 0.9667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.0860 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 149/500\n",
            "18/18 - 0s - loss: 0.0631 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1076 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 150/500\n",
            "18/18 - 0s - loss: 0.0569 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0763 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 151/500\n",
            "18/18 - 0s - loss: 0.0835 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0616 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 152/500\n",
            "18/18 - 0s - loss: 0.1066 - acc: 0.9667 - precision: 0.9565 - recall: 0.9778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0705 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 153/500\n",
            "18/18 - 0s - loss: 0.1645 - acc: 0.9444 - precision: 0.9651 - recall: 0.9222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0789 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 154/500\n",
            "18/18 - 0s - loss: 0.0941 - acc: 0.9556 - precision: 0.9271 - recall: 0.9889 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.0875 - val_acc: 0.9500 - val_precision: 1.0000 - val_recall: 0.9000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 155/500\n",
            "18/18 - 0s - loss: 0.1056 - acc: 0.9667 - precision: 0.9884 - recall: 0.9444 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.3077 - val_acc: 0.7500 - val_precision: 0.6667 - val_recall: 1.0000 - val_tn: 15.0000 - val_fp: 15.0000\n",
            "Epoch 156/500\n",
            "18/18 - 0s - loss: 0.1149 - acc: 0.9667 - precision: 0.9565 - recall: 0.9778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0712 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 157/500\n",
            "18/18 - 0s - loss: 0.1021 - acc: 0.9611 - precision: 0.9462 - recall: 0.9778 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.0610 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 158/500\n",
            "18/18 - 0s - loss: 0.0837 - acc: 0.9778 - precision: 1.0000 - recall: 0.9556 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0778 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 159/500\n",
            "18/18 - 0s - loss: 0.0636 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0549 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 160/500\n",
            "18/18 - 0s - loss: 0.0358 - acc: 0.9889 - precision: 0.9783 - recall: 1.0000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0469 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 161/500\n",
            "18/18 - 0s - loss: 0.0833 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0794 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 162/500\n",
            "18/18 - 0s - loss: 0.0623 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0617 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 163/500\n",
            "18/18 - 0s - loss: 0.0830 - acc: 0.9667 - precision: 0.9468 - recall: 0.9889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.0587 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 164/500\n",
            "18/18 - 0s - loss: 0.0800 - acc: 0.9722 - precision: 1.0000 - recall: 0.9444 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.1222 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 165/500\n",
            "18/18 - 0s - loss: 0.0689 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0541 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 166/500\n",
            "18/18 - 0s - loss: 0.0829 - acc: 0.9667 - precision: 0.9565 - recall: 0.9778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0789 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 167/500\n",
            "18/18 - 0s - loss: 0.0624 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1312 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 168/500\n",
            "18/18 - 0s - loss: 0.0466 - acc: 0.9889 - precision: 0.9889 - recall: 0.9889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0499 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 169/500\n",
            "18/18 - 0s - loss: 0.0230 - acc: 0.9944 - precision: 1.0000 - recall: 0.9889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.1132 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 170/500\n",
            "18/18 - 0s - loss: 0.0229 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.1176 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 171/500\n",
            "18/18 - 0s - loss: 0.0435 - acc: 0.9833 - precision: 0.9888 - recall: 0.9778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0316 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 172/500\n",
            "18/18 - 0s - loss: 0.0713 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0333 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 173/500\n",
            "18/18 - 0s - loss: 0.0909 - acc: 0.9611 - precision: 0.9770 - recall: 0.9444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1577 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 174/500\n",
            "18/18 - 0s - loss: 0.0873 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2757 - val_acc: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000 - val_tn: 18.0000 - val_fp: 12.0000\n",
            "Epoch 175/500\n",
            "18/18 - 0s - loss: 0.1040 - acc: 0.9389 - precision: 0.9341 - recall: 0.9444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.0538 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 176/500\n",
            "18/18 - 0s - loss: 0.0633 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0783 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 177/500\n",
            "18/18 - 0s - loss: 0.0485 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0650 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 178/500\n",
            "18/18 - 0s - loss: 0.0192 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0599 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 179/500\n",
            "18/18 - 0s - loss: 0.0182 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0386 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 180/500\n",
            "18/18 - 0s - loss: 0.1252 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0337 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 181/500\n",
            "18/18 - 0s - loss: 0.0993 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.0590 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 182/500\n",
            "18/18 - 0s - loss: 0.0713 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0414 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 183/500\n",
            "18/18 - 0s - loss: 0.0386 - acc: 0.9944 - precision: 1.0000 - recall: 0.9889 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.1528 - val_acc: 0.9333 - val_precision: 0.8824 - val_recall: 1.0000 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 184/500\n",
            "18/18 - 0s - loss: 0.0878 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0660 - val_acc: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 185/500\n",
            "18/18 - 0s - loss: 0.1327 - acc: 0.9389 - precision: 0.9341 - recall: 0.9444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.0381 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 186/500\n",
            "18/18 - 0s - loss: 0.0925 - acc: 0.9833 - precision: 1.0000 - recall: 0.9667 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.0569 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 187/500\n",
            "18/18 - 0s - loss: 0.0475 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1070 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 188/500\n",
            "18/18 - 0s - loss: 0.0605 - acc: 0.9778 - precision: 0.9778 - recall: 0.9778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0741 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 189/500\n",
            "18/18 - 0s - loss: 0.0905 - acc: 0.9833 - precision: 0.9780 - recall: 0.9889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0498 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 190/500\n",
            "18/18 - 0s - loss: 0.1059 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.1188 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 191/500\n",
            "18/18 - 0s - loss: 0.0548 - acc: 0.9722 - precision: 0.9885 - recall: 0.9556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.0747 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 192/500\n",
            "18/18 - 0s - loss: 0.0787 - acc: 0.9889 - precision: 0.9783 - recall: 1.0000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.0440 - val_acc: 0.9833 - val_precision: 1.0000 - val_recall: 0.9667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 193/500\n",
            "18/18 - 0s - loss: 0.0849 - acc: 0.9722 - precision: 0.9775 - recall: 0.9667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1016 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 194/500\n",
            "18/18 - 0s - loss: 0.1125 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.1713 - val_acc: 0.9333 - val_precision: 0.8824 - val_recall: 1.0000 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 195/500\n",
            "18/18 - 0s - loss: 0.0662 - acc: 0.9667 - precision: 0.9468 - recall: 0.9889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.0435 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 196/500\n",
            "18/18 - 0s - loss: 0.0797 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.0758 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.0000 - fp: 0.0000e+00    \n",
            "loss:\n",
            "[0.03161749243736267, 1.0, 1.0, 1.0, 30.0, 0.0]\n",
            "['loss', 'acc', 'precision', 'recall', 'tn', 'fp']\n",
            "Training and evaluating on fold 7 out of 8...\n",
            "train_index[  0   2   3   4   5   6   7  11  12  13  15  16  17  18  19  21  22  23\n",
            "  24  25  26  28  29  31  32  34  35  36  40  41  42  43  44  45  46  47\n",
            "  48  49  51  53  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
            "  70  71  72  73  74  76  77  79  80  82  85  86  87  88  90  91  93  94\n",
            "  96  97  98 100 101 102 103 104 105 106 107 108 109 110 111 112 114 116\n",
            " 121 122 123 124 125 130 133 134 135 136 137 138 139 140 141 143 144 147\n",
            " 148 151 152 153 154 155 156 157 158 159 161 162 164 165 167 168 169 170\n",
            " 171 172 173 174 175 176 177 178 182 183 184 185 186 188 190 191 192 193\n",
            " 194 195 196 197 198 199 200 202 203 204 205 206 207 210 211 212 215 216\n",
            " 217 218 219 220 222 223 225 226 227 228 230 232 233 234 236 237 238 239]\n",
            "test_index[  1   8   9  10  14  20  27  30  33  37  38  39  50  52  54  55  75  78\n",
            "  81  83  84  89  92  95  99 113 115 117 118 119 120 126 127 128 129 131\n",
            " 132 142 145 146 149 150 160 163 166 179 180 181 187 189 201 208 209 213\n",
            " 214 221 224 229 231 235]\n",
            "Epoch 1/500\n",
            "18/18 - 2s - loss: 0.7065 - acc: 0.4444 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.6951 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 2/500\n",
            "18/18 - 0s - loss: 0.7019 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6938 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 3/500\n",
            "18/18 - 0s - loss: 0.6990 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6936 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 4/500\n",
            "18/18 - 0s - loss: 0.6963 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 5/500\n",
            "18/18 - 0s - loss: 0.6953 - acc: 0.4056 - precision: 0.4220 - recall: 0.5111 - tn: 27.0000 - fp: 63.0000 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 6/500\n",
            "18/18 - 0s - loss: 0.6967 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 7/500\n",
            "18/18 - 0s - loss: 0.6942 - acc: 0.4056 - precision: 0.4286 - recall: 0.5667 - tn: 22.0000 - fp: 68.0000 - val_loss: 0.6928 - val_acc: 0.5333 - val_precision: 1.0000 - val_recall: 0.0667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 8/500\n",
            "18/18 - 0s - loss: 0.6972 - acc: 0.5000 - precision: 0.5000 - recall: 0.0111 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6930 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 9/500\n",
            "18/18 - 0s - loss: 0.6940 - acc: 0.5333 - precision: 0.8750 - recall: 0.0778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6916 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 10/500\n",
            "18/18 - 0s - loss: 0.7496 - acc: 0.4944 - precision: 0.4972 - recall: 0.9889 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 11/500\n",
            "18/18 - 0s - loss: 0.6948 - acc: 0.4333 - precision: 0.3846 - recall: 0.2222 - tn: 58.0000 - fp: 32.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 12/500\n",
            "18/18 - 0s - loss: 0.6941 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 13/500\n",
            "18/18 - 0s - loss: 0.6949 - acc: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6933 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 14/500\n",
            "18/18 - 0s - loss: 0.6963 - acc: 0.3000 - precision: 0.0909 - recall: 0.0444 - tn: 50.0000 - fp: 40.0000 - val_loss: 0.6928 - val_acc: 0.6000 - val_precision: 0.5577 - val_recall: 0.9667 - val_tn: 7.0000 - val_fp: 23.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/500\n",
            "18/18 - 0s - loss: 0.6953 - acc: 0.5000 - precision: 0.5000 - recall: 0.0556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 16/500\n",
            "18/18 - 0s - loss: 0.6933 - acc: 0.5333 - precision: 1.0000 - recall: 0.0667 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.6927 - val_acc: 0.5167 - val_precision: 1.0000 - val_recall: 0.0333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 17/500\n",
            "18/18 - 0s - loss: 0.6924 - acc: 0.5333 - precision: 0.6667 - recall: 0.1333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.6925 - val_acc: 0.5333 - val_precision: 1.0000 - val_recall: 0.0667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 18/500\n",
            "18/18 - 0s - loss: 0.6906 - acc: 0.5667 - precision: 0.8000 - recall: 0.1778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.6909 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 19/500\n",
            "18/18 - 0s - loss: 0.6910 - acc: 0.4000 - precision: 0.4100 - recall: 0.4556 - tn: 31.0000 - fp: 59.0000 - val_loss: 0.6901 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 20/500\n",
            "18/18 - 0s - loss: 0.6865 - acc: 0.5889 - precision: 0.9444 - recall: 0.1889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6874 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 21/500\n",
            "18/18 - 0s - loss: 0.6833 - acc: 0.5056 - precision: 0.5070 - recall: 0.4000 - tn: 55.0000 - fp: 35.0000 - val_loss: 0.6831 - val_acc: 0.6167 - val_precision: 0.7692 - val_recall: 0.3333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 22/500\n",
            "18/18 - 0s - loss: 0.6723 - acc: 0.6500 - precision: 0.8857 - recall: 0.3444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.6695 - val_acc: 0.6667 - val_precision: 0.7273 - val_recall: 0.5333 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 23/500\n",
            "18/18 - 0s - loss: 0.6662 - acc: 0.5889 - precision: 0.6538 - recall: 0.3778 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.6604 - val_acc: 0.6167 - val_precision: 0.7692 - val_recall: 0.3333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 24/500\n",
            "18/18 - 0s - loss: 0.7263 - acc: 0.6778 - precision: 0.7286 - recall: 0.5667 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.6568 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 25/500\n",
            "18/18 - 0s - loss: 0.7072 - acc: 0.5000 - precision: 0.5000 - recall: 0.4556 - tn: 49.0000 - fp: 41.0000 - val_loss: 0.6688 - val_acc: 0.6167 - val_precision: 0.7692 - val_recall: 0.3333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 26/500\n",
            "18/18 - 0s - loss: 0.6713 - acc: 0.6000 - precision: 0.8750 - recall: 0.2333 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.6698 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 27/500\n",
            "18/18 - 0s - loss: 0.6665 - acc: 0.6056 - precision: 0.8276 - recall: 0.2667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.6645 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 28/500\n",
            "18/18 - 0s - loss: 0.6440 - acc: 0.6667 - precision: 0.9688 - recall: 0.3444 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6551 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 29/500\n",
            "18/18 - 0s - loss: 0.6472 - acc: 0.6222 - precision: 0.8056 - recall: 0.3222 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.6457 - val_acc: 0.6167 - val_precision: 0.7692 - val_recall: 0.3333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 30/500\n",
            "18/18 - 0s - loss: 0.6462 - acc: 0.5778 - precision: 0.6129 - recall: 0.4222 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.6340 - val_acc: 0.6167 - val_precision: 0.7692 - val_recall: 0.3333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 31/500\n",
            "18/18 - 0s - loss: 0.6103 - acc: 0.6556 - precision: 0.8043 - recall: 0.4111 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.6203 - val_acc: 0.6167 - val_precision: 0.7692 - val_recall: 0.3333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 32/500\n",
            "18/18 - 0s - loss: 0.5938 - acc: 0.6556 - precision: 0.8043 - recall: 0.4111 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.6068 - val_acc: 0.6167 - val_precision: 0.7692 - val_recall: 0.3333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 33/500\n",
            "18/18 - 0s - loss: 0.5937 - acc: 0.6667 - precision: 0.7273 - recall: 0.5333 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.5932 - val_acc: 0.6667 - val_precision: 0.8125 - val_recall: 0.4333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 34/500\n",
            "18/18 - 0s - loss: 0.5696 - acc: 0.6611 - precision: 0.7101 - recall: 0.5444 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.5892 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 35/500\n",
            "18/18 - 0s - loss: 0.5967 - acc: 0.6722 - precision: 0.8605 - recall: 0.4111 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5819 - val_acc: 0.6333 - val_precision: 0.7857 - val_recall: 0.3667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 36/500\n",
            "18/18 - 0s - loss: 0.5855 - acc: 0.6500 - precision: 0.6901 - recall: 0.5444 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.5690 - val_acc: 0.6833 - val_precision: 0.8235 - val_recall: 0.4667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 37/500\n",
            "18/18 - 0s - loss: 0.5859 - acc: 0.6500 - precision: 0.7647 - recall: 0.4333 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.5846 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 38/500\n",
            "18/18 - 0s - loss: 0.4990 - acc: 0.7333 - precision: 0.9038 - recall: 0.5222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5513 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 39/500\n",
            "18/18 - 0s - loss: 0.5266 - acc: 0.7056 - precision: 0.7606 - recall: 0.6000 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.5252 - val_acc: 0.7333 - val_precision: 0.8500 - val_recall: 0.5667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 40/500\n",
            "18/18 - 0s - loss: 0.5295 - acc: 0.7222 - precision: 0.8125 - recall: 0.5778 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.5510 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 41/500\n",
            "18/18 - 0s - loss: 0.5669 - acc: 0.6222 - precision: 0.6341 - recall: 0.5778 - tn: 60.0000 - fp: 30.0000 - val_loss: 0.5445 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 42/500\n",
            "18/18 - 0s - loss: 0.4810 - acc: 0.7667 - precision: 0.8750 - recall: 0.6222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5367 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 43/500\n",
            "18/18 - 0s - loss: 0.4743 - acc: 0.7500 - precision: 0.8358 - recall: 0.6222 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5271 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 44/500\n",
            "18/18 - 0s - loss: 0.5467 - acc: 0.7111 - precision: 0.8276 - recall: 0.5333 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5257 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 45/500\n",
            "18/18 - 0s - loss: 0.5405 - acc: 0.6944 - precision: 0.8302 - recall: 0.4889 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5570 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 46/500\n",
            "18/18 - 0s - loss: 0.5145 - acc: 0.6889 - precision: 0.8696 - recall: 0.4444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5291 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 47/500\n",
            "18/18 - 0s - loss: 0.4992 - acc: 0.7000 - precision: 0.7571 - recall: 0.5889 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.5297 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 48/500\n",
            "18/18 - 0s - loss: 0.5080 - acc: 0.7444 - precision: 0.8929 - recall: 0.5556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4969 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 49/500\n",
            "18/18 - 0s - loss: 0.4441 - acc: 0.7611 - precision: 0.7474 - recall: 0.7889 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.5188 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50/500\n",
            "18/18 - 0s - loss: 0.5138 - acc: 0.7111 - precision: 0.8167 - recall: 0.5444 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5147 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 51/500\n",
            "18/18 - 0s - loss: 0.4503 - acc: 0.8167 - precision: 0.8519 - recall: 0.7667 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.5102 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 52/500\n",
            "18/18 - 0s - loss: 0.5021 - acc: 0.7556 - precision: 0.7614 - recall: 0.7444 - tn: 69.0000 - fp: 21.0000 - val_loss: 0.5490 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 53/500\n",
            "18/18 - 0s - loss: 0.5384 - acc: 0.6833 - precision: 0.9231 - recall: 0.4000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5423 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 54/500\n",
            "18/18 - 0s - loss: 0.5049 - acc: 0.6333 - precision: 0.6333 - recall: 0.6333 - tn: 57.0000 - fp: 33.0000 - val_loss: 0.5339 - val_acc: 0.7667 - val_precision: 0.7353 - val_recall: 0.8333 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 55/500\n",
            "18/18 - 0s - loss: 0.4695 - acc: 0.7444 - precision: 0.7750 - recall: 0.6889 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.5096 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 56/500\n",
            "18/18 - 0s - loss: 0.3981 - acc: 0.8111 - precision: 0.8684 - recall: 0.7333 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4686 - val_acc: 0.7667 - val_precision: 0.7353 - val_recall: 0.8333 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 57/500\n",
            "18/18 - 0s - loss: 0.4465 - acc: 0.7444 - precision: 0.7895 - recall: 0.6667 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5069 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 58/500\n",
            "18/18 - 0s - loss: 0.4496 - acc: 0.7556 - precision: 0.8485 - recall: 0.6222 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5005 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 59/500\n",
            "18/18 - 0s - loss: 0.4310 - acc: 0.7611 - precision: 0.8983 - recall: 0.5889 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4796 - val_acc: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 60/500\n",
            "18/18 - 0s - loss: 0.4729 - acc: 0.7389 - precision: 0.6937 - recall: 0.8556 - tn: 56.0000 - fp: 34.0000 - val_loss: 0.5100 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 61/500\n",
            "18/18 - 0s - loss: 0.5089 - acc: 0.7000 - precision: 0.9286 - recall: 0.4333 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5194 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 62/500\n",
            "18/18 - 0s - loss: 0.4394 - acc: 0.7556 - precision: 0.7556 - recall: 0.7556 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.4929 - val_acc: 0.7500 - val_precision: 0.7273 - val_recall: 0.8000 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 63/500\n",
            "18/18 - 0s - loss: 0.3560 - acc: 0.8000 - precision: 0.7596 - recall: 0.8778 - tn: 65.0000 - fp: 25.0000 - val_loss: 0.4598 - val_acc: 0.7500 - val_precision: 0.8000 - val_recall: 0.6667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 64/500\n",
            "18/18 - 0s - loss: 0.4115 - acc: 0.8056 - precision: 0.8235 - recall: 0.7778 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.4766 - val_acc: 0.8167 - val_precision: 0.8276 - val_recall: 0.8000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 65/500\n",
            "18/18 - 0s - loss: 0.4780 - acc: 0.7167 - precision: 0.7053 - recall: 0.7444 - tn: 62.0000 - fp: 28.0000 - val_loss: 0.4966 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 66/500\n",
            "18/18 - 0s - loss: 0.4590 - acc: 0.7556 - precision: 0.9107 - recall: 0.5667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4790 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 67/500\n",
            "18/18 - 0s - loss: 0.3637 - acc: 0.8056 - precision: 0.8481 - recall: 0.7444 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.4517 - val_acc: 0.7833 - val_precision: 0.8148 - val_recall: 0.7333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 68/500\n",
            "18/18 - 0s - loss: 0.4534 - acc: 0.8056 - precision: 0.8022 - recall: 0.8111 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4884 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 69/500\n",
            "18/18 - 0s - loss: 0.4329 - acc: 0.7722 - precision: 0.7882 - recall: 0.7444 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4876 - val_acc: 0.7667 - val_precision: 0.7500 - val_recall: 0.8000 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 70/500\n",
            "18/18 - 0s - loss: 0.3444 - acc: 0.8500 - precision: 0.8462 - recall: 0.8556 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.4465 - val_acc: 0.7667 - val_precision: 0.8077 - val_recall: 0.7000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 71/500\n",
            "18/18 - 0s - loss: 0.3746 - acc: 0.8000 - precision: 0.7872 - recall: 0.8222 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.4423 - val_acc: 0.8000 - val_precision: 0.7500 - val_recall: 0.9000 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 72/500\n",
            "18/18 - 0s - loss: 0.4137 - acc: 0.7667 - precision: 0.8429 - recall: 0.6556 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4701 - val_acc: 0.8167 - val_precision: 0.9130 - val_recall: 0.7000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 73/500\n",
            "18/18 - 0s - loss: 0.3879 - acc: 0.8333 - precision: 0.8571 - recall: 0.8000 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.4492 - val_acc: 0.7500 - val_precision: 0.8000 - val_recall: 0.6667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 74/500\n",
            "18/18 - 0s - loss: 0.3237 - acc: 0.8389 - precision: 0.8280 - recall: 0.8556 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4439 - val_acc: 0.7500 - val_precision: 0.7419 - val_recall: 0.7667 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 75/500\n",
            "18/18 - 0s - loss: 0.2495 - acc: 0.8944 - precision: 0.8737 - recall: 0.9222 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.3991 - val_acc: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 76/500\n",
            "18/18 - 0s - loss: 0.3519 - acc: 0.8389 - precision: 0.8081 - recall: 0.8889 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.4021 - val_acc: 0.8500 - val_precision: 0.8387 - val_recall: 0.8667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 77/500\n",
            "18/18 - 0s - loss: 0.3375 - acc: 0.8278 - precision: 0.8391 - recall: 0.8111 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.4527 - val_acc: 0.7500 - val_precision: 0.7419 - val_recall: 0.7667 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 78/500\n",
            "18/18 - 0s - loss: 0.3389 - acc: 0.7944 - precision: 0.7978 - recall: 0.7889 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.4400 - val_acc: 0.7833 - val_precision: 1.0000 - val_recall: 0.5667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 79/500\n",
            "18/18 - 0s - loss: 0.3407 - acc: 0.8500 - precision: 0.8387 - recall: 0.8667 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.4149 - val_acc: 0.8000 - val_precision: 0.8214 - val_recall: 0.7667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 80/500\n",
            "18/18 - 0s - loss: 0.3706 - acc: 0.8278 - precision: 0.8554 - recall: 0.7889 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.4229 - val_acc: 0.7833 - val_precision: 0.8148 - val_recall: 0.7333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 81/500\n",
            "18/18 - 0s - loss: 0.2689 - acc: 0.8722 - precision: 0.8764 - recall: 0.8667 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.3993 - val_acc: 0.8500 - val_precision: 0.7838 - val_recall: 0.9667 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 82/500\n",
            "18/18 - 0s - loss: 0.3153 - acc: 0.8667 - precision: 0.8587 - recall: 0.8778 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.4404 - val_acc: 0.7500 - val_precision: 0.8000 - val_recall: 0.6667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 83/500\n",
            "18/18 - 0s - loss: 0.3551 - acc: 0.8333 - precision: 0.7941 - recall: 0.9000 - tn: 69.0000 - fp: 21.0000 - val_loss: 0.4155 - val_acc: 0.7833 - val_precision: 0.7742 - val_recall: 0.8000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 84/500\n",
            "18/18 - 0s - loss: 0.3073 - acc: 0.8778 - precision: 0.8469 - recall: 0.9222 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.4101 - val_acc: 0.7500 - val_precision: 0.8000 - val_recall: 0.6667 - val_tn: 25.0000 - val_fp: 5.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 85/500\n",
            "18/18 - 0s - loss: 0.3946 - acc: 0.8111 - precision: 0.8182 - recall: 0.8000 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4172 - val_acc: 0.8500 - val_precision: 0.8387 - val_recall: 0.8667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 86/500\n",
            "18/18 - 0s - loss: 0.3141 - acc: 0.8444 - precision: 0.8523 - recall: 0.8333 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.4130 - val_acc: 0.8500 - val_precision: 0.8387 - val_recall: 0.8667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 87/500\n",
            "18/18 - 0s - loss: 0.3649 - acc: 0.8278 - precision: 0.8933 - recall: 0.7444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4164 - val_acc: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 88/500\n",
            "18/18 - 0s - loss: 0.3147 - acc: 0.8444 - precision: 0.8370 - recall: 0.8556 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.4115 - val_acc: 0.8500 - val_precision: 0.8000 - val_recall: 0.9333 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 89/500\n",
            "18/18 - 0s - loss: 0.2296 - acc: 0.9056 - precision: 0.8925 - recall: 0.9222 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4012 - val_acc: 0.8667 - val_precision: 0.8235 - val_recall: 0.9333 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 90/500\n",
            "18/18 - 0s - loss: 0.2247 - acc: 0.9000 - precision: 0.8830 - recall: 0.9222 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.3798 - val_acc: 0.8167 - val_precision: 0.8276 - val_recall: 0.8000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 91/500\n",
            "18/18 - 0s - loss: 0.3047 - acc: 0.8778 - precision: 0.8617 - recall: 0.9000 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.4160 - val_acc: 0.7667 - val_precision: 0.8077 - val_recall: 0.7000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 92/500\n",
            "18/18 - 0s - loss: 0.3240 - acc: 0.8500 - precision: 0.9200 - recall: 0.7667 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4395 - val_acc: 0.8167 - val_precision: 0.7879 - val_recall: 0.8667 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 93/500\n",
            "18/18 - 0s - loss: 0.2818 - acc: 0.8556 - precision: 0.8019 - recall: 0.9444 - tn: 69.0000 - fp: 21.0000 - val_loss: 0.3790 - val_acc: 0.8667 - val_precision: 0.8438 - val_recall: 0.9000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 94/500\n",
            "18/18 - 0s - loss: 0.2381 - acc: 0.9000 - precision: 0.9000 - recall: 0.9000 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3608 - val_acc: 0.9000 - val_precision: 0.8529 - val_recall: 0.9667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 95/500\n",
            "18/18 - 0s - loss: 0.2274 - acc: 0.9111 - precision: 0.8700 - recall: 0.9667 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.3699 - val_acc: 0.7833 - val_precision: 0.8148 - val_recall: 0.7333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 96/500\n",
            "18/18 - 0s - loss: 0.2193 - acc: 0.8944 - precision: 0.9277 - recall: 0.8556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3618 - val_acc: 0.9000 - val_precision: 0.8529 - val_recall: 0.9667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 97/500\n",
            "18/18 - 0s - loss: 0.2650 - acc: 0.8722 - precision: 0.8454 - recall: 0.9111 - tn: 75.0000 - fp: 15.0000 - val_loss: 0.3567 - val_acc: 0.9000 - val_precision: 0.8529 - val_recall: 0.9667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 98/500\n",
            "18/18 - 0s - loss: 0.2468 - acc: 0.8944 - precision: 0.8989 - recall: 0.8889 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3201 - val_acc: 0.9000 - val_precision: 0.8529 - val_recall: 0.9667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 99/500\n",
            "18/18 - 0s - loss: 0.2007 - acc: 0.9000 - precision: 0.8673 - recall: 0.9444 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.3776 - val_acc: 0.7667 - val_precision: 0.8077 - val_recall: 0.7000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 100/500\n",
            "18/18 - 0s - loss: 0.3092 - acc: 0.8833 - precision: 0.8791 - recall: 0.8889 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.3925 - val_acc: 0.7833 - val_precision: 0.8148 - val_recall: 0.7333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 101/500\n",
            "18/18 - 0s - loss: 0.3529 - acc: 0.8500 - precision: 0.8706 - recall: 0.8222 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.3860 - val_acc: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 102/500\n",
            "18/18 - 0s - loss: 0.2388 - acc: 0.9222 - precision: 0.9130 - recall: 0.9333 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3519 - val_acc: 0.8500 - val_precision: 0.8387 - val_recall: 0.8667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 103/500\n",
            "18/18 - 0s - loss: 0.2192 - acc: 0.9278 - precision: 0.8969 - recall: 0.9667 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3675 - val_acc: 0.8667 - val_precision: 0.8235 - val_recall: 0.9333 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 104/500\n",
            "18/18 - 0s - loss: 0.3087 - acc: 0.8389 - precision: 0.8211 - recall: 0.8667 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.4236 - val_acc: 0.8167 - val_precision: 0.7317 - val_recall: 1.0000 - val_tn: 19.0000 - val_fp: 11.0000\n",
            "Epoch 105/500\n",
            "18/18 - 0s - loss: 0.3043 - acc: 0.8944 - precision: 0.9176 - recall: 0.8667 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3920 - val_acc: 0.8667 - val_precision: 0.8438 - val_recall: 0.9000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 106/500\n",
            "18/18 - 0s - loss: 0.2199 - acc: 0.9167 - precision: 0.9310 - recall: 0.9000 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5103 - val_acc: 0.7500 - val_precision: 0.6667 - val_recall: 1.0000 - val_tn: 15.0000 - val_fp: 15.0000\n",
            "Epoch 107/500\n",
            "18/18 - 0s - loss: 0.2332 - acc: 0.8944 - precision: 0.8901 - recall: 0.9000 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4627 - val_acc: 0.7667 - val_precision: 0.6905 - val_recall: 0.9667 - val_tn: 17.0000 - val_fp: 13.0000\n",
            "Epoch 108/500\n",
            "18/18 - 0s - loss: 0.1741 - acc: 0.9389 - precision: 0.9247 - recall: 0.9556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3481 - val_acc: 0.8500 - val_precision: 0.7838 - val_recall: 0.9667 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 109/500\n",
            "18/18 - 0s - loss: 0.2397 - acc: 0.9222 - precision: 0.9318 - recall: 0.9111 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3919 - val_acc: 0.8333 - val_precision: 0.7632 - val_recall: 0.9667 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 110/500\n",
            "18/18 - 0s - loss: 0.2597 - acc: 0.9167 - precision: 0.9032 - recall: 0.9333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4417 - val_acc: 0.7333 - val_precision: 0.6591 - val_recall: 0.9667 - val_tn: 15.0000 - val_fp: 15.0000\n",
            "Epoch 111/500\n",
            "18/18 - 0s - loss: 0.2247 - acc: 0.9333 - precision: 0.9333 - recall: 0.9333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4400 - val_acc: 0.7500 - val_precision: 0.6667 - val_recall: 1.0000 - val_tn: 15.0000 - val_fp: 15.0000\n",
            "Epoch 112/500\n",
            "18/18 - 0s - loss: 0.2665 - acc: 0.8667 - precision: 0.8667 - recall: 0.8667 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.3065 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 113/500\n",
            "18/18 - 0s - loss: 0.2612 - acc: 0.8833 - precision: 0.8165 - recall: 0.9889 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.3350 - val_acc: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 114/500\n",
            "18/18 - 0s - loss: 0.2815 - acc: 0.8833 - precision: 0.9059 - recall: 0.8556 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4240 - val_acc: 0.7833 - val_precision: 0.6977 - val_recall: 1.0000 - val_tn: 17.0000 - val_fp: 13.0000\n",
            "Epoch 115/500\n",
            "18/18 - 0s - loss: 0.1990 - acc: 0.9222 - precision: 0.9419 - recall: 0.9000 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2946 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 116/500\n",
            "18/18 - 0s - loss: 0.2526 - acc: 0.9167 - precision: 0.8788 - recall: 0.9667 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.2833 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 117/500\n",
            "18/18 - 0s - loss: 0.2009 - acc: 0.9056 - precision: 0.9740 - recall: 0.8333 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3099 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 118/500\n",
            "18/18 - 0s - loss: 0.1611 - acc: 0.9389 - precision: 0.9540 - recall: 0.9222 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2946 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 119/500\n",
            "18/18 - 0s - loss: 0.1822 - acc: 0.9333 - precision: 0.9432 - recall: 0.9222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2916 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 120/500\n",
            "18/18 - 0s - loss: 0.1202 - acc: 0.9778 - precision: 0.9574 - recall: 1.0000 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3097 - val_acc: 0.9167 - val_precision: 0.8788 - val_recall: 0.9667 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 121/500\n",
            "18/18 - 0s - loss: 0.1643 - acc: 0.9222 - precision: 0.9419 - recall: 0.9000 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.5561 - val_acc: 0.7500 - val_precision: 0.6667 - val_recall: 1.0000 - val_tn: 15.0000 - val_fp: 15.0000\n",
            "Epoch 122/500\n",
            "18/18 - 0s - loss: 0.1895 - acc: 0.9333 - precision: 0.9333 - recall: 0.9333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4991 - val_acc: 0.7500 - val_precision: 0.6667 - val_recall: 1.0000 - val_tn: 15.0000 - val_fp: 15.0000\n",
            "Epoch 123/500\n",
            "18/18 - 0s - loss: 0.2953 - acc: 0.8667 - precision: 0.8667 - recall: 0.8667 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.4203 - val_acc: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000 - val_tn: 18.0000 - val_fp: 12.0000\n",
            "Epoch 124/500\n",
            "18/18 - 0s - loss: 0.1621 - acc: 0.9333 - precision: 0.9333 - recall: 0.9333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3209 - val_acc: 0.8500 - val_precision: 0.8000 - val_recall: 0.9333 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 125/500\n",
            "18/18 - 0s - loss: 0.2008 - acc: 0.9167 - precision: 0.8947 - recall: 0.9444 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.2846 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 126/500\n",
            "18/18 - 0s - loss: 0.1734 - acc: 0.9167 - precision: 0.9310 - recall: 0.9000 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3794 - val_acc: 0.7667 - val_precision: 0.6905 - val_recall: 0.9667 - val_tn: 17.0000 - val_fp: 13.0000\n",
            "Epoch 127/500\n",
            "18/18 - 0s - loss: 0.1565 - acc: 0.9556 - precision: 0.9767 - recall: 0.9333 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4984 - val_acc: 0.7167 - val_precision: 0.6383 - val_recall: 1.0000 - val_tn: 13.0000 - val_fp: 17.0000\n",
            "Epoch 128/500\n",
            "18/18 - 0s - loss: 0.1313 - acc: 0.9500 - precision: 0.9451 - recall: 0.9556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3177 - val_acc: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 129/500\n",
            "18/18 - 0s - loss: 0.1486 - acc: 0.9444 - precision: 0.9651 - recall: 0.9222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.8774 - val_acc: 0.5833 - val_precision: 0.5455 - val_recall: 1.0000 - val_tn: 5.0000 - val_fp: 25.0000\n",
            "Epoch 130/500\n",
            "18/18 - 0s - loss: 0.2308 - acc: 0.8833 - precision: 0.8632 - recall: 0.9111 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.2948 - val_acc: 0.8833 - val_precision: 0.8966 - val_recall: 0.8667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 131/500\n",
            "18/18 - 0s - loss: 0.2096 - acc: 0.9278 - precision: 0.8969 - recall: 0.9667 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3387 - val_acc: 0.9167 - val_precision: 0.8571 - val_recall: 1.0000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 132/500\n",
            "18/18 - 0s - loss: 0.1196 - acc: 0.9500 - precision: 0.9355 - recall: 0.9667 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2362 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 133/500\n",
            "18/18 - 0s - loss: 0.1795 - acc: 0.9278 - precision: 0.9425 - recall: 0.9111 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2160 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 134/500\n",
            "18/18 - 0s - loss: 0.1697 - acc: 0.9333 - precision: 0.9062 - recall: 0.9667 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3044 - val_acc: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 135/500\n",
            "18/18 - 0s - loss: 0.1782 - acc: 0.9222 - precision: 0.9222 - recall: 0.9222 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3585 - val_acc: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 136/500\n",
            "18/18 - 0s - loss: 0.1233 - acc: 0.9556 - precision: 0.9881 - recall: 0.9222 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.3892 - val_acc: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000 - val_tn: 18.0000 - val_fp: 12.0000\n",
            "Epoch 137/500\n",
            "18/18 - 0s - loss: 0.1285 - acc: 0.9333 - precision: 0.9333 - recall: 0.9333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.6055 - val_acc: 0.7000 - val_precision: 0.6250 - val_recall: 1.0000 - val_tn: 12.0000 - val_fp: 18.0000\n",
            "Epoch 138/500\n",
            "18/18 - 0s - loss: 0.0813 - acc: 0.9611 - precision: 0.9278 - recall: 1.0000 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3366 - val_acc: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000 - val_tn: 18.0000 - val_fp: 12.0000\n",
            "Epoch 139/500\n",
            "18/18 - 0s - loss: 0.1265 - acc: 0.9667 - precision: 0.9565 - recall: 0.9778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2225 - val_acc: 0.8833 - val_precision: 0.8108 - val_recall: 1.0000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 140/500\n",
            "18/18 - 0s - loss: 0.1374 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4545 - val_acc: 0.7500 - val_precision: 0.6667 - val_recall: 1.0000 - val_tn: 15.0000 - val_fp: 15.0000\n",
            "Epoch 141/500\n",
            "18/18 - 0s - loss: 0.1310 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2185 - val_acc: 0.9000 - val_precision: 0.8529 - val_recall: 0.9667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 142/500\n",
            "18/18 - 0s - loss: 0.1156 - acc: 0.9556 - precision: 0.9271 - recall: 0.9889 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.1652 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 143/500\n",
            "18/18 - 0s - loss: 0.0744 - acc: 0.9778 - precision: 1.0000 - recall: 0.9556 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.2477 - val_acc: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 144/500\n",
            "18/18 - 0s - loss: 0.0696 - acc: 0.9722 - precision: 0.9570 - recall: 0.9889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2979 - val_acc: 0.8667 - val_precision: 0.7895 - val_recall: 1.0000 - val_tn: 22.0000 - val_fp: 8.0000\n",
            "Epoch 145/500\n",
            "18/18 - 0s - loss: 0.1874 - acc: 0.9278 - precision: 0.9326 - recall: 0.9222 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.6382 - val_acc: 0.6333 - val_precision: 0.5769 - val_recall: 1.0000 - val_tn: 8.0000 - val_fp: 22.0000\n",
            "Epoch 146/500\n",
            "18/18 - 0s - loss: 0.1619 - acc: 0.9278 - precision: 0.9326 - recall: 0.9222 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2789 - val_acc: 0.9167 - val_precision: 0.8571 - val_recall: 1.0000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 147/500\n",
            "18/18 - 0s - loss: 0.1186 - acc: 0.9611 - precision: 0.9368 - recall: 0.9889 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.2586 - val_acc: 0.9167 - val_precision: 0.8571 - val_recall: 1.0000 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 148/500\n",
            "18/18 - 0s - loss: 0.0808 - acc: 0.9611 - precision: 0.9770 - recall: 0.9444 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4240 - val_acc: 0.7500 - val_precision: 0.6667 - val_recall: 1.0000 - val_tn: 15.0000 - val_fp: 15.0000\n",
            "Epoch 149/500\n",
            "18/18 - 0s - loss: 0.1778 - acc: 0.9500 - precision: 0.9765 - recall: 0.9222 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.1968 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 150/500\n",
            "18/18 - 0s - loss: 0.2089 - acc: 0.9222 - precision: 0.8800 - recall: 0.9778 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.2166 - val_acc: 0.9333 - val_precision: 0.9062 - val_recall: 0.9667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 151/500\n",
            "18/18 - 0s - loss: 0.2847 - acc: 0.9056 - precision: 0.9506 - recall: 0.8556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3636 - val_acc: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000 - val_tn: 18.0000 - val_fp: 12.0000\n",
            "Epoch 152/500\n",
            "18/18 - 0s - loss: 0.2504 - acc: 0.9000 - precision: 0.8673 - recall: 0.9444 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.2198 - val_acc: 0.9167 - val_precision: 0.9032 - val_recall: 0.9333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 153/500\n",
            "18/18 - 0s - loss: 0.1133 - acc: 0.9778 - precision: 0.9674 - recall: 0.9889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.3435 - val_acc: 0.8167 - val_precision: 0.7317 - val_recall: 1.0000 - val_tn: 19.0000 - val_fp: 11.0000\n",
            "Epoch 154/500\n",
            "18/18 - 0s - loss: 0.1313 - acc: 0.9611 - precision: 0.9663 - recall: 0.9556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.3852 - val_acc: 0.7833 - val_precision: 0.6977 - val_recall: 1.0000 - val_tn: 17.0000 - val_fp: 13.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 155/500\n",
            "18/18 - 0s - loss: 0.1285 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5683 - val_acc: 0.7000 - val_precision: 0.6250 - val_recall: 1.0000 - val_tn: 12.0000 - val_fp: 18.0000\n",
            "Epoch 156/500\n",
            "18/18 - 0s - loss: 0.1790 - acc: 0.9389 - precision: 0.9247 - recall: 0.9556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2389 - val_acc: 0.8833 - val_precision: 0.8108 - val_recall: 1.0000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 157/500\n",
            "18/18 - 0s - loss: 0.1040 - acc: 0.9722 - precision: 1.0000 - recall: 0.9444 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.5633 - val_acc: 0.7500 - val_precision: 0.6667 - val_recall: 1.0000 - val_tn: 15.0000 - val_fp: 15.0000\n",
            "Epoch 158/500\n",
            "18/18 - 0s - loss: 0.1770 - acc: 0.9333 - precision: 0.9062 - recall: 0.9667 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.1856 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 159/500\n",
            "18/18 - 0s - loss: 0.1331 - acc: 0.9500 - precision: 0.9263 - recall: 0.9778 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.2256 - val_acc: 0.9500 - val_precision: 0.9091 - val_recall: 1.0000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 160/500\n",
            "18/18 - 0s - loss: 0.2059 - acc: 0.9222 - precision: 0.9524 - recall: 0.8889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3017 - val_acc: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 161/500\n",
            "18/18 - 0s - loss: 0.1235 - acc: 0.9667 - precision: 0.9468 - recall: 0.9889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2604 - val_acc: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 162/500\n",
            "18/18 - 0s - loss: 0.1141 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2878 - val_acc: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000 - val_tn: 20.0000 - val_fp: 10.0000\n",
            "Epoch 163/500\n",
            "18/18 - 0s - loss: 0.1813 - acc: 0.9556 - precision: 0.9362 - recall: 0.9778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.1902 - val_acc: 0.8833 - val_precision: 0.8108 - val_recall: 1.0000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "Epoch 164/500\n",
            "18/18 - 0s - loss: 0.1912 - acc: 0.9056 - precision: 0.9398 - recall: 0.8667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.7121 - val_acc: 0.6500 - val_precision: 0.5882 - val_recall: 1.0000 - val_tn: 9.0000 - val_fp: 21.0000\n",
            "Epoch 165/500\n",
            "18/18 - 0s - loss: 0.0943 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4353 - val_acc: 0.7833 - val_precision: 0.6977 - val_recall: 1.0000 - val_tn: 17.0000 - val_fp: 13.0000\n",
            "Epoch 166/500\n",
            "18/18 - 0s - loss: 0.0818 - acc: 0.9722 - precision: 0.9670 - recall: 0.9778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5549 - val_acc: 0.7000 - val_precision: 0.6250 - val_recall: 1.0000 - val_tn: 12.0000 - val_fp: 18.0000\n",
            "Epoch 167/500\n",
            "18/18 - 0s - loss: 0.0830 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.2449 - val_acc: 0.8833 - val_precision: 0.8108 - val_recall: 1.0000 - val_tn: 23.0000 - val_fp: 7.0000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1652 - acc: 0.9333 - precision: 0.9062 - recall: 0.9667 - tn: 27.0000 - fp: 3.0000        \n",
            "loss:\n",
            "[0.16516141593456268, 0.9333333373069763, 0.90625, 0.9666666388511658, 27.0, 3.0]\n",
            "['loss', 'acc', 'precision', 'recall', 'tn', 'fp']\n",
            "Training and evaluating on fold 8 out of 8...\n",
            "train_index[  0   1   2   3   4   5   7   8   9  10  11  12  14  16  18  19  20  21\n",
            "  22  23  25  26  27  29  30  31  32  33  34  35  37  38  39  42  43  45\n",
            "  47  48  50  52  53  54  55  57  59  63  64  66  67  68  69  70  71  72\n",
            "  73  74  75  76  78  80  81  82  83  84  86  87  88  89  91  92  93  94\n",
            "  95  98  99 100 101 102 105 106 109 110 111 113 114 115 116 117 118 119\n",
            " 120 121 123 126 127 128 129 130 131 132 135 136 137 138 139 140 141 142\n",
            " 144 145 146 147 148 149 150 151 152 153 154 157 158 159 160 162 163 166\n",
            " 167 168 170 171 172 173 174 176 177 178 179 180 181 182 184 186 187 189\n",
            " 190 193 194 195 200 201 202 203 204 205 206 207 208 209 210 211 213 214\n",
            " 216 217 218 220 221 222 223 224 225 226 229 230 231 232 233 235 236 239]\n",
            "test_index[  6  13  15  17  24  28  36  40  41  44  46  49  51  56  58  60  61  62\n",
            "  65  77  79  85  90  96  97 103 104 107 108 112 122 124 125 133 134 143\n",
            " 155 156 161 164 165 169 175 183 185 188 191 192 196 197 198 199 212 215\n",
            " 219 227 228 234 237 238]\n",
            "Epoch 1/500\n",
            "18/18 - 2s - loss: 0.7298 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6977 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 2/500\n",
            "18/18 - 0s - loss: 0.6995 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 3/500\n",
            "18/18 - 0s - loss: 0.6946 - acc: 0.4000 - precision: 0.0909 - recall: 0.0222 - tn: 70.0000 - fp: 20.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 4/500\n",
            "18/18 - 0s - loss: 0.6941 - acc: 0.4944 - precision: 0.3333 - recall: 0.0111 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.6930 - val_acc: 0.5167 - val_precision: 0.5714 - val_recall: 0.1333 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 5/500\n",
            "18/18 - 0s - loss: 0.6953 - acc: 0.3833 - precision: 0.1111 - recall: 0.0333 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 6/500\n",
            "18/18 - 0s - loss: 0.6951 - acc: 0.2500 - precision: 0.1053 - recall: 0.0667 - tn: 39.0000 - fp: 51.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 7/500\n",
            "18/18 - 0s - loss: 0.6944 - acc: 0.4056 - precision: 0.4479 - recall: 0.8111 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 8/500\n",
            "18/18 - 0s - loss: 0.6939 - acc: 0.3944 - precision: 0.4112 - recall: 0.4889 - tn: 27.0000 - fp: 63.0000 - val_loss: 0.6929 - val_acc: 0.5500 - val_precision: 1.0000 - val_recall: 0.1000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 9/500\n",
            "18/18 - 0s - loss: 0.7036 - acc: 0.3944 - precision: 0.4354 - recall: 0.7111 - tn: 7.0000 - fp: 83.0000 - val_loss: 0.6929 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 10/500\n",
            "18/18 - 0s - loss: 0.6950 - acc: 0.2944 - precision: 0.0698 - recall: 0.0333 - tn: 50.0000 - fp: 40.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 11/500\n",
            "18/18 - 0s - loss: 0.6947 - acc: 0.4444 - precision: 0.0833 - recall: 0.0111 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 12/500\n",
            "18/18 - 0s - loss: 0.6949 - acc: 0.3889 - precision: 0.4167 - recall: 0.5556 - tn: 20.0000 - fp: 70.0000 - val_loss: 0.6928 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 13/500\n",
            "18/18 - 0s - loss: 0.6923 - acc: 0.3889 - precision: 0.4000 - recall: 0.4444 - tn: 30.0000 - fp: 60.0000 - val_loss: 0.6920 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 14/500\n",
            "18/18 - 0s - loss: 0.6928 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6920 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 15/500\n",
            "18/18 - 0s - loss: 0.6879 - acc: 0.5000 - precision: 0.5000 - recall: 1.0000 - tn: 0.0000e+00 - fp: 90.0000 - val_loss: 0.6900 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 16/500\n",
            "18/18 - 0s - loss: 0.6818 - acc: 0.4833 - precision: 0.4870 - recall: 0.6222 - tn: 31.0000 - fp: 59.0000 - val_loss: 0.6869 - val_acc: 0.5833 - val_precision: 1.0000 - val_recall: 0.1667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/500\n",
            "18/18 - 0s - loss: 0.6589 - acc: 0.6333 - precision: 0.7727 - recall: 0.3778 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.6636 - val_acc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_fp: 30.0000\n",
            "Epoch 18/500\n",
            "18/18 - 0s - loss: 0.6726 - acc: 0.4556 - precision: 0.4630 - recall: 0.5556 - tn: 32.0000 - fp: 58.0000 - val_loss: 0.6769 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 19/500\n",
            "18/18 - 0s - loss: 0.6676 - acc: 0.4333 - precision: 0.4538 - recall: 0.6556 - tn: 19.0000 - fp: 71.0000 - val_loss: 0.6741 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 20/500\n",
            "18/18 - 0s - loss: 0.6488 - acc: 0.6500 - precision: 0.8293 - recall: 0.3778 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.6640 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 21/500\n",
            "18/18 - 0s - loss: 0.6011 - acc: 0.6667 - precision: 0.7027 - recall: 0.5778 - tn: 68.0000 - fp: 22.0000 - val_loss: 0.6538 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 22/500\n",
            "18/18 - 0s - loss: 0.6005 - acc: 0.6722 - precision: 0.7925 - recall: 0.4667 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.6411 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 23/500\n",
            "18/18 - 0s - loss: 0.5903 - acc: 0.6722 - precision: 0.7818 - recall: 0.4778 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.6362 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 24/500\n",
            "18/18 - 0s - loss: 0.5692 - acc: 0.6944 - precision: 0.7108 - recall: 0.6556 - tn: 66.0000 - fp: 24.0000 - val_loss: 0.6397 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 25/500\n",
            "18/18 - 0s - loss: 0.5696 - acc: 0.7167 - precision: 0.8980 - recall: 0.4889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.6281 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 26/500\n",
            "18/18 - 0s - loss: 0.5649 - acc: 0.6833 - precision: 0.7324 - recall: 0.5778 - tn: 71.0000 - fp: 19.0000 - val_loss: 0.6430 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 27/500\n",
            "18/18 - 0s - loss: 0.5820 - acc: 0.6611 - precision: 0.9677 - recall: 0.3333 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.6445 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 28/500\n",
            "18/18 - 0s - loss: 0.5659 - acc: 0.6556 - precision: 0.6795 - recall: 0.5889 - tn: 65.0000 - fp: 25.0000 - val_loss: 0.5929 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 29/500\n",
            "18/18 - 0s - loss: 0.5727 - acc: 0.6722 - precision: 0.7925 - recall: 0.4667 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.6267 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 30/500\n",
            "18/18 - 0s - loss: 0.5188 - acc: 0.7389 - precision: 0.8116 - recall: 0.6222 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.6193 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 31/500\n",
            "18/18 - 0s - loss: 0.5919 - acc: 0.6778 - precision: 0.9444 - recall: 0.3778 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.6470 - val_acc: 0.5833 - val_precision: 1.0000 - val_recall: 0.1667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 32/500\n",
            "18/18 - 0s - loss: 0.5238 - acc: 0.7167 - precision: 0.8679 - recall: 0.5111 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.6005 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 33/500\n",
            "18/18 - 0s - loss: 0.4960 - acc: 0.7722 - precision: 0.8551 - recall: 0.6556 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.5939 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 34/500\n",
            "18/18 - 0s - loss: 0.5043 - acc: 0.7389 - precision: 0.8772 - recall: 0.5556 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.6281 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 35/500\n",
            "18/18 - 0s - loss: 0.5785 - acc: 0.6778 - precision: 0.8077 - recall: 0.4667 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.6213 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 36/500\n",
            "18/18 - 0s - loss: 0.5122 - acc: 0.7056 - precision: 0.9302 - recall: 0.4444 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5959 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 37/500\n",
            "18/18 - 0s - loss: 0.4943 - acc: 0.7278 - precision: 0.8254 - recall: 0.5778 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.5606 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 38/500\n",
            "18/18 - 0s - loss: 0.5828 - acc: 0.6667 - precision: 0.7679 - recall: 0.4778 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.6268 - val_acc: 0.6000 - val_precision: 1.0000 - val_recall: 0.2000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 39/500\n",
            "18/18 - 0s - loss: 0.5145 - acc: 0.7111 - precision: 0.9750 - recall: 0.4333 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5983 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 40/500\n",
            "18/18 - 0s - loss: 0.4647 - acc: 0.7778 - precision: 0.8906 - recall: 0.6333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5731 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 41/500\n",
            "18/18 - 0s - loss: 0.4894 - acc: 0.7556 - precision: 0.8108 - recall: 0.6667 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.6010 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 42/500\n",
            "18/18 - 0s - loss: 0.4861 - acc: 0.7500 - precision: 0.9245 - recall: 0.5444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5947 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 43/500\n",
            "18/18 - 0s - loss: 0.5011 - acc: 0.7111 - precision: 0.7879 - recall: 0.5778 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.6053 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 44/500\n",
            "18/18 - 0s - loss: 0.4798 - acc: 0.7722 - precision: 0.9455 - recall: 0.5778 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5879 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 45/500\n",
            "18/18 - 0s - loss: 0.4260 - acc: 0.7889 - precision: 0.9062 - recall: 0.6444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5504 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 46/500\n",
            "18/18 - 0s - loss: 0.4640 - acc: 0.7444 - precision: 0.8143 - recall: 0.6333 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.6316 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 47/500\n",
            "18/18 - 0s - loss: 0.4410 - acc: 0.7611 - precision: 0.9434 - recall: 0.5556 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5720 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 48/500\n",
            "18/18 - 0s - loss: 0.4624 - acc: 0.7389 - precision: 0.7867 - recall: 0.6556 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5586 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 49/500\n",
            "18/18 - 0s - loss: 0.4298 - acc: 0.7833 - precision: 0.9048 - recall: 0.6333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5698 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 50/500\n",
            "18/18 - 0s - loss: 0.4200 - acc: 0.7667 - precision: 0.8636 - recall: 0.6333 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5627 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 51/500\n",
            "18/18 - 0s - loss: 0.4224 - acc: 0.7944 - precision: 0.8732 - recall: 0.6889 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5508 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52/500\n",
            "18/18 - 0s - loss: 0.4500 - acc: 0.7500 - precision: 0.7922 - recall: 0.6778 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.6166 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 53/500\n",
            "18/18 - 0s - loss: 0.3809 - acc: 0.8056 - precision: 0.9365 - recall: 0.6556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5737 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 54/500\n",
            "18/18 - 0s - loss: 0.4312 - acc: 0.8000 - precision: 0.8971 - recall: 0.6778 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5702 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 55/500\n",
            "18/18 - 0s - loss: 0.3676 - acc: 0.8278 - precision: 0.8933 - recall: 0.7444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5464 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 56/500\n",
            "18/18 - 0s - loss: 0.4282 - acc: 0.8167 - precision: 0.9130 - recall: 0.7000 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5724 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 57/500\n",
            "18/18 - 0s - loss: 0.4184 - acc: 0.7944 - precision: 0.8046 - recall: 0.7778 - tn: 73.0000 - fp: 17.0000 - val_loss: 0.5406 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 58/500\n",
            "18/18 - 0s - loss: 0.3447 - acc: 0.8444 - precision: 0.9559 - recall: 0.7222 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5925 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 59/500\n",
            "18/18 - 0s - loss: 0.3897 - acc: 0.8278 - precision: 0.9041 - recall: 0.7333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.5957 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 60/500\n",
            "18/18 - 0s - loss: 0.3969 - acc: 0.7944 - precision: 0.9077 - recall: 0.6556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.5551 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 61/500\n",
            "18/18 - 0s - loss: 0.3712 - acc: 0.8389 - precision: 0.8861 - recall: 0.7778 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5488 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 62/500\n",
            "18/18 - 0s - loss: 0.3624 - acc: 0.8222 - precision: 0.8919 - recall: 0.7333 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.5508 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 63/500\n",
            "18/18 - 0s - loss: 0.3591 - acc: 0.8056 - precision: 0.8481 - recall: 0.7444 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.5608 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 64/500\n",
            "18/18 - 0s - loss: 0.4267 - acc: 0.7889 - precision: 0.9333 - recall: 0.6222 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5440 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 65/500\n",
            "18/18 - 0s - loss: 0.4276 - acc: 0.8000 - precision: 0.9355 - recall: 0.6444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.5568 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 66/500\n",
            "18/18 - 0s - loss: 0.3503 - acc: 0.7944 - precision: 0.8354 - recall: 0.7333 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.5176 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 67/500\n",
            "18/18 - 0s - loss: 0.3285 - acc: 0.8611 - precision: 0.9452 - recall: 0.7667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4984 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 68/500\n",
            "18/18 - 0s - loss: 0.3494 - acc: 0.8111 - precision: 0.8182 - recall: 0.8000 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5419 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 69/500\n",
            "18/18 - 0s - loss: 0.3561 - acc: 0.8222 - precision: 0.9833 - recall: 0.6556 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.5346 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 70/500\n",
            "18/18 - 0s - loss: 0.3482 - acc: 0.7889 - precision: 0.8095 - recall: 0.7556 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.5238 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 71/500\n",
            "18/18 - 0s - loss: 0.3332 - acc: 0.8667 - precision: 0.9125 - recall: 0.8111 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.4624 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 72/500\n",
            "18/18 - 0s - loss: 0.4242 - acc: 0.8000 - precision: 0.8750 - recall: 0.7000 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.5564 - val_acc: 0.6167 - val_precision: 1.0000 - val_recall: 0.2333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 73/500\n",
            "18/18 - 0s - loss: 0.3389 - acc: 0.8389 - precision: 0.8588 - recall: 0.8111 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.5223 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 74/500\n",
            "18/18 - 0s - loss: 0.3931 - acc: 0.7778 - precision: 0.8205 - recall: 0.7111 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.4873 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 75/500\n",
            "18/18 - 0s - loss: 0.3096 - acc: 0.8556 - precision: 1.0000 - recall: 0.7111 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.4973 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 76/500\n",
            "18/18 - 0s - loss: 0.2772 - acc: 0.8778 - precision: 0.9048 - recall: 0.8444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4774 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 77/500\n",
            "18/18 - 0s - loss: 0.2714 - acc: 0.8611 - precision: 0.8916 - recall: 0.8222 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4762 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 78/500\n",
            "18/18 - 0s - loss: 0.2594 - acc: 0.8833 - precision: 0.9726 - recall: 0.7889 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4915 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 79/500\n",
            "18/18 - 0s - loss: 0.2717 - acc: 0.8611 - precision: 0.8824 - recall: 0.8333 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4688 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 80/500\n",
            "18/18 - 0s - loss: 0.3516 - acc: 0.8389 - precision: 0.8506 - recall: 0.8222 - tn: 77.0000 - fp: 13.0000 - val_loss: 0.4685 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 81/500\n",
            "18/18 - 0s - loss: 0.3700 - acc: 0.8056 - precision: 0.7723 - recall: 0.8667 - tn: 67.0000 - fp: 23.0000 - val_loss: 0.4779 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 82/500\n",
            "18/18 - 0s - loss: 0.3129 - acc: 0.8556 - precision: 0.9848 - recall: 0.7222 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4931 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 83/500\n",
            "18/18 - 0s - loss: 0.3010 - acc: 0.8667 - precision: 0.8837 - recall: 0.8444 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4581 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 84/500\n",
            "18/18 - 0s - loss: 0.2083 - acc: 0.8833 - precision: 0.9600 - recall: 0.8000 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4864 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 85/500\n",
            "18/18 - 0s - loss: 0.2638 - acc: 0.8944 - precision: 0.9494 - recall: 0.8333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4528 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 86/500\n",
            "18/18 - 0s - loss: 0.2881 - acc: 0.8333 - precision: 0.8409 - recall: 0.8222 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.6004 - val_acc: 0.6333 - val_precision: 1.0000 - val_recall: 0.2667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 87/500\n",
            "18/18 - 0s - loss: 0.2825 - acc: 0.8500 - precision: 0.9701 - recall: 0.7222 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4718 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 88/500\n",
            "18/18 - 0s - loss: 0.3315 - acc: 0.8500 - precision: 0.8316 - recall: 0.8778 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4639 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 89/500\n",
            "18/18 - 0s - loss: 0.3278 - acc: 0.8111 - precision: 0.8684 - recall: 0.7333 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4228 - val_acc: 0.8333 - val_precision: 0.8125 - val_recall: 0.8667 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 90/500\n",
            "18/18 - 0s - loss: 0.3427 - acc: 0.8722 - precision: 0.8941 - recall: 0.8444 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4726 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 91/500\n",
            "18/18 - 0s - loss: 0.3163 - acc: 0.8389 - precision: 0.8861 - recall: 0.7778 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4576 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 92/500\n",
            "18/18 - 0s - loss: 0.2617 - acc: 0.8778 - precision: 0.8864 - recall: 0.8667 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.4689 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 93/500\n",
            "18/18 - 0s - loss: 0.2941 - acc: 0.8778 - precision: 0.9857 - recall: 0.7667 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.4408 - val_acc: 0.7833 - val_precision: 1.0000 - val_recall: 0.5667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 94/500\n",
            "18/18 - 0s - loss: 0.2709 - acc: 0.9000 - precision: 0.9390 - recall: 0.8556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4447 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 95/500\n",
            "18/18 - 0s - loss: 0.2655 - acc: 0.8944 - precision: 0.9383 - recall: 0.8444 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4280 - val_acc: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 96/500\n",
            "18/18 - 0s - loss: 0.2489 - acc: 0.8889 - precision: 0.8804 - recall: 0.9000 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4251 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 97/500\n",
            "18/18 - 0s - loss: 0.3026 - acc: 0.8722 - precision: 0.9467 - recall: 0.7889 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4336 - val_acc: 0.8500 - val_precision: 0.8621 - val_recall: 0.8333 - val_tn: 26.0000 - val_fp: 4.0000\n",
            "Epoch 98/500\n",
            "18/18 - 0s - loss: 0.3783 - acc: 0.8167 - precision: 0.8065 - recall: 0.8333 - tn: 72.0000 - fp: 18.0000 - val_loss: 0.5123 - val_acc: 0.6500 - val_precision: 1.0000 - val_recall: 0.3000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 99/500\n",
            "18/18 - 0s - loss: 0.2353 - acc: 0.8889 - precision: 0.9605 - recall: 0.8111 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.4415 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 100/500\n",
            "18/18 - 0s - loss: 0.2323 - acc: 0.9000 - precision: 0.9390 - recall: 0.8556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4567 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.4333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 101/500\n",
            "18/18 - 0s - loss: 0.2512 - acc: 0.9111 - precision: 0.9111 - recall: 0.9111 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4409 - val_acc: 0.6833 - val_precision: 1.0000 - val_recall: 0.3667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 102/500\n",
            "18/18 - 0s - loss: 0.2611 - acc: 0.8500 - precision: 0.8889 - recall: 0.8000 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4122 - val_acc: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 103/500\n",
            "18/18 - 0s - loss: 0.2158 - acc: 0.9222 - precision: 0.9130 - recall: 0.9333 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3884 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 104/500\n",
            "18/18 - 0s - loss: 0.2609 - acc: 0.9000 - precision: 0.9500 - recall: 0.8444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4154 - val_acc: 0.7000 - val_precision: 1.0000 - val_recall: 0.4000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 105/500\n",
            "18/18 - 0s - loss: 0.2829 - acc: 0.8667 - precision: 0.9024 - recall: 0.8222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4545 - val_acc: 0.8000 - val_precision: 1.0000 - val_recall: 0.6000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 106/500\n",
            "18/18 - 0s - loss: 0.2899 - acc: 0.8667 - precision: 0.8367 - recall: 0.9111 - tn: 74.0000 - fp: 16.0000 - val_loss: 0.4046 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 107/500\n",
            "18/18 - 0s - loss: 0.2126 - acc: 0.9000 - precision: 0.9286 - recall: 0.8667 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3615 - val_acc: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 108/500\n",
            "18/18 - 0s - loss: 0.1639 - acc: 0.9222 - precision: 0.9750 - recall: 0.8667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3716 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 109/500\n",
            "18/18 - 0s - loss: 0.1484 - acc: 0.9389 - precision: 0.9341 - recall: 0.9444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4335 - val_acc: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 110/500\n",
            "18/18 - 0s - loss: 0.2080 - acc: 0.9111 - precision: 0.9022 - recall: 0.9222 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3824 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 111/500\n",
            "18/18 - 0s - loss: 0.1884 - acc: 0.9111 - precision: 0.9111 - recall: 0.9111 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3517 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 112/500\n",
            "18/18 - 0s - loss: 0.2123 - acc: 0.9000 - precision: 0.8830 - recall: 0.9222 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.4026 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 113/500\n",
            "18/18 - 0s - loss: 0.1736 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3710 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 114/500\n",
            "18/18 - 0s - loss: 0.2660 - acc: 0.8833 - precision: 0.8791 - recall: 0.8889 - tn: 79.0000 - fp: 11.0000 - val_loss: 0.3726 - val_acc: 0.8833 - val_precision: 1.0000 - val_recall: 0.7667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 115/500\n",
            "18/18 - 0s - loss: 0.2022 - acc: 0.9333 - precision: 0.9239 - recall: 0.9444 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3676 - val_acc: 0.7833 - val_precision: 0.7931 - val_recall: 0.7667 - val_tn: 24.0000 - val_fp: 6.0000\n",
            "Epoch 116/500\n",
            "18/18 - 0s - loss: 0.1897 - acc: 0.9278 - precision: 0.9231 - recall: 0.9333 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3913 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 117/500\n",
            "18/18 - 0s - loss: 0.1462 - acc: 0.9444 - precision: 0.9545 - recall: 0.9333 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4131 - val_acc: 0.8167 - val_precision: 0.9130 - val_recall: 0.7000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 118/500\n",
            "18/18 - 0s - loss: 0.2664 - acc: 0.8611 - precision: 0.8652 - recall: 0.8556 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.4868 - val_acc: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 119/500\n",
            "18/18 - 0s - loss: 0.1874 - acc: 0.9278 - precision: 0.9140 - recall: 0.9444 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3651 - val_acc: 0.8500 - val_precision: 0.8889 - val_recall: 0.8000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 120/500\n",
            "18/18 - 0s - loss: 0.1644 - acc: 0.9389 - precision: 0.9438 - recall: 0.9333 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3458 - val_acc: 0.8833 - val_precision: 1.0000 - val_recall: 0.7667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 121/500\n",
            "18/18 - 0s - loss: 0.1965 - acc: 0.9167 - precision: 0.9412 - recall: 0.8889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3136 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 122/500\n",
            "18/18 - 0s - loss: 0.1975 - acc: 0.9222 - precision: 0.9043 - recall: 0.9444 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4011 - val_acc: 0.8833 - val_precision: 1.0000 - val_recall: 0.7667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 123/500\n",
            "18/18 - 0s - loss: 0.2904 - acc: 0.8833 - precision: 0.9157 - recall: 0.8444 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3835 - val_acc: 0.8500 - val_precision: 0.8889 - val_recall: 0.8000 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 124/500\n",
            "18/18 - 0s - loss: 0.1656 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4040 - val_acc: 0.8500 - val_precision: 1.0000 - val_recall: 0.7000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 125/500\n",
            "18/18 - 0s - loss: 0.1744 - acc: 0.9389 - precision: 0.9647 - recall: 0.9111 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.5023 - val_acc: 0.6667 - val_precision: 1.0000 - val_recall: 0.3333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 126/500\n",
            "18/18 - 0s - loss: 0.1683 - acc: 0.9333 - precision: 0.9432 - recall: 0.9222 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4038 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 127/500\n",
            "18/18 - 0s - loss: 0.2678 - acc: 0.8611 - precision: 0.9452 - recall: 0.7667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3771 - val_acc: 0.8000 - val_precision: 0.8214 - val_recall: 0.7667 - val_tn: 25.0000 - val_fp: 5.0000\n",
            "Epoch 128/500\n",
            "18/18 - 0s - loss: 0.1581 - acc: 0.9444 - precision: 0.9348 - recall: 0.9556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3545 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 129/500\n",
            "18/18 - 0s - loss: 0.2562 - acc: 0.9000 - precision: 0.9000 - recall: 0.9000 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.3921 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 130/500\n",
            "18/18 - 0s - loss: 0.2458 - acc: 0.8778 - precision: 0.8542 - recall: 0.9111 - tn: 76.0000 - fp: 14.0000 - val_loss: 0.4092 - val_acc: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 131/500\n",
            "18/18 - 0s - loss: 0.2779 - acc: 0.9111 - precision: 1.0000 - recall: 0.8222 - tn: 90.0000 - fp: 0.0000e+00 - val_loss: 0.4023 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 132/500\n",
            "18/18 - 0s - loss: 0.1791 - acc: 0.9444 - precision: 0.9348 - recall: 0.9556 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3634 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 133/500\n",
            "18/18 - 0s - loss: 0.2274 - acc: 0.9167 - precision: 0.9412 - recall: 0.8889 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.2860 - val_acc: 0.9000 - val_precision: 0.9286 - val_recall: 0.8667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 134/500\n",
            "18/18 - 0s - loss: 0.1768 - acc: 0.9333 - precision: 0.9875 - recall: 0.8778 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.3630 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 135/500\n",
            "18/18 - 0s - loss: 0.1723 - acc: 0.9444 - precision: 0.9167 - recall: 0.9778 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3561 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 136/500\n",
            "18/18 - 0s - loss: 0.1912 - acc: 0.9222 - precision: 0.9222 - recall: 0.9222 - tn: 83.0000 - fp: 7.0000 - val_loss: 0.3165 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 137/500\n",
            "18/18 - 0s - loss: 0.1731 - acc: 0.9167 - precision: 0.9121 - recall: 0.9222 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4453 - val_acc: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 138/500\n",
            "18/18 - 0s - loss: 0.1637 - acc: 0.9389 - precision: 0.9759 - recall: 0.9000 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.4179 - val_acc: 0.8833 - val_precision: 1.0000 - val_recall: 0.7667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 139/500\n",
            "18/18 - 0s - loss: 0.1844 - acc: 0.9167 - precision: 0.9518 - recall: 0.8778 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.4361 - val_acc: 0.8500 - val_precision: 1.0000 - val_recall: 0.7000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 140/500\n",
            "18/18 - 0s - loss: 0.1215 - acc: 0.9500 - precision: 0.9451 - recall: 0.9556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4133 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 141/500\n",
            "18/18 - 0s - loss: 0.1923 - acc: 0.9278 - precision: 0.9639 - recall: 0.8889 - tn: 87.0000 - fp: 3.0000 - val_loss: 0.3353 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 142/500\n",
            "18/18 - 0s - loss: 0.1984 - acc: 0.9111 - precision: 0.9022 - recall: 0.9222 - tn: 81.0000 - fp: 9.0000 - val_loss: 0.4189 - val_acc: 0.8833 - val_precision: 1.0000 - val_recall: 0.7667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 143/500\n",
            "18/18 - 0s - loss: 0.1445 - acc: 0.9389 - precision: 0.9158 - recall: 0.9667 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.3442 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 144/500\n",
            "18/18 - 0s - loss: 0.2098 - acc: 0.9389 - precision: 0.9341 - recall: 0.9444 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.4094 - val_acc: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 145/500\n",
            "18/18 - 0s - loss: 0.1899 - acc: 0.9333 - precision: 0.9333 - recall: 0.9333 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3184 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 146/500\n",
            "18/18 - 0s - loss: 0.2359 - acc: 0.9000 - precision: 0.9091 - recall: 0.8889 - tn: 82.0000 - fp: 8.0000 - val_loss: 0.4253 - val_acc: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 147/500\n",
            "18/18 - 0s - loss: 0.1173 - acc: 0.9500 - precision: 0.9451 - recall: 0.9556 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3089 - val_acc: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 148/500\n",
            "18/18 - 0s - loss: 0.1095 - acc: 0.9556 - precision: 0.9457 - recall: 0.9667 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.4935 - val_acc: 0.7833 - val_precision: 1.0000 - val_recall: 0.5667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 149/500\n",
            "18/18 - 0s - loss: 0.1678 - acc: 0.9389 - precision: 0.9877 - recall: 0.8889 - tn: 89.0000 - fp: 1.0000 - val_loss: 0.3362 - val_acc: 0.8333 - val_precision: 0.7632 - val_recall: 0.9667 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 150/500\n",
            "18/18 - 0s - loss: 0.2468 - acc: 0.8944 - precision: 0.8737 - recall: 0.9222 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.3631 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 151/500\n",
            "18/18 - 0s - loss: 0.1540 - acc: 0.9500 - precision: 0.9551 - recall: 0.9444 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3088 - val_acc: 0.8167 - val_precision: 0.7568 - val_recall: 0.9333 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 152/500\n",
            "18/18 - 0s - loss: 0.1162 - acc: 0.9556 - precision: 0.9556 - recall: 0.9556 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.2977 - val_acc: 0.8333 - val_precision: 0.8846 - val_recall: 0.7667 - val_tn: 27.0000 - val_fp: 3.0000\n",
            "Epoch 153/500\n",
            "18/18 - 0s - loss: 0.1968 - acc: 0.9278 - precision: 0.9425 - recall: 0.9111 - tn: 85.0000 - fp: 5.0000 - val_loss: 0.3439 - val_acc: 0.8500 - val_precision: 0.9200 - val_recall: 0.7667 - val_tn: 28.0000 - val_fp: 2.0000\n",
            "Epoch 154/500\n",
            "18/18 - 0s - loss: 0.2074 - acc: 0.9167 - precision: 0.8788 - recall: 0.9667 - tn: 78.0000 - fp: 12.0000 - val_loss: 0.4527 - val_acc: 0.8167 - val_precision: 1.0000 - val_recall: 0.6333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 155/500\n",
            "18/18 - 0s - loss: 0.2352 - acc: 0.9056 - precision: 0.9294 - recall: 0.8778 - tn: 84.0000 - fp: 6.0000 - val_loss: 0.3281 - val_acc: 0.8000 - val_precision: 0.7500 - val_recall: 0.9000 - val_tn: 21.0000 - val_fp: 9.0000\n",
            "Epoch 156/500\n",
            "18/18 - 0s - loss: 0.1076 - acc: 0.9611 - precision: 0.9560 - recall: 0.9667 - tn: 86.0000 - fp: 4.0000 - val_loss: 0.3838 - val_acc: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_tn: 30.0000 - val_fp: 0.0000e+00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 157/500\n",
            "18/18 - 0s - loss: 0.2453 - acc: 0.8944 - precision: 0.8901 - recall: 0.9000 - tn: 80.0000 - fp: 10.0000 - val_loss: 0.3361 - val_acc: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "Epoch 158/500\n",
            "18/18 - 0s - loss: 0.1538 - acc: 0.9222 - precision: 0.9750 - recall: 0.8667 - tn: 88.0000 - fp: 2.0000 - val_loss: 0.3522 - val_acc: 0.8833 - val_precision: 1.0000 - val_recall: 0.7667 - val_tn: 30.0000 - val_fp: 0.0000e+00\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.2860 - acc: 0.9000 - precision: 0.9286 - recall: 0.8667 - tn: 28.0000 - fp: 2.0000   \n",
            "loss:\n",
            "[0.2859880328178406, 0.8999999761581421, 0.9285714030265808, 0.8666666746139526, 28.0, 2.0]\n",
            "['loss', 'acc', 'precision', 'recall', 'tn', 'fp']\n"
          ]
        }
      ],
      "source": [
        "for i, (train_index, test_index) in enumerate(stratified_folds):\n",
        "    print(f\"Training and evaluating on fold {i+1} out of {folds * n_repeats}...\")\n",
        "    print(\"train_index\" + str(train_index))\n",
        "    print(\"test_index\" + str(test_index))\n",
        "    train_gen, test_gen = get_generators(\n",
        "        train_index, test_index, graph_labels, batch_size=10\n",
        "    )\n",
        "\n",
        "    model = create_graph_classification_model(generator)\n",
        "\n",
        "    history, acc, precision, recall, true_neg, false_pos= train_fold(model, train_gen, test_gen, es, epochs)\n",
        "\n",
        "    histories.append(history)\n",
        "    test_accs.append(acc)\n",
        "    test_precision.append(precision)\n",
        "    test_recall.append(recall)\n",
        "    test_true_neg.append(true_neg)\n",
        "    test_false_pos.append(false_pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2yJpdjxs0y3",
        "outputId": "2633c472-b093-4356-f209-52a4e75350ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy over all folds mean: 91.2% and std: 1e+01%\n",
            "Precision over all folds mean: 95.5%\n",
            "Recall over all folds mean: 86.7%\n",
            "True Negs over all folds mean: 28.8\n",
            "False Pos over all folds mean: 1.25\n",
            "Specificity over all folds mean: 95.8%\n"
          ]
        }
      ],
      "source": [
        "test_specificity = np.array(test_true_neg) / (np.array(test_true_neg) + np.array(test_false_pos))\n",
        "tn_mean = np.mean(test_true_neg)*100\n",
        "fp_mean = np.mean(test_false_pos)*100\n",
        "specificity_mean = tn_mean / (tn_mean + fp_mean)\n",
        "print(\n",
        "    f\"Accuracy over all folds mean: {np.mean(test_accs)*100:.3}% and std: {np.std(test_accs)*100:.2}%\\n\"\n",
        "    f\"Precision over all folds mean: {np.mean(test_precision)*100:.3}%\\n\"\n",
        "    f\"Recall over all folds mean: {np.mean(test_recall)*100:.3}%\\n\"\n",
        "    f\"True Negs over all folds mean: {np.mean(test_true_neg):.3}\\n\"\n",
        "    f\"False Pos over all folds mean: {np.mean(test_false_pos):.3}\\n\"\n",
        "    f\"Specificity over all folds mean: {specificity_mean*100:.3}%\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz8i8-qls0y4"
      },
      "source": [
        "Finally, we plot a histogram of the accuracy of all `n_repeats x folds` models trained (25 in total)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkOQ6OTZs0y4",
        "outputId": "b4632d5a-f7f4-4015-e4d6-b914f4e22dc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(test_accs)\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0VH5OT4s0y5"
      },
      "source": [
        "The histogram shown above indicates the difficulty of training a good model on the reduced PPMI dataset due to the following factors,\n",
        "- small amount of available data, i.e., only 20 graphs\n",
        "- small amount of validation data since for a single fold only 2 graphs are used for validation\n",
        "- the data are unbalanced since one class has twice as many nodes\n",
        "\n",
        "Given the above, average performance as estimated using repeated k-fold cross validation displays high variance but overall good performance for a straightforward application of graph convolutional neural networks to supervised graph classification. The high variance is likely the result of the small dataset size.\n",
        "\n",
        "Generally, performance is higher than SOTA in recent literature. However, we have not tuned the model to avoid overfittig possible so some improvement over the current baseline may be attainable.\n",
        "\n",
        "When comparing to graph kernel-based approaches, our straightforward GCN with mean pooling graph classification model is competitive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOzQ1scis0y5",
        "outputId": "5bb52105-f0be-4721-8312-e4391ad43126"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(test_precision)\n",
        "plt.xlabel(\"Precision\")\n",
        "plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtecIJErs0y6",
        "outputId": "9ac4ff4e-22f7-4a93-e6fa-d57dedbf9979"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(test_recall)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eXa5VC3s0y6",
        "outputId": "13edb237-21a8-42bd-b8ba-716188660729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFzCAYAAAD18ZqMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATvElEQVR4nO3dfbBtd3kX8O9DQqCSAMEcM6EhvcUibcQ2xEtsSMUmZSpvA7ZVWrTyInoHLW1ItU6UccQZ/wBfKFZq6zWl0IqpRZIRCm2DQKBVGrhJk0tCIqWQKILkpmgDU4ea8PjHXpccD/ees2/uWef+zj6fz8yevc56+z2/ve7KN2vttdeq7g4AMJZHnOoCAICvJ6ABYEACGgAGJKABYEACGgAGJKABYECnn+oC1jvnnHN63759p7oMANgRN998833dvXasaUMF9L59+3Lo0KFTXQYA7Iiquud405ziBoABCWgAGJCABoABCWgAGJCABoABCWgAGJCABoABCWgAGJCABoABCWgAGNCst/qsqruTfCnJg0ke6O79c7YHAKtiJ+7FfXl337cD7QDAynCKGwAGNPcRdCe5oao6yb/u7oMbZ6iqA0kOJMkFF1wwczkAjGrf1e851SVs6e7XP3/H2pr7CPqy7r44yXOT/EhVPWvjDN19sLv3d/f+tbVjPhITAPacWQO6uz83vd+b5Pokl8zZHgCsitkCuqoeU1VnHR1O8r1Jbp+rPQBYJXN+B31ukuur6mg7/667f23G9gBgZcwW0N396STfMdf6AWCV+ZkVAAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxIQAPAgAQ0AAxo9oCuqtOq6rer6lfmbgsAVsVOHEFfmeTOHWgHAFbGrAFdVecneX6Sa+ZsBwBWzdxH0G9K8neTfPV4M1TVgao6VFWHjhw5MnM5ALA7zBbQVfWCJPd2982bzdfdB7t7f3fvX1tbm6scANhV5jyCvizJC6vq7iS/lOSKqvq3M7YHACtjtoDu7r/X3ed3974kP5TkA939w3O1BwCrxO+gAWBAp+9EI919Y5Ibd6ItAFgFjqABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYEACGgAGJKABYECzBXRVPbqqPlpVt1XVHVX1j+ZqCwBWzekzrvsrSa7o7i9X1SOT/GZV/Wp3/9aMbQLASpgtoLu7k3x5+vOR06vnag8AVsms30FX1WlVdWuSe5O8r7tvOsY8B6rqUFUdOnLkyJzlAMCuMWtAd/eD3X1RkvOTXFJVTzvGPAe7e393719bW5uzHADYNXbkKu7u/t9JbkzynJ1oDwB2uzmv4l6rqsdPw9+Q5NlJ7pqrPQBYJXNexX1ekrdV1WlZ/I/AL3f3r8zYHgCsjDmv4j6c5OlzrR8AVpk7iQHAgAQ0AAxIQAPAgAQ0AAxIQAPAgJYK6Kq6bJlxAMD2WPYI+l8uOQ4A2Aab/g66qi5N8swka1X14+smPTbJaXMWBgB72VY3KjkjyZnTfGetG39/kr84V1EAsNdtGtDd/aEkH6qqt3b3PTtUEwDsecve6vNRVXUwyb71y3T3FXMUBQB73bIB/Y4kP5vkmiQPzlcOAJAsH9APdPfPzFoJAPA1y/7M6t1V9beq6ryqesLR16yVAcAetuwR9Mum959YN66TPHl7ywEAkiUDuru/ee5CAICHLBXQVfXSY43v7l/Y3nIAgGT5U9zPWDf86CTfk+SWJAIaAGaw7CnuH13/d1U9LskvzlIRAPCwHzf5B0mesp2FAAAPWfY76HdncdV2snhIxrcl+eW5igKAvW7Z76D/2brhB5Lc092fnaEeACBLnuKeHppxVxZPtDo7yR/OWRQA7HVLBXRVvTjJR5P8pSQvTnJTVXncJADMZNlT3K9N8ozuvjdJqmotyX9K8h/mKgwA9rJlr+J+xNFwnvzeCSwLAJygZY+gf62qfj3JtdPfP5jkvfOUBABsGtBV9S1Jzu3un6iq70/yXUkqyUeSvH0H6gOAPWmr09RvSvKlJOnu67r7x7v7qiyOnt80b2kAsHdtFdD7uvvwxpHdfSjJvlkqAgC2DOhHbzLtG7azEADgIVsF9Meq6m9sHFlVr0xy8zwlAQBbXcX9miTXV9VfyUOBvD/JGUm+b8a6AGBP2zSgu/sLSZ5ZVZcnedo0+j3d/YHZKwOAPWzZ50F/MMkHZ64FAJi4GxgADEhAA8CABDQADEhAA8CABDQADEhAA8CABDQADEhAA8CABDQADEhAA8CABDQADEhAA8CABDQADEhAA8CABDQADEhAA8CABDQADEhAA8CAZgvoqnpSVX2wqu6sqjuq6sq52gKAVXP6jOt+IMnf7u5bquqsJDdX1fu6+xMztgkAK2G2I+ju/nx33zINfynJnUm+ca72AGCV7Mh30FW1L8nTk9y0E+0BwG43e0BX1ZlJ3pnkNd19/zGmH6iqQ1V16MiRI3OXAwC7wqwBXVWPzCKc397d1x1rnu4+2N37u3v/2tranOUAwK4x51XcleTnktzZ3W+cqx0AWEVzHkFfluSvJrmiqm6dXs+bsT0AWBmz/cyqu38zSc21fgBYZe4kBgADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADEtAAMCABDQADmi2gq+otVXVvVd0+VxsAsKrmPIJ+a5LnzLh+AFhZswV0d384yRfnWj8ArDLfQQPAgE4/1QVU1YEkB5Lkggsu2NZ177v6Pdu6vu129+uff6pLYAeM/u8wGf/fos+QveiUH0F398Hu3t/d+9fW1k51OQAwhFMe0ADA15vzZ1bXJvlIkqdW1Wer6pVztQUAq2a276C7+yVzrRsAVp1T3AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwIAENAAMS0AAwoFkDuqqeU1X/tao+VVVXz9kWAKyS2QK6qk5L8tNJnpvkwiQvqaoL52oPAFbJnEfQlyT5VHd/urv/MMkvJXnRjO0BwMqYM6C/Mcl/X/f3Z6dxAMAWTp9x3XWMcf11M1UdSHJg+vMrVXX7jDUNpd6Qc5Lcd6rr2GH6PKB6w7avcvg+bzf7894ww3b+puNNmDOgP5vkSev+Pj/J5zbO1N0HkxxMkqo61N37Z6xpKHutv4k+7xX6vDfo87zmPMX9sSRPqapvrqozkvxQknfN2B4ArIzZjqC7+4GqenWSX09yWpK3dPcdc7UHAKtkzlPc6e73JnnvCSxycK5aBrXX+pvo816hz3uDPs+our/uui0A4BRzq08AGNCcdxLb9DafVfW4qnp3Vd1WVXdU1Sum8U+qqg9W1Z3T+CvXLfO6qvofVXXr9HreXPU/HA+3z9O0u6vq41O/Dq0b/4Sqel9V/c70fvZO9WcZJ7Gdn7puO95aVfdX1WumacNu5yX6e3ZVXV9Vh6vqo1X1tK2WXYFtfMw+r/i+vNl2XtV9+Xjbebfuy2+pqnvrOD/trYWfmj6Pw1V18bppO7Mvd/e2v7K4KOx3kzw5yRlJbkty4YZ5/n6SN0zDa0m+OM17XpKLp/FnJfnk0WWTvC7J35mj5lPZ5+nvu5Occ4z1/pMkV0/DVx9dfoTXyfZ5w3r+Z5JvGnk7L9nff5rkH07D35rk/VstuwLb+Hh9XuV9+Zh9nv5e1X35uH3esJ7h9+WptmcluTjJ7ceZ/rwkv5rFPT2+M8lNW31W272N5zqCXuY2n53krKqqJGdm8R/uB7r78919S5J095eS3JndcQeyh93nLdb7oiRvm4bfluQvbFvFJ2+7+vw9SX63u++Zu+CTtEx/L0zy/iTp7ruS7Kuqc7dYdrdv42P2ecX35eNt582s5HbeMM9u2ZfT3R/O4r9Hx/OiJL/QC7+V5PFVdV52cF+eK6CXuc3nm5N8WxY3L/l4kiu7+6vrZ6iqfUmenuSmdaNfPZ1ueMtgp4hOts+d5IaqurkWd1c76tzu/nySTO9/bI7iH6Zt2c5Z/Eb+2g3jRtzOy/T3tiTfnyRVdUkWdwk6f4tld/s2Pl6fv2YF9+XN+ryq+/KW2zm7Z19exvE+kx3bl+cK6GVu8/nnk9ya5IlJLkry5qp67NdWUHVmkncmeU133z+N/pkkf3ya//NJ/vl2Fn2STrbPl3X3xVk8/etHqupZM9W5nbZjO5+R5IVJ3rFumVG38zL9fX2Ss6vq1iQ/muS3szhjsNStbwd0Mn1erGA19+XN+ryq+/JW23k37cvLON5nsmP78lwBvcxtPl+R5Lrp9MGnknwmi+81UlWPzGKHfnt3X3d0ge7+Qnc/OB2B/ZssTjWM4qT63N2fm97vTXJ9HurbF6bTKpne752tByfupPo8eW6SW7r7C0dHDLydt+xvd9/f3a/o7ouSvDSL790/s8Wyu3obb9Lnld2XN+vzqu7Lm/V5spv25WUc7zPZsX15roBe5jaf/y2L7ysyfY/x1CSfnr6r/Lkkd3b3G9cvcLTjk+9LMtKDNU6mz4+pqrOm8Y9J8r15qG/vSvKyafhlSf7jrL04MQ+7z+umvyQbTokNvJ237G9VPX6aliR/PcmHp6PGzZbd1dv4eH1e5X15kz6v7L68yb/to3bTvryMdyV56XQ193cm+f3ptPXO7csnc4XZZq8sroD7ZBZXu712GveqJK+ahp+Y5IYsvpe8PckPT+O/K4vTBYezODV6a5LnTdN+cZr/8PRBnDdX/Tvc5ydn8f3ObUnuOLrsNO2PZnFhxu9M70841f3cjj5P0/5Ikt9L8rgN6xx2Oy/R30unbXVXkuuSnL3ZsiuyjY/Z5xXfl4/X51Xelzf7t70b9+Vrszjt/n+zOCp+5Yb+VpKfnj6PjyfZv9lnNcc2dicxABiQO4kBwIAENAAMSEADwIAENAAMSEADwIAENOwCVfXaWjwR6nAtngr0Z7Zx3e+tqsdPwz9Wi6dPvb2qXljHeKrRhmX/y/S+r6r+8nbVBMTPrGB0VXVpkjcm+e7u/kpVnZPFE8E23rVtO9q6K8lzu/szW878/y/33Vk8tegF210T7FWOoGF85yW5r7u/kiTdfV93f64Wzx1+Qy2ezfvRqvqWJKmqtap6Z1V9bHpdNo0/s6p+vhbPKj5cVT8wjb+7qs6pqp/N4kYb76qqq6rq5VX15mmec2vxLODbptczp/Ffnmp8fZI/Ox3dX1VVv1FVFx3tQFX956r69p35uGA1CGgY3w1JnlRVn6yqf1VVf27dtPu7+5Isnhr2pmncv0jyk939jCQ/kOSaafw/yOJ2hX+qu789yQfWN9Ldr8rinsKXd/dPbqjhp5J8qLu/I4tn6N6xYfrVSX6juy+alr0mycuTpKr+RJJHdffhh9d92JsENAyuu7+c5E8nOZDkSJJ/X1UvnyZfu+790mn42Vk8NezWLG6v+Njp/tDPzuLWhUfX+79OoIwrsngyUXrx8IPf32L+dyR5wfSwjL+W5K0n0BaQ5PRTXQCwte5+MMmNSW6sqo/noRvyr7+I5OjwI5Jc2t3/Z/06podX7MhFJ939B1X1viweYP/iJPt3ol1YJY6gYXBV9dSqesq6URcluWca/sF17x+Zhm9I8up1y190nPFnn0AZ70/yN6flTqt1z/SefCnJWRvGXZPFqfGPdfcXT6AtIAIadoMzk7ytqj5RVYeTXJjkddO0R1XVTUmuTHLVNO7HkuyfLgT7RBZP6EmSf5zk7Kq6vapuS3L5CdRwZZLLp6P3m5P8yQ3TDyd5YLqA7Kok6e6bk9yf5OdPoB1g4mdWsEtV1d1ZPALvvlNdy7FU1ROzOC3/rd391VNcDuw6jqCBbVdVL01yUxbPyhXO8DA4ggaAATmCBoABCWgAGJCABoABCWgAGJCABoABCWgAGND/A8Yj7o01wqRkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(test_specificity)\n",
        "plt.xlabel(\"Specificity\")\n",
        "plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPFvBb-8s0y6",
        "outputId": "db104613-09f6-4db4-e615-8b90c1002b66"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbsphinx": "hidden",
        "tags": [
          "CloudRunner"
        ],
        "id": "gsOKTCC7s0y7"
      },
      "source": [
        "<table><tr><td>Run the latest release of this notebook:</td><td><a href=\"https://mybinder.org/v2/gh/stellargraph/stellargraph/master?urlpath=lab/tree/demos/graph-classification/gcn-supervised-graph-classification.ipynb\" alt=\"Open In Binder\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\"/></a></td><td><a href=\"https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/graph-classification/gcn-supervised-graph-classification.ipynb\" alt=\"Open In Colab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a></td></tr></table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ANlR2Bbgs0y7",
        "outputId": "7dd0a9a8-c257-47f6-c447-fc5370c1c4ae"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lePQuuzzs0y7"
      },
      "outputs": [],
      "source": [
        "# test_accs > 0.9\n",
        "# test_precision > 0.9\n",
        "# test_recall > 0.9\n",
        "# test_specificity > 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x0_Fc8ks0y8",
        "outputId": "4410ca84-8083-42d1-b939-3c5dbf529c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9333333333333333]\n"
          ]
        }
      ],
      "source": [
        "print(test_specificity.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W30KB_yas0y8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGAN1Fwus0y8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
